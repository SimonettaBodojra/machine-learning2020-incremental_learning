{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "IL_lwf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "tvETQMX1ipNf",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1Odgmkpmjsp2tkXXJ3Yoxyukvr2QaEAMA\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab Account AI\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-LoM_h1IXAi",
        "colab_type": "code",
        "outputId": "27575964-e2c6-49a8-9bc6-e62356dadb4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "\"\"\"!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\"\"\"\n",
        "\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "print(gpu.name)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "wwN82ZV7ipNg",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RSnex0bmipNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_ROOT = 'cifar-100-python'\n",
        "CODE_ROOT = 'libs'\n",
        "import os\n",
        "if not os.path.isdir(DATASET_ROOT):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !rm -rf 'cifar-100-python.tar.gz'\n",
        "\n",
        "if not os.path.isdir(CODE_ROOT):\n",
        "  !git clone https://lore-lml:29f601e814e0446c5b17a9f6c3684d1cbd316bcf@github.com/lore-lml/machine-learning2020-incremental_learning.git\n",
        "  !mv 'machine-learning2020-incremental_learning/libs' '.'\n",
        "  !rm -rf 'machine-learning2020-incremental_learning'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Subset\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import libs.utils as utils\n",
        "from libs.utils import get_one_hot\n",
        "\n",
        "from libs.models.lwf import LwfModel\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7W9y67yoipNk",
        "colab_type": "text"
      },
      "source": [
        "**SET ARGUMENTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "r0hjWAP3ipNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "arguments = utils.get_arguments()\n",
        "\n",
        "DEVICE = arguments['DEVICE']\n",
        "NUM_CLASSES = arguments[\"NUM_CLASSES\"] \n",
        "\n",
        "BATCH_SIZE = arguments[\"BATCH_SIZE\"]        # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                                            # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = arguments[\"LR\"]                        # The initial Learning Rate\n",
        "MOMENTUM = arguments[\"MOMENTUM\"]            # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = arguments[\"WEIGHT_DECAY\"]    # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = arguments[\"NUM_EPOCHS\"]        # Total number of training epochs (iterations over dataset)\n",
        "GAMMA = arguments[\"GAMMA\"]                  # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = arguments[\"LOG_FREQUENCY\"]\n",
        "MILESTONES = arguments[\"MILESTONES\"]\n",
        "SEED = arguments[\"SEED\"]\n",
        "\n",
        "OUTPUT_PATH = \"RUN1_LWF\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "SaT8eFDNipNm",
        "colab_type": "text"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "m-ydAGw4ipNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms, eval_transforms = utils.get_train_eval_transforms()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "X7Naz_DdipNp",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "G-Xct5sNipNp",
        "colab_type": "code",
        "outputId": "468a412b-5475-49a6-af92-13984e201ef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_val_dataset = utils.get_cifar_with_seed(DATASET_ROOT, train_transforms, src='train', seed=SEED)\n",
        "test_dataset = utils.get_cifar_with_seed(DATASET_ROOT, eval_transforms, src='test', seed=SEED)\n",
        "\n",
        "print(f\"Size Training Set: {len(train_val_dataset)}\")\n",
        "print(f\"Size Test Set: {len(test_dataset)}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size Training Set: 50000\n",
            "Size Test Set: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xZDP5yXBipNt",
        "colab_type": "text"
      },
      "source": [
        "**Train, Test, Validation functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "secPALBtipNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(net: LwfModel, train_loader, optimizer, current_step, device=DEVICE):\n",
        "    net.train()\n",
        "    cumulative_loss =.0\n",
        "    running_corrects = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(images)\n",
        "        \n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        \n",
        "        loss = net.compute_distillation_loss(images, labels, outputs, DEVICE)\n",
        "        cumulative_loss += loss.item()\n",
        "        \n",
        "        if current_step != 0 and current_step % LOG_FREQUENCY == 0:\n",
        "                print('\\t\\tTrain step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_step += 1\n",
        "\n",
        "    return cumulative_loss / len(train_loader), running_corrects, current_step\n",
        "\n",
        "def validate(net, val_loader, criterion, optimizer, device=DEVICE):\n",
        "    net.eval()\n",
        "    cumulative_loss =.0\n",
        "    running_corrects = 0\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        labels_enc = get_one_hot(labels, NUM_CLASSES, DEVICE)\n",
        "        \n",
        "\n",
        "        outputs = net(images)\n",
        "        \n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        \n",
        "        loss = criterion(outputs, labels_enc)\n",
        "        cumulative_loss += loss.item()\n",
        "\n",
        "\n",
        "    return cumulative_loss / len(val_loader), running_corrects\n",
        "\n",
        "def test(net, test_loader, device=DEVICE):\n",
        "    \n",
        "    # confusion matrix\n",
        "    y_true = []\n",
        "    y_preds = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    for images, labels in tqdm(test_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        net.eval()\n",
        "        outputs = net(images)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        # confusion matrix\n",
        "        y_true.extend(labels.data.tolist())\n",
        "        y_preds.extend(preds.tolist())\n",
        "\n",
        "   \n",
        "    return running_corrects, y_true, y_preds\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "s5SroLpaipNw",
        "colab_type": "text"
      },
      "source": [
        "**FINE TUNING FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "clnGi_eLipNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lwf_training(train_val_dataset, test_dataset, max_epoch=NUM_EPOCHS, file_path=OUTPUT_PATH, device=DEVICE):\n",
        "    import math, time\n",
        "    incremental_test = []\n",
        "    train_mean_stage_accuracies = []\n",
        "    val_mean_stage_accuracies = []\n",
        "    test_stage_accuracies = []\n",
        "    cudnn.benchmark\n",
        "    net = LwfModel(100)\n",
        "    criterion = utils.get_criterion('bce')\n",
        "    start_time = time.time()\n",
        "    for stage in range(10):\n",
        "        optimizer, scheduler = utils.get_otpmizer_scheduler(net.parameters(), LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA)\n",
        "        print(f\"STARTING FINE TUNING STAGE {stage+1}...\")\n",
        "        # Get indices\n",
        "        # 4000 training, 1000 validation\n",
        "        train_idx, val_idx, test_idx = utils.get_kth_batch(train_val_dataset, test_dataset, stage,\n",
        "                                                                 seed=SEED, train_size=.9, get='indices')\n",
        "        \n",
        "        # Make test set incremental\n",
        "        incremental_test.extend(test_idx)\n",
        "        train_set, val_set, test_set = Subset(train_val_dataset, train_idx),\\\n",
        "                                       Subset(train_val_dataset, val_idx),\\\n",
        "                                       Subset(test_dataset, incremental_test)\n",
        "\n",
        "        # Build data loaders\n",
        "        curr_train_loader = utils.get_train_loader(train_set,batch_size=BATCH_SIZE)\n",
        "        curr_val_loader = utils.get_eval_loader(val_set, batch_size=BATCH_SIZE)\n",
        "        curr_test_loader = utils.get_eval_loader(test_set, batch_size=BATCH_SIZE)\n",
        "\n",
        "        # Init results\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        train_accuracies = []\n",
        "        val_accuracies = []\n",
        "        min_val_loss = -1\n",
        "        current_step = 0\n",
        "        tolerance = 10\n",
        "        \n",
        "        net.before_train(DEVICE)\n",
        "        for epoch in range(max_epoch):\n",
        "            print(f\"\\tSTARTING EPOCH {epoch+1} - LR={scheduler.get_last_lr()}...\")\n",
        "            curr_result = train_batch(net, curr_train_loader, optimizer, current_step, device)\n",
        "            curr_train_loss = curr_result[0]\n",
        "            curr_train_accuracy = curr_result[1] / float(BATCH_SIZE * len(curr_train_loader))\n",
        "            current_step = curr_result[2]\n",
        "            \n",
        "            train_losses.append(curr_train_loss)\n",
        "            train_accuracies.append(curr_train_accuracy)\n",
        "            scheduler.step()\n",
        "            \n",
        "            curr_val_loss, val_corrects = validate(net, curr_val_loader, criterion, optimizer, device)\n",
        "            val_losses.append(curr_val_loss)\n",
        "            curr_val_accuracy = val_corrects / float(len(val_set))\n",
        "            val_accuracies.append(curr_val_accuracy)\n",
        "            \n",
        "            print(f\"\\t\\tRESULT EPOCH {epoch+1}:\")\n",
        "            print(f\"\\t\\t\\tTrain Loss: {curr_train_loss} - Train Accuracy: {curr_train_accuracy}\")\n",
        "            print(f\"\\t\\t\\tVal Loss: {curr_val_loss} - Val Accuracy: {curr_val_accuracy}\\n\")\n",
        "            \n",
        "            if math.isnan(curr_val_loss):\n",
        "                tolerance -= 1\n",
        "            else:\n",
        "                tolerance = 10\n",
        "            \n",
        "            if tolerance == 0:\n",
        "                print(f\"STAGE {stage+1} -> EARLY STOPPING\\n\")\n",
        "                break\n",
        "            \n",
        "            if min_val_loss == -1 or min_val_loss > curr_val_loss:\n",
        "                min_val_loss = curr_val_loss\n",
        "                torch.save(net, f\"{file_path}_best_model_finetuning.pth\")\n",
        "        \n",
        "        net.after_train(10)\n",
        "        corrects, y_true, y_preds = test(net, curr_test_loader, device)\n",
        "        epoch_test_accuracy = corrects / float(len(test_set))\n",
        "        test_stage_accuracies.append(epoch_test_accuracy)\n",
        "        train_mean_stage_accuracies.append(np.mean(train_accuracies))\n",
        "        val_mean_stage_accuracies.append(np.mean(val_accuracies))\n",
        "        \n",
        "        print(f\"\\n\\tResults STAGE {stage+1}:\")\n",
        "        print(f\"\\t\\tTrain Mean Accuracy: {train_mean_stage_accuracies[stage]}\")\n",
        "        print(f\"\\t\\tVal Mean Accuracy: {val_mean_stage_accuracies[stage]}\")\n",
        "        print(f\"\\t\\tTest Accuracy: {test_stage_accuracies[stage]}\\n\")\n",
        "\n",
        "\n",
        "    total_time = int(time.time() - start_time)\n",
        "    min = int(total_time / 60)\n",
        "    sec = total_time % 60\n",
        "    print(f\"\\nTotal time: {min} min {sec} sec\\n\")\n",
        "        \n",
        "    return train_mean_stage_accuracies,\\\n",
        "           val_mean_stage_accuracies,\\\n",
        "           test_stage_accuracies,\\\n",
        "           y_true, y_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "bvaYg8SiipNy",
        "colab_type": "text"
      },
      "source": [
        "**LEARNING WITHOUT FORGETTING START**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "i_ejvvl4ipNy",
        "colab_type": "code",
        "outputId": "139375ca-8014-4b06-a8cd-fdc3449d6907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_accuracies,\\\n",
        "val_accuracies,\\\n",
        "test_accuracies,\\\n",
        "y_true, y_preds = lwf_training(train_val_dataset, test_dataset, NUM_EPOCHS)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STARTING FINE TUNING STAGE 1...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n",
            "\t\tTrain step - Step 30, Loss 0.030733630061149597\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.07061414931501661 - Train Accuracy: 0.14375\n",
            "\t\t\tVal Loss: 0.031240341253578663 - Val Accuracy: 0.218\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.026248306035995483\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.027470116849456515 - Train Accuracy: 0.3352678571428571\n",
            "\t\t\tVal Loss: 0.028079324401915073 - Val Accuracy: 0.344\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.02308800257742405\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.024299784111125128 - Train Accuracy: 0.4303571428571429\n",
            "\t\t\tVal Loss: 0.035256588365882635 - Val Accuracy: 0.318\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.020478812977671623\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.02260982676276139 - Train Accuracy: 0.4792410714285714\n",
            "\t\t\tVal Loss: 0.023256429005414248 - Val Accuracy: 0.496\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 150, Loss 0.021932577714323997\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.020575817301869394 - Train Accuracy: 0.5341517857142857\n",
            "\t\t\tVal Loss: 0.024051738902926445 - Val Accuracy: 0.456\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.01850033923983574\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.01964324643569333 - Train Accuracy: 0.5629464285714286\n",
            "\t\t\tVal Loss: 0.02183485869318247 - Val Accuracy: 0.526\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.018325088545680046\n",
            "\t\tTrain step - Step 240, Loss 0.020385051146149635\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.01879817715712956 - Train Accuracy: 0.5720982142857143\n",
            "\t\t\tVal Loss: 0.020019283052533865 - Val Accuracy: 0.556\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 270, Loss 0.01694224216043949\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.017542955093085767 - Train Accuracy: 0.6140625\n",
            "\t\t\tVal Loss: 0.025968101574108005 - Val Accuracy: 0.474\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.015878871083259583\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.016033808274992876 - Train Accuracy: 0.6598214285714286\n",
            "\t\t\tVal Loss: 0.022356064058840275 - Val Accuracy: 0.532\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.01555815152823925\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.015452326328626701 - Train Accuracy: 0.6767857142857143\n",
            "\t\t\tVal Loss: 0.020405953051522374 - Val Accuracy: 0.568\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.015669863671064377\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.014409094303846359 - Train Accuracy: 0.6924107142857143\n",
            "\t\t\tVal Loss: 0.022454554680734873 - Val Accuracy: 0.562\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.01367389876395464\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.014490363693663052 - Train Accuracy: 0.7011160714285715\n",
            "\t\t\tVal Loss: 0.021461487747728825 - Val Accuracy: 0.56\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 420, Loss 0.011936179362237453\n",
            "\t\tTrain step - Step 450, Loss 0.01433872152119875\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.013458071489419255 - Train Accuracy: 0.7272321428571429\n",
            "\t\t\tVal Loss: 0.017086763633415103 - Val Accuracy: 0.632\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.013119776733219624\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.012602427761469569 - Train Accuracy: 0.7419642857142857\n",
            "\t\t\tVal Loss: 0.017382814083248377 - Val Accuracy: 0.632\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.012827742844820023\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.012421449992273535 - Train Accuracy: 0.7497767857142857\n",
            "\t\t\tVal Loss: 0.017475093714892864 - Val Accuracy: 0.64\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 540, Loss 0.014133837074041367\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.011682408249803952 - Train Accuracy: 0.7611607142857143\n",
            "\t\t\tVal Loss: 0.018422286957502365 - Val Accuracy: 0.638\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.011254156939685345\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.011656423152557441 - Train Accuracy: 0.765625\n",
            "\t\t\tVal Loss: 0.021636233432218432 - Val Accuracy: 0.59\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.010918853804469109\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.011349384220583097 - Train Accuracy: 0.7671875\n",
            "\t\t\tVal Loss: 0.016145601170137525 - Val Accuracy: 0.66\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.010927028022706509\n",
            "\t\tTrain step - Step 660, Loss 0.009804424829781055\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.010297485919935363 - Train Accuracy: 0.790625\n",
            "\t\t\tVal Loss: 0.014378991909325123 - Val Accuracy: 0.722\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.007845266722142696\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.010058987459966114 - Train Accuracy: 0.7986607142857143\n",
            "\t\t\tVal Loss: 0.01557406666688621 - Val Accuracy: 0.708\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.007917015813291073\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.009666857788605349 - Train Accuracy: 0.8071428571428572\n",
            "\t\t\tVal Loss: 0.01588044222444296 - Val Accuracy: 0.722\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.007555624470114708\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.009293264403407062 - Train Accuracy: 0.8075892857142857\n",
            "\t\t\tVal Loss: 0.014627637341618538 - Val Accuracy: 0.714\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.009551603347063065\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.00895870676530259 - Train Accuracy: 0.8241071428571428\n",
            "\t\t\tVal Loss: 0.019113812362775207 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 810, Loss 0.006472326349467039\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.008150921921644893 - Train Accuracy: 0.8424107142857142\n",
            "\t\t\tVal Loss: 0.013213919941335917 - Val Accuracy: 0.748\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.0083536421880126\n",
            "\t\tTrain step - Step 870, Loss 0.009379216469824314\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.008329939270125968 - Train Accuracy: 0.8410714285714286\n",
            "\t\t\tVal Loss: 0.013509433483704925 - Val Accuracy: 0.728\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.008348945528268814\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.008363248487668378 - Train Accuracy: 0.8305803571428572\n",
            "\t\t\tVal Loss: 0.013314103707671165 - Val Accuracy: 0.748\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 930, Loss 0.007589139975607395\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.008019757097853082 - Train Accuracy: 0.8446428571428571\n",
            "\t\t\tVal Loss: 0.013435955392196774 - Val Accuracy: 0.748\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.007356175221502781\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.007563154652182545 - Train Accuracy: 0.853125\n",
            "\t\t\tVal Loss: 0.013588008238002658 - Val Accuracy: 0.748\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.006789296865463257\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.007330421757485185 - Train Accuracy: 0.8607142857142858\n",
            "\t\t\tVal Loss: 0.012786442646756768 - Val Accuracy: 0.752\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.007913119159638882\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.0074261101894080635 - Train Accuracy: 0.8491071428571428\n",
            "\t\t\tVal Loss: 0.016830394277349114 - Val Accuracy: 0.724\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1050, Loss 0.007013299502432346\n",
            "\t\tTrain step - Step 1080, Loss 0.009168577380478382\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.007132834289222956 - Train Accuracy: 0.8598214285714286\n",
            "\t\t\tVal Loss: 0.015668313018977642 - Val Accuracy: 0.702\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.0066611687652766705\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.00703598799716149 - Train Accuracy: 0.8647321428571428\n",
            "\t\t\tVal Loss: 0.014637224143370986 - Val Accuracy: 0.716\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.009747743606567383\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.00641430372904454 - Train Accuracy: 0.8774553571428572\n",
            "\t\t\tVal Loss: 0.012623416841961443 - Val Accuracy: 0.746\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.005788648966699839\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.006460828467139176 - Train Accuracy: 0.8761160714285714\n",
            "\t\t\tVal Loss: 0.012187206884846091 - Val Accuracy: 0.76\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1200, Loss 0.009219272062182426\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.006239243689924479 - Train Accuracy: 0.8852678571428572\n",
            "\t\t\tVal Loss: 0.01430187956430018 - Val Accuracy: 0.75\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.005008589010685682\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.006094410789332219 - Train Accuracy: 0.8808035714285715\n",
            "\t\t\tVal Loss: 0.013235061196610332 - Val Accuracy: 0.756\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.00545885507017374\n",
            "\t\tTrain step - Step 1290, Loss 0.005521691404283047\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.005690258521852749 - Train Accuracy: 0.8924107142857143\n",
            "\t\t\tVal Loss: 0.016133340075612068 - Val Accuracy: 0.708\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1320, Loss 0.007222488522529602\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.006281753376658474 - Train Accuracy: 0.8794642857142857\n",
            "\t\t\tVal Loss: 0.014655152335762978 - Val Accuracy: 0.752\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.004612871911376715\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.005410319393766778 - Train Accuracy: 0.9004464285714285\n",
            "\t\t\tVal Loss: 0.01284597790800035 - Val Accuracy: 0.758\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.003882437478750944\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.005454031830387456 - Train Accuracy: 0.8975446428571429\n",
            "\t\t\tVal Loss: 0.013813169207423925 - Val Accuracy: 0.748\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.003983017522841692\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.00521737865970603 - Train Accuracy: 0.9017857142857143\n",
            "\t\t\tVal Loss: 0.010893358383327723 - Val Accuracy: 0.79\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1440, Loss 0.004261801950633526\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.00466919791485582 - Train Accuracy: 0.9149553571428571\n",
            "\t\t\tVal Loss: 0.017431808868423104 - Val Accuracy: 0.714\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.003772687166929245\n",
            "\t\tTrain step - Step 1500, Loss 0.004402929916977882\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.005061690269836358 - Train Accuracy: 0.9060267857142857\n",
            "\t\t\tVal Loss: 0.011349264183081686 - Val Accuracy: 0.802\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.00614391453564167\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.005174580469195332 - Train Accuracy: 0.9037946428571428\n",
            "\t\t\tVal Loss: 0.015543923480436206 - Val Accuracy: 0.74\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.005333770997822285\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.00493638456932136 - Train Accuracy: 0.9089285714285714\n",
            "\t\t\tVal Loss: 0.01663584541529417 - Val Accuracy: 0.694\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1590, Loss 0.0033425018191337585\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.004953560372814536 - Train Accuracy: 0.9060267857142857\n",
            "\t\t\tVal Loss: 0.012644689995795488 - Val Accuracy: 0.766\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.005397322587668896\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.00443437293704067 - Train Accuracy: 0.9198660714285715\n",
            "\t\t\tVal Loss: 0.011220798129215837 - Val Accuracy: 0.78\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.0027784311678260565\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.004043022370232003 - Train Accuracy: 0.9283482142857142\n",
            "\t\t\tVal Loss: 0.012405151384882629 - Val Accuracy: 0.792\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.004165989812463522\n",
            "\t\tTrain step - Step 1710, Loss 0.006838539149612188\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.004420192932177867 - Train Accuracy: 0.9154017857142858\n",
            "\t\t\tVal Loss: 0.015353039838373661 - Val Accuracy: 0.768\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1740, Loss 0.0018097851425409317\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.003335531222234879 - Train Accuracy: 0.9395089285714285\n",
            "\t\t\tVal Loss: 0.008273817133158445 - Val Accuracy: 0.858\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1770, Loss 0.0017896988429129124\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.002295448268497629 - Train Accuracy: 0.9636160714285714\n",
            "\t\t\tVal Loss: 0.007638151990249753 - Val Accuracy: 0.868\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1800, Loss 0.0017063936684280634\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.0018457897972049457 - Train Accuracy: 0.9743303571428571\n",
            "\t\t\tVal Loss: 0.007935407338663936 - Val Accuracy: 0.844\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1830, Loss 0.0016226540319621563\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.001678071091217654 - Train Accuracy: 0.9770089285714286\n",
            "\t\t\tVal Loss: 0.008713099756278098 - Val Accuracy: 0.846\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1860, Loss 0.002078151097521186\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.0015834571394537176 - Train Accuracy: 0.9763392857142857\n",
            "\t\t\tVal Loss: 0.008220649440772831 - Val Accuracy: 0.868\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1890, Loss 0.0015732976607978344\n",
            "\t\tTrain step - Step 1920, Loss 0.0014428016729652882\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.0016670993678937 - Train Accuracy: 0.9770089285714286\n",
            "\t\t\tVal Loss: 0.008044296293519437 - Val Accuracy: 0.862\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.0025587044656276703\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.0014739623609265047 - Train Accuracy: 0.9819196428571428\n",
            "\t\t\tVal Loss: 0.00788225163705647 - Val Accuracy: 0.858\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1980, Loss 0.001427693641744554\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.001449498818588576 - Train Accuracy: 0.9790178571428572\n",
            "\t\t\tVal Loss: 0.008632997400127351 - Val Accuracy: 0.85\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.0009228014969266951\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.001329366857784667 - Train Accuracy: 0.9828125\n",
            "\t\t\tVal Loss: 0.00864425441250205 - Val Accuracy: 0.866\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.0015779193490743637\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.001270381361246109 - Train Accuracy: 0.9825892857142857\n",
            "\t\t\tVal Loss: 0.008598703308962286 - Val Accuracy: 0.868\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.0008463902631774545\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.0011716333783364722 - Train Accuracy: 0.9852678571428571\n",
            "\t\t\tVal Loss: 0.00892144872341305 - Val Accuracy: 0.852\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2100, Loss 0.0012788146268576384\n",
            "\t\tTrain step - Step 2130, Loss 0.0010973097523674369\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.001191385354780193 - Train Accuracy: 0.9859375\n",
            "\t\t\tVal Loss: 0.00921690696850419 - Val Accuracy: 0.85\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.001543316524475813\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.001120022073986807 - Train Accuracy: 0.9861607142857143\n",
            "\t\t\tVal Loss: 0.007976904162205756 - Val Accuracy: 0.874\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.001890651066787541\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.0010725618938782384 - Train Accuracy: 0.9870535714285714\n",
            "\t\t\tVal Loss: 0.00829657749272883 - Val Accuracy: 0.866\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2220, Loss 0.0008171196095645428\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.000929542224288785 - Train Accuracy: 0.9908482142857142\n",
            "\t\t\tVal Loss: 0.008036225801333785 - Val Accuracy: 0.864\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2250, Loss 0.0008316859602928162\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.0008900208781207246 - Train Accuracy: 0.9917410714285714\n",
            "\t\t\tVal Loss: 0.00927021587267518 - Val Accuracy: 0.85\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2280, Loss 0.0010994150070473552\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.0008524209452194295 - Train Accuracy: 0.9912946428571429\n",
            "\t\t\tVal Loss: 0.009432291146367788 - Val Accuracy: 0.846\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2310, Loss 0.0010489706182852387\n",
            "\t\tTrain step - Step 2340, Loss 0.0008386856643483043\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.00093769636504086 - Train Accuracy: 0.9899553571428571\n",
            "\t\t\tVal Loss: 0.009325782768428326 - Val Accuracy: 0.848\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2370, Loss 0.000534599821548909\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.0008626433172529297 - Train Accuracy: 0.9915178571428571\n",
            "\t\t\tVal Loss: 0.009372640517540276 - Val Accuracy: 0.842\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2400, Loss 0.00047128237201832235\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.000926479887649683 - Train Accuracy: 0.9904017857142857\n",
            "\t\t\tVal Loss: 0.00846882350742817 - Val Accuracy: 0.876\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2430, Loss 0.0012643066002056003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.000863638989228223 - Train Accuracy: 0.9919642857142857\n",
            "\t\t\tVal Loss: 0.008587801246903837 - Val Accuracy: 0.872\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 16.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 1:\n",
            "\t\tTrain Mean Accuracy: 0.8357174744897958\n",
            "\t\tVal Mean Accuracy: 0.7198571428571428\n",
            "\t\tTest Accuracy: 0.849\n",
            "\n",
            "STARTING FINE TUNING STAGE 2...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.0407659150660038\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.06090020388364792 - Train Accuracy: 0.09866071428571428\n",
            "\t\t\tVal Loss: 0.04504810553044081 - Val Accuracy: 0.206\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.036608848720788956\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.03556331204516547 - Train Accuracy: 0.36227678571428573\n",
            "\t\t\tVal Loss: 0.03568358113989234 - Val Accuracy: 0.322\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.029329899698495865\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.03119640222617558 - Train Accuracy: 0.4381696428571429\n",
            "\t\t\tVal Loss: 0.031131264753639698 - Val Accuracy: 0.442\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.032339856028556824\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.02892651983669826 - Train Accuracy: 0.5017857142857143\n",
            "\t\t\tVal Loss: 0.031570179387927055 - Val Accuracy: 0.462\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 150, Loss 0.026306750252842903\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.027717754989862443 - Train Accuracy: 0.5408482142857143\n",
            "\t\t\tVal Loss: 0.028658011928200722 - Val Accuracy: 0.506\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.02865009196102619\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.027018524866018977 - Train Accuracy: 0.5607142857142857\n",
            "\t\t\tVal Loss: 0.028387564700096846 - Val Accuracy: 0.53\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.026132434606552124\n",
            "\t\tTrain step - Step 240, Loss 0.0256672203540802\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.02571915366819927 - Train Accuracy: 0.5993303571428571\n",
            "\t\t\tVal Loss: 0.027947736904025078 - Val Accuracy: 0.508\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 270, Loss 0.02632543258368969\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.024854489735194614 - Train Accuracy: 0.6154017857142857\n",
            "\t\t\tVal Loss: 0.030227696057409048 - Val Accuracy: 0.53\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.025152908638119698\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.02456782263304506 - Train Accuracy: 0.6377232142857143\n",
            "\t\t\tVal Loss: 0.026409021578729153 - Val Accuracy: 0.622\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.022758835926651955\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.023701903011117662 - Train Accuracy: 0.6667410714285714\n",
            "\t\t\tVal Loss: 0.02740759588778019 - Val Accuracy: 0.592\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.02169937640428543\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.023062215479356902 - Train Accuracy: 0.6941964285714286\n",
            "\t\t\tVal Loss: 0.026557616889476776 - Val Accuracy: 0.592\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.021531201899051666\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.022940824234059878 - Train Accuracy: 0.6908482142857143\n",
            "\t\t\tVal Loss: 0.02866213209927082 - Val Accuracy: 0.574\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 420, Loss 0.023913297802209854\n",
            "\t\tTrain step - Step 450, Loss 0.023772604763507843\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.02242556858275618 - Train Accuracy: 0.6886160714285714\n",
            "\t\t\tVal Loss: 0.026506201829761267 - Val Accuracy: 0.636\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.022474421188235283\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.02221099824777671 - Train Accuracy: 0.7075892857142857\n",
            "\t\t\tVal Loss: 0.026743032038211823 - Val Accuracy: 0.642\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.020898915827274323\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.021500805392861366 - Train Accuracy: 0.7252232142857142\n",
            "\t\t\tVal Loss: 0.02579372003674507 - Val Accuracy: 0.668\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 540, Loss 0.01943456381559372\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.021416899615100453 - Train Accuracy: 0.7305803571428572\n",
            "\t\t\tVal Loss: 0.028744579292833805 - Val Accuracy: 0.64\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.022296061739325523\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.020791430664913995 - Train Accuracy: 0.7379464285714286\n",
            "\t\t\tVal Loss: 0.025319545529782772 - Val Accuracy: 0.68\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.023204872384667397\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.020579655681337627 - Train Accuracy: 0.7450892857142857\n",
            "\t\t\tVal Loss: 0.02959196548908949 - Val Accuracy: 0.598\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.019927192479372025\n",
            "\t\tTrain step - Step 660, Loss 0.020080285146832466\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.020445114001631737 - Train Accuracy: 0.7497767857142857\n",
            "\t\t\tVal Loss: 0.027475972194224596 - Val Accuracy: 0.652\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.02268311195075512\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.02022051066160202 - Train Accuracy: 0.7598214285714285\n",
            "\t\t\tVal Loss: 0.02726769633591175 - Val Accuracy: 0.654\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.01954474486410618\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.019198671568717275 - Train Accuracy: 0.7796875\n",
            "\t\t\tVal Loss: 0.029629855882376432 - Val Accuracy: 0.668\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.018852150067687035\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.01968667996781213 - Train Accuracy: 0.759375\n",
            "\t\t\tVal Loss: 0.026724184397608042 - Val Accuracy: 0.678\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.019795214757323265\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.019102884456515312 - Train Accuracy: 0.7816964285714286\n",
            "\t\t\tVal Loss: 0.027932477183640003 - Val Accuracy: 0.64\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 810, Loss 0.02030263841152191\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.019152579403349333 - Train Accuracy: 0.778125\n",
            "\t\t\tVal Loss: 0.027048188727349043 - Val Accuracy: 0.626\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.019203871488571167\n",
            "\t\tTrain step - Step 870, Loss 0.0199885293841362\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.019272387826016972 - Train Accuracy: 0.7912946428571429\n",
            "\t\t\tVal Loss: 0.028912678360939026 - Val Accuracy: 0.64\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.019758904352784157\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.01907869976546083 - Train Accuracy: 0.7930803571428572\n",
            "\t\t\tVal Loss: 0.027769545558840036 - Val Accuracy: 0.68\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 930, Loss 0.02065115235745907\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.01903072004871709 - Train Accuracy: 0.7948660714285715\n",
            "\t\t\tVal Loss: 0.0258779707364738 - Val Accuracy: 0.698\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.018714815378189087\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.018722272344997952 - Train Accuracy: 0.8026785714285715\n",
            "\t\t\tVal Loss: 0.029596037697046995 - Val Accuracy: 0.664\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.018552016466856003\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.018881522385137423 - Train Accuracy: 0.8055803571428571\n",
            "\t\t\tVal Loss: 0.0278784092515707 - Val Accuracy: 0.648\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.01804267056286335\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.01790441716355937 - Train Accuracy: 0.8149553571428572\n",
            "\t\t\tVal Loss: 0.02778687421232462 - Val Accuracy: 0.674\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1050, Loss 0.01551593467593193\n",
            "\t\tTrain step - Step 1080, Loss 0.016997145488858223\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.01748572380415031 - Train Accuracy: 0.8209821428571429\n",
            "\t\t\tVal Loss: 0.027684324886649847 - Val Accuracy: 0.684\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.01753394864499569\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.017626013553568295 - Train Accuracy: 0.8205357142857143\n",
            "\t\t\tVal Loss: 0.027165696490556 - Val Accuracy: 0.694\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.01732037402689457\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.017529579624533654 - Train Accuracy: 0.8305803571428572\n",
            "\t\t\tVal Loss: 0.02768447808921337 - Val Accuracy: 0.674\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.018193479627370834\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.017452477025134222 - Train Accuracy: 0.8200892857142857\n",
            "\t\t\tVal Loss: 0.029663960449397564 - Val Accuracy: 0.696\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1200, Loss 0.01820261962711811\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.017373036433543477 - Train Accuracy: 0.8310267857142857\n",
            "\t\t\tVal Loss: 0.030961208511143923 - Val Accuracy: 0.668\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.017591988667845726\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.017014560369508606 - Train Accuracy: 0.8339285714285715\n",
            "\t\t\tVal Loss: 0.032010063994675875 - Val Accuracy: 0.664\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.017967695370316505\n",
            "\t\tTrain step - Step 1290, Loss 0.016822511330246925\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.017138784804514477 - Train Accuracy: 0.8372767857142858\n",
            "\t\t\tVal Loss: 0.028532991651445627 - Val Accuracy: 0.672\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1320, Loss 0.019166745245456696\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.016998713224061896 - Train Accuracy: 0.8475446428571428\n",
            "\t\t\tVal Loss: 0.03194944467395544 - Val Accuracy: 0.642\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.01780938357114792\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.016241045748548847 - Train Accuracy: 0.846875\n",
            "\t\t\tVal Loss: 0.028925583697855473 - Val Accuracy: 0.688\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.01593739539384842\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.016680294541375977 - Train Accuracy: 0.853125\n",
            "\t\t\tVal Loss: 0.026464687194675207 - Val Accuracy: 0.752\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.01620115153491497\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.016955071607870714 - Train Accuracy: 0.8415178571428571\n",
            "\t\t\tVal Loss: 0.028410821687430143 - Val Accuracy: 0.71\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1440, Loss 0.015939926728606224\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.016080269270709584 - Train Accuracy: 0.859375\n",
            "\t\t\tVal Loss: 0.0282167075201869 - Val Accuracy: 0.704\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.015050441958010197\n",
            "\t\tTrain step - Step 1500, Loss 0.01735968142747879\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.016467883890228612 - Train Accuracy: 0.8502232142857142\n",
            "\t\t\tVal Loss: 0.02654131967574358 - Val Accuracy: 0.69\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.015759486705064774\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.016378029808402063 - Train Accuracy: 0.8535714285714285\n",
            "\t\t\tVal Loss: 0.02595939626917243 - Val Accuracy: 0.748\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.015511841513216496\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.015252685653311865 - Train Accuracy: 0.8839285714285714\n",
            "\t\t\tVal Loss: 0.029901019297540188 - Val Accuracy: 0.682\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1590, Loss 0.013026801869273186\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.01584889976573842 - Train Accuracy: 0.8645089285714286\n",
            "\t\t\tVal Loss: 0.02503830846399069 - Val Accuracy: 0.756\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.016260594129562378\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.01571406213832753 - Train Accuracy: 0.8752232142857143\n",
            "\t\t\tVal Loss: 0.027622492518275976 - Val Accuracy: 0.696\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.014667659997940063\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.01660650856792927 - Train Accuracy: 0.8569196428571428\n",
            "\t\t\tVal Loss: 0.028251553419977427 - Val Accuracy: 0.726\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.016380054876208305\n",
            "\t\tTrain step - Step 1710, Loss 0.014431375078856945\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.01576291272150619 - Train Accuracy: 0.8694196428571429\n",
            "\t\t\tVal Loss: 0.028274521697312593 - Val Accuracy: 0.69\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1740, Loss 0.013387970626354218\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.01387709557477917 - Train Accuracy: 0.8926339285714285\n",
            "\t\t\tVal Loss: 0.023413924500346184 - Val Accuracy: 0.788\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1770, Loss 0.012641651555895805\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.012517547447766576 - Train Accuracy: 0.9058035714285714\n",
            "\t\t\tVal Loss: 0.025782917626202106 - Val Accuracy: 0.754\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1800, Loss 0.011479967273771763\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.012151461653411388 - Train Accuracy: 0.9223214285714286\n",
            "\t\t\tVal Loss: 0.02453336538746953 - Val Accuracy: 0.778\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1830, Loss 0.011162723414599895\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.011938302511615413 - Train Accuracy: 0.921875\n",
            "\t\t\tVal Loss: 0.025299481116235256 - Val Accuracy: 0.756\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1860, Loss 0.011690487153828144\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.011773844302764961 - Train Accuracy: 0.9160714285714285\n",
            "\t\t\tVal Loss: 0.024241737090051174 - Val Accuracy: 0.776\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1890, Loss 0.011430551297962666\n",
            "\t\tTrain step - Step 1920, Loss 0.010717980563640594\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.01168378721922636 - Train Accuracy: 0.9165178571428572\n",
            "\t\t\tVal Loss: 0.0249266573227942 - Val Accuracy: 0.774\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.01065419614315033\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.011481775982039316 - Train Accuracy: 0.9183035714285714\n",
            "\t\t\tVal Loss: 0.024827116634696722 - Val Accuracy: 0.77\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1980, Loss 0.011630011722445488\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.011591258059654917 - Train Accuracy: 0.9229910714285714\n",
            "\t\t\tVal Loss: 0.024489375296980143 - Val Accuracy: 0.772\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.010161280632019043\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.01144958609449012 - Train Accuracy: 0.9154017857142858\n",
            "\t\t\tVal Loss: 0.02464619977399707 - Val Accuracy: 0.782\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.012192489579319954\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.011513114560927663 - Train Accuracy: 0.9227678571428571\n",
            "\t\t\tVal Loss: 0.025621061213314533 - Val Accuracy: 0.772\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.011228203773498535\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.011130279595298427 - Train Accuracy: 0.9252232142857143\n",
            "\t\t\tVal Loss: 0.02645496977493167 - Val Accuracy: 0.756\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2100, Loss 0.011187217198312283\n",
            "\t\tTrain step - Step 2130, Loss 0.011540457606315613\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.011284330567078931 - Train Accuracy: 0.9258928571428572\n",
            "\t\t\tVal Loss: 0.02636416256427765 - Val Accuracy: 0.778\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.01098451018333435\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.011116209706025464 - Train Accuracy: 0.9232142857142858\n",
            "\t\t\tVal Loss: 0.026854010298848152 - Val Accuracy: 0.752\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.011403021402657032\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.01117973058883633 - Train Accuracy: 0.9290178571428571\n",
            "\t\t\tVal Loss: 0.02588976128026843 - Val Accuracy: 0.778\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2220, Loss 0.010093106888234615\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.010917182719068868 - Train Accuracy: 0.9236607142857143\n",
            "\t\t\tVal Loss: 0.026122755836695433 - Val Accuracy: 0.782\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2250, Loss 0.011345102451741695\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.01075460333377123 - Train Accuracy: 0.9247767857142857\n",
            "\t\t\tVal Loss: 0.02539461152628064 - Val Accuracy: 0.772\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2280, Loss 0.010007185861468315\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.010632148810795375 - Train Accuracy: 0.9290178571428571\n",
            "\t\t\tVal Loss: 0.026569263078272343 - Val Accuracy: 0.78\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2310, Loss 0.010560564696788788\n",
            "\t\tTrain step - Step 2340, Loss 0.011452455073595047\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.010778008960187435 - Train Accuracy: 0.9292410714285714\n",
            "\t\t\tVal Loss: 0.026112878695130348 - Val Accuracy: 0.776\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2370, Loss 0.010890893638134003\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.01073559011731829 - Train Accuracy: 0.9339285714285714\n",
            "\t\t\tVal Loss: 0.02675697486847639 - Val Accuracy: 0.762\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2400, Loss 0.011083578690886497\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.010664933068411691 - Train Accuracy: 0.9252232142857143\n",
            "\t\t\tVal Loss: 0.025691159069538116 - Val Accuracy: 0.766\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2430, Loss 0.010940470732748508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/16 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.010697228913860662 - Train Accuracy: 0.9290178571428571\n",
            "\t\t\tVal Loss: 0.026209763251245022 - Val Accuracy: 0.772\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:00<00:00, 20.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 2:\n",
            "\t\tTrain Mean Accuracy: 0.7943176020408165\n",
            "\t\tVal Mean Accuracy: 0.6729142857142857\n",
            "\t\tTest Accuracy: 0.6995\n",
            "\n",
            "STARTING FINE TUNING STAGE 3...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.04904147982597351\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.06349315089838846 - Train Accuracy: 0.03236607142857143\n",
            "\t\t\tVal Loss: 0.06493940018117428 - Val Accuracy: 0.168\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.043926239013671875\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.046062731529985156 - Train Accuracy: 0.19508928571428572\n",
            "\t\t\tVal Loss: 0.055649057030677795 - Val Accuracy: 0.2\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.042305152863264084\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.04213668352791241 - Train Accuracy: 0.275\n",
            "\t\t\tVal Loss: 0.05140100698918104 - Val Accuracy: 0.25\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.041357483714818954\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.04053701726453645 - Train Accuracy: 0.30848214285714287\n",
            "\t\t\tVal Loss: 0.049893563613295555 - Val Accuracy: 0.324\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 150, Loss 0.03863246366381645\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.039515034109354016 - Train Accuracy: 0.3488839285714286\n",
            "\t\t\tVal Loss: 0.048267634585499763 - Val Accuracy: 0.326\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.03991638869047165\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.03895053480352674 - Train Accuracy: 0.3888392857142857\n",
            "\t\t\tVal Loss: 0.047227248549461365 - Val Accuracy: 0.368\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.040781326591968536\n",
            "\t\tTrain step - Step 240, Loss 0.03781033307313919\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.03821983284183911 - Train Accuracy: 0.421875\n",
            "\t\t\tVal Loss: 0.0461789621040225 - Val Accuracy: 0.392\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 270, Loss 0.03808237612247467\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.037490292532103404 - Train Accuracy: 0.44441964285714286\n",
            "\t\t\tVal Loss: 0.045643165707588196 - Val Accuracy: 0.408\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.038255684077739716\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.03726440082703318 - Train Accuracy: 0.4602678571428571\n",
            "\t\t\tVal Loss: 0.045204740948975086 - Val Accuracy: 0.406\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.03549880534410477\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.037262426848922454 - Train Accuracy: 0.47120535714285716\n",
            "\t\t\tVal Loss: 0.04676888231188059 - Val Accuracy: 0.424\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.03348016366362572\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.03609445126993316 - Train Accuracy: 0.5029017857142857\n",
            "\t\t\tVal Loss: 0.04625088255852461 - Val Accuracy: 0.426\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.03507573902606964\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.03535593929035323 - Train Accuracy: 0.5234375\n",
            "\t\t\tVal Loss: 0.04430296178907156 - Val Accuracy: 0.446\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 420, Loss 0.03771274909377098\n",
            "\t\tTrain step - Step 450, Loss 0.0348823219537735\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.03567069609250341 - Train Accuracy: 0.5421875\n",
            "\t\t\tVal Loss: 0.04571608453989029 - Val Accuracy: 0.482\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.035714782774448395\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.0353823823588235 - Train Accuracy: 0.5477678571428571\n",
            "\t\t\tVal Loss: 0.04755475465208292 - Val Accuracy: 0.48\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.03364947810769081\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.03522021791764668 - Train Accuracy: 0.5729910714285714\n",
            "\t\t\tVal Loss: 0.044650016352534294 - Val Accuracy: 0.49\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 540, Loss 0.03271374851465225\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.034970710373350554 - Train Accuracy: 0.5861607142857143\n",
            "\t\t\tVal Loss: 0.04782218858599663 - Val Accuracy: 0.51\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.03405864164233208\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.034082747676542825 - Train Accuracy: 0.6006696428571429\n",
            "\t\t\tVal Loss: 0.04825392831116915 - Val Accuracy: 0.48\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.03242580592632294\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.03409680128097534 - Train Accuracy: 0.61875\n",
            "\t\t\tVal Loss: 0.044311936013400555 - Val Accuracy: 0.512\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.030629638582468033\n",
            "\t\tTrain step - Step 660, Loss 0.03572671860456467\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.033324141640748296 - Train Accuracy: 0.61875\n",
            "\t\t\tVal Loss: 0.046097492799162865 - Val Accuracy: 0.52\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.03357522934675217\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.03348419932382447 - Train Accuracy: 0.6310267857142857\n",
            "\t\t\tVal Loss: 0.04736933205276728 - Val Accuracy: 0.502\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.033146459609270096\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.03321157002023288 - Train Accuracy: 0.6383928571428571\n",
            "\t\t\tVal Loss: 0.04612265061587095 - Val Accuracy: 0.538\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.03194495663046837\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.032788447556751116 - Train Accuracy: 0.6602678571428572\n",
            "\t\t\tVal Loss: 0.04691364150494337 - Val Accuracy: 0.512\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.035683464258909225\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.03283919234360967 - Train Accuracy: 0.66875\n",
            "\t\t\tVal Loss: 0.04624599777162075 - Val Accuracy: 0.51\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 810, Loss 0.03171543404459953\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.03191673878048148 - Train Accuracy: 0.6866071428571429\n",
            "\t\t\tVal Loss: 0.04279774893075228 - Val Accuracy: 0.578\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.029599184170365334\n",
            "\t\tTrain step - Step 870, Loss 0.03290179744362831\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.03176699323313577 - Train Accuracy: 0.6973214285714285\n",
            "\t\t\tVal Loss: 0.04934766888618469 - Val Accuracy: 0.542\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.032736886292696\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.03225231154688767 - Train Accuracy: 0.6854910714285715\n",
            "\t\t\tVal Loss: 0.04710864927619696 - Val Accuracy: 0.52\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 930, Loss 0.031150445342063904\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.03189961830420154 - Train Accuracy: 0.7033482142857143\n",
            "\t\t\tVal Loss: 0.0434413542971015 - Val Accuracy: 0.582\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.029405392706394196\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.0318966347192015 - Train Accuracy: 0.6993303571428572\n",
            "\t\t\tVal Loss: 0.04965179692953825 - Val Accuracy: 0.52\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.035479795187711716\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.03192459493875503 - Train Accuracy: 0.7069196428571428\n",
            "\t\t\tVal Loss: 0.04322280641645193 - Val Accuracy: 0.568\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.030839256942272186\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.03180377281137875 - Train Accuracy: 0.7066964285714286\n",
            "\t\t\tVal Loss: 0.04561625048518181 - Val Accuracy: 0.59\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1050, Loss 0.02970734052360058\n",
            "\t\tTrain step - Step 1080, Loss 0.031491003930568695\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.03113063376929079 - Train Accuracy: 0.7258928571428571\n",
            "\t\t\tVal Loss: 0.04079963359981775 - Val Accuracy: 0.602\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.033172763884067535\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.03172440241490092 - Train Accuracy: 0.7296875\n",
            "\t\t\tVal Loss: 0.04621157702058554 - Val Accuracy: 0.518\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.030666746199131012\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.03111438639461994 - Train Accuracy: 0.7299107142857143\n",
            "\t\t\tVal Loss: 0.04726958181709051 - Val Accuracy: 0.534\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.030294299125671387\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.030730534185256276 - Train Accuracy: 0.7404017857142857\n",
            "\t\t\tVal Loss: 0.04645164683461189 - Val Accuracy: 0.558\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1200, Loss 0.02680579200387001\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.030287900833146912 - Train Accuracy: 0.7600446428571429\n",
            "\t\t\tVal Loss: 0.04335452802479267 - Val Accuracy: 0.588\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.0289633609354496\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.03078987252499376 - Train Accuracy: 0.7486607142857142\n",
            "\t\t\tVal Loss: 0.04328883346170187 - Val Accuracy: 0.57\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.030923865735530853\n",
            "\t\tTrain step - Step 1290, Loss 0.029799597337841988\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.03012497169630868 - Train Accuracy: 0.7662946428571429\n",
            "\t\t\tVal Loss: 0.044104584492743015 - Val Accuracy: 0.584\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1320, Loss 0.028615057468414307\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.029987443132059914 - Train Accuracy: 0.7671875\n",
            "\t\t\tVal Loss: 0.04475035239011049 - Val Accuracy: 0.578\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.029103683307766914\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.029383524400847297 - Train Accuracy: 0.7805803571428571\n",
            "\t\t\tVal Loss: 0.049109204672276974 - Val Accuracy: 0.56\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.02809828147292137\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.029612926553402627 - Train Accuracy: 0.7665178571428571\n",
            "\t\t\tVal Loss: 0.04622272867709398 - Val Accuracy: 0.586\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.02824915573000908\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.029751696650471005 - Train Accuracy: 0.7727678571428571\n",
            "\t\t\tVal Loss: 0.044119592756032944 - Val Accuracy: 0.6\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1440, Loss 0.029170308262109756\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.029096634047372002 - Train Accuracy: 0.7857142857142857\n",
            "\t\t\tVal Loss: 0.04591338895261288 - Val Accuracy: 0.618\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.029245024546980858\n",
            "\t\tTrain step - Step 1500, Loss 0.02876574918627739\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.029337273697767938 - Train Accuracy: 0.7919642857142857\n",
            "\t\t\tVal Loss: 0.05043038912117481 - Val Accuracy: 0.554\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.028045086190104485\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.02912420965731144 - Train Accuracy: 0.7988839285714285\n",
            "\t\t\tVal Loss: 0.048760950565338135 - Val Accuracy: 0.564\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.028850072994828224\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.02877752876707486 - Train Accuracy: 0.8082589285714286\n",
            "\t\t\tVal Loss: 0.048913897946476936 - Val Accuracy: 0.604\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1590, Loss 0.029062271118164062\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.029152909240552357 - Train Accuracy: 0.7959821428571429\n",
            "\t\t\tVal Loss: 0.04955414216965437 - Val Accuracy: 0.582\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.03089059330523014\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.029293632507324217 - Train Accuracy: 0.7991071428571429\n",
            "\t\t\tVal Loss: 0.047327665612101555 - Val Accuracy: 0.59\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.028497843071818352\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.0293744365551642 - Train Accuracy: 0.8020089285714286\n",
            "\t\t\tVal Loss: 0.04644535016268492 - Val Accuracy: 0.588\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.028062090277671814\n",
            "\t\tTrain step - Step 1710, Loss 0.0285345446318388\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.029307815805077554 - Train Accuracy: 0.8020089285714286\n",
            "\t\t\tVal Loss: 0.04941052943468094 - Val Accuracy: 0.544\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1740, Loss 0.024489521980285645\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.026433797925710677 - Train Accuracy: 0.8415178571428571\n",
            "\t\t\tVal Loss: 0.04237836133688688 - Val Accuracy: 0.638\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1770, Loss 0.02372077852487564\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.02472494031701769 - Train Accuracy: 0.8616071428571429\n",
            "\t\t\tVal Loss: 0.04363079648464918 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1800, Loss 0.023863358423113823\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.024387076922825403 - Train Accuracy: 0.8580357142857142\n",
            "\t\t\tVal Loss: 0.04438465274870396 - Val Accuracy: 0.626\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1830, Loss 0.023837778717279434\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.0240733481411423 - Train Accuracy: 0.8720982142857143\n",
            "\t\t\tVal Loss: 0.04380737617611885 - Val Accuracy: 0.652\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1860, Loss 0.024083487689495087\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.023638399317860603 - Train Accuracy: 0.8758928571428571\n",
            "\t\t\tVal Loss: 0.04550900589674711 - Val Accuracy: 0.62\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1890, Loss 0.022585982456803322\n",
            "\t\tTrain step - Step 1920, Loss 0.022850260138511658\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.023660625304494587 - Train Accuracy: 0.8741071428571429\n",
            "\t\t\tVal Loss: 0.04550094157457352 - Val Accuracy: 0.636\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.024625714868307114\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.02349881897015231 - Train Accuracy: 0.8689732142857143\n",
            "\t\t\tVal Loss: 0.04575053043663502 - Val Accuracy: 0.626\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1980, Loss 0.022221708670258522\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.023417929506727626 - Train Accuracy: 0.8716517857142857\n",
            "\t\t\tVal Loss: 0.04610463231801987 - Val Accuracy: 0.64\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.025590747594833374\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.023318471440247127 - Train Accuracy: 0.8709821428571428\n",
            "\t\t\tVal Loss: 0.04571802634745836 - Val Accuracy: 0.626\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.022054161876440048\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.023116059441651616 - Train Accuracy: 0.8754464285714286\n",
            "\t\t\tVal Loss: 0.047528959810733795 - Val Accuracy: 0.614\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.0220505241304636\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.02322509198316506 - Train Accuracy: 0.8767857142857143\n",
            "\t\t\tVal Loss: 0.045642148703336716 - Val Accuracy: 0.624\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2100, Loss 0.02211400307714939\n",
            "\t\tTrain step - Step 2130, Loss 0.02343512512743473\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.023053297932658878 - Train Accuracy: 0.8779017857142857\n",
            "\t\t\tVal Loss: 0.04707234911620617 - Val Accuracy: 0.628\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.02334974706172943\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.022905279695987702 - Train Accuracy: 0.8787946428571428\n",
            "\t\t\tVal Loss: 0.047583021223545074 - Val Accuracy: 0.632\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.022050946950912476\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.02271681906921523 - Train Accuracy: 0.86875\n",
            "\t\t\tVal Loss: 0.04613993689417839 - Val Accuracy: 0.61\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2220, Loss 0.023409651592373848\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.022605415540082115 - Train Accuracy: 0.8879464285714286\n",
            "\t\t\tVal Loss: 0.04567118361592293 - Val Accuracy: 0.624\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2250, Loss 0.022211918607354164\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.022712268254586627 - Train Accuracy: 0.8841517857142858\n",
            "\t\t\tVal Loss: 0.04586044792085886 - Val Accuracy: 0.65\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2280, Loss 0.022050626575946808\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.022411700231688363 - Train Accuracy: 0.8861607142857143\n",
            "\t\t\tVal Loss: 0.046525864861905575 - Val Accuracy: 0.648\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2310, Loss 0.023338427767157555\n",
            "\t\tTrain step - Step 2340, Loss 0.023264016956090927\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.022434739236320767 - Train Accuracy: 0.8921875\n",
            "\t\t\tVal Loss: 0.046676076017320156 - Val Accuracy: 0.622\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2370, Loss 0.024485226720571518\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.022485751871551787 - Train Accuracy: 0.8888392857142857\n",
            "\t\t\tVal Loss: 0.04659893736243248 - Val Accuracy: 0.616\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2400, Loss 0.022381912916898727\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.022395482659339903 - Train Accuracy: 0.8895089285714286\n",
            "\t\t\tVal Loss: 0.04773715045303106 - Val Accuracy: 0.608\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2430, Loss 0.021717175841331482\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/24 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.022561501658388546 - Train Accuracy: 0.8877232142857143\n",
            "\t\t\tVal Loss: 0.04718276858329773 - Val Accuracy: 0.638\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [00:01<00:00, 22.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 3:\n",
            "\t\tTrain Mean Accuracy: 0.7000733418367348\n",
            "\t\tVal Mean Accuracy: 0.5389999999999998\n",
            "\t\tTest Accuracy: 0.604\n",
            "\n",
            "STARTING FINE TUNING STAGE 4...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.060864612460136414\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.0721652871796063 - Train Accuracy: 0.03549107142857143\n",
            "\t\t\tVal Loss: 0.07442129217088223 - Val Accuracy: 0.12\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.05651111528277397\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.056672750094107216 - Train Accuracy: 0.15848214285714285\n",
            "\t\t\tVal Loss: 0.0651845708489418 - Val Accuracy: 0.224\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.05361726135015488\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.05318838762385505 - Train Accuracy: 0.2502232142857143\n",
            "\t\t\tVal Loss: 0.061346592381596565 - Val Accuracy: 0.274\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.05187741294503212\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.05130858602268355 - Train Accuracy: 0.30558035714285714\n",
            "\t\t\tVal Loss: 0.05991831608116627 - Val Accuracy: 0.31\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 150, Loss 0.048552170395851135\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.05001615190080234 - Train Accuracy: 0.3573660714285714\n",
            "\t\t\tVal Loss: 0.060717424377799034 - Val Accuracy: 0.316\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.05148330703377724\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.049543368497065136 - Train Accuracy: 0.39017857142857143\n",
            "\t\t\tVal Loss: 0.057696507312357426 - Val Accuracy: 0.352\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.05209427699446678\n",
            "\t\tTrain step - Step 240, Loss 0.05120113119482994\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.04900007556591715 - Train Accuracy: 0.41941964285714284\n",
            "\t\t\tVal Loss: 0.059853510931134224 - Val Accuracy: 0.352\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 270, Loss 0.04757465794682503\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.048458149603434975 - Train Accuracy: 0.44620535714285714\n",
            "\t\t\tVal Loss: 0.05883841868489981 - Val Accuracy: 0.408\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.046351414173841476\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.0477119365973132 - Train Accuracy: 0.4747767857142857\n",
            "\t\t\tVal Loss: 0.05981520842760801 - Val Accuracy: 0.4\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.043731097131967545\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.04754017272165843 - Train Accuracy: 0.5040178571428572\n",
            "\t\t\tVal Loss: 0.05788513645529747 - Val Accuracy: 0.424\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.045038480311632156\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.046725795205150335 - Train Accuracy: 0.5265625\n",
            "\t\t\tVal Loss: 0.05798166524618864 - Val Accuracy: 0.474\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.04547322168946266\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.04668129405805043 - Train Accuracy: 0.5417410714285714\n",
            "\t\t\tVal Loss: 0.05629814509302378 - Val Accuracy: 0.474\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 420, Loss 0.04652541130781174\n",
            "\t\tTrain step - Step 450, Loss 0.0447726845741272\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.04653816734041486 - Train Accuracy: 0.5609375\n",
            "\t\t\tVal Loss: 0.058766274712979794 - Val Accuracy: 0.486\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.04562351480126381\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.046328257237161906 - Train Accuracy: 0.5877232142857143\n",
            "\t\t\tVal Loss: 0.059331631287932396 - Val Accuracy: 0.48\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.04430653527379036\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.045887298669133866 - Train Accuracy: 0.5930803571428571\n",
            "\t\t\tVal Loss: 0.05537818651646376 - Val Accuracy: 0.534\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 540, Loss 0.04322468489408493\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.04563497996756009 - Train Accuracy: 0.6042410714285714\n",
            "\t\t\tVal Loss: 0.05823422409594059 - Val Accuracy: 0.504\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.04692549630999565\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.045830742589065006 - Train Accuracy: 0.6098214285714286\n",
            "\t\t\tVal Loss: 0.055637878365814686 - Val Accuracy: 0.53\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.046315260231494904\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.04520521770630564 - Train Accuracy: 0.6428571428571429\n",
            "\t\t\tVal Loss: 0.05518318712711334 - Val Accuracy: 0.556\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.04452166333794594\n",
            "\t\tTrain step - Step 660, Loss 0.04718610644340515\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.04498882272413799 - Train Accuracy: 0.6426339285714285\n",
            "\t\t\tVal Loss: 0.05831783264875412 - Val Accuracy: 0.512\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.045002032071352005\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.04481540960924966 - Train Accuracy: 0.6685267857142857\n",
            "\t\t\tVal Loss: 0.05899433791637421 - Val Accuracy: 0.52\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.045849986374378204\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.045047373111758916 - Train Accuracy: 0.6649553571428571\n",
            "\t\t\tVal Loss: 0.055679136887192726 - Val Accuracy: 0.516\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.04631483927369118\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.04471835674984115 - Train Accuracy: 0.6689732142857143\n",
            "\t\t\tVal Loss: 0.05704453960061073 - Val Accuracy: 0.556\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.046169307082891464\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.04446205369063786 - Train Accuracy: 0.6796875\n",
            "\t\t\tVal Loss: 0.05648995563387871 - Val Accuracy: 0.588\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 810, Loss 0.041525859385728836\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.04406131399529321 - Train Accuracy: 0.703125\n",
            "\t\t\tVal Loss: 0.057324064895510674 - Val Accuracy: 0.54\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.0443415530025959\n",
            "\t\tTrain step - Step 870, Loss 0.044041410088539124\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.044231098145246506 - Train Accuracy: 0.6959821428571429\n",
            "\t\t\tVal Loss: 0.05696605518460274 - Val Accuracy: 0.544\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.04469500109553337\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.04357195517846516 - Train Accuracy: 0.7174107142857142\n",
            "\t\t\tVal Loss: 0.057836310006678104 - Val Accuracy: 0.564\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 930, Loss 0.04298785701394081\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.04375600591301918 - Train Accuracy: 0.7151785714285714\n",
            "\t\t\tVal Loss: 0.06176969036459923 - Val Accuracy: 0.55\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.044210370630025864\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.04363015634672982 - Train Accuracy: 0.7216517857142857\n",
            "\t\t\tVal Loss: 0.06003082264214754 - Val Accuracy: 0.558\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.04180441424250603\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.043265056397233694 - Train Accuracy: 0.7270089285714286\n",
            "\t\t\tVal Loss: 0.05558282323181629 - Val Accuracy: 0.604\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.042640700936317444\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.04320047050714493 - Train Accuracy: 0.7316964285714286\n",
            "\t\t\tVal Loss: 0.05603776779025793 - Val Accuracy: 0.588\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1050, Loss 0.04132440313696861\n",
            "\t\tTrain step - Step 1080, Loss 0.04328101873397827\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.043326813727617264 - Train Accuracy: 0.7274553571428571\n",
            "\t\t\tVal Loss: 0.05691333208233118 - Val Accuracy: 0.58\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.04196943715214729\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.043096790036984856 - Train Accuracy: 0.7495535714285714\n",
            "\t\t\tVal Loss: 0.05533176567405462 - Val Accuracy: 0.598\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.04087167978286743\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.042568695438759664 - Train Accuracy: 0.7609375\n",
            "\t\t\tVal Loss: 0.0584924416616559 - Val Accuracy: 0.602\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.044188231229782104\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.04305113681725093 - Train Accuracy: 0.7524553571428572\n",
            "\t\t\tVal Loss: 0.05741831846535206 - Val Accuracy: 0.614\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1200, Loss 0.04398157820105553\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.042765229088919506 - Train Accuracy: 0.7582589285714286\n",
            "\t\t\tVal Loss: 0.055225806310772896 - Val Accuracy: 0.634\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.04198677837848663\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.04261867254972458 - Train Accuracy: 0.7676339285714285\n",
            "\t\t\tVal Loss: 0.05679944343864918 - Val Accuracy: 0.632\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.041356801986694336\n",
            "\t\tTrain step - Step 1290, Loss 0.04456128180027008\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.04243737246309008 - Train Accuracy: 0.7814732142857143\n",
            "\t\t\tVal Loss: 0.05895271059125662 - Val Accuracy: 0.608\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1320, Loss 0.04329900071024895\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.04250884354114533 - Train Accuracy: 0.7725446428571429\n",
            "\t\t\tVal Loss: 0.055695803835988045 - Val Accuracy: 0.65\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.0417630672454834\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.04207844776766641 - Train Accuracy: 0.7890625\n",
            "\t\t\tVal Loss: 0.05442191660404205 - Val Accuracy: 0.616\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.04075909033417702\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.04216889387794903 - Train Accuracy: 0.7767857142857143\n",
            "\t\t\tVal Loss: 0.05602939426898956 - Val Accuracy: 0.632\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.0436551570892334\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.042087009016956604 - Train Accuracy: 0.790625\n",
            "\t\t\tVal Loss: 0.056368157267570496 - Val Accuracy: 0.604\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1440, Loss 0.04136831313371658\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.04176416216152055 - Train Accuracy: 0.7904017857142858\n",
            "\t\t\tVal Loss: 0.05881309695541859 - Val Accuracy: 0.628\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.04122910276055336\n",
            "\t\tTrain step - Step 1500, Loss 0.04168412461876869\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.04175048853669848 - Train Accuracy: 0.8008928571428572\n",
            "\t\t\tVal Loss: 0.06045403331518173 - Val Accuracy: 0.596\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.03962145745754242\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.04150083905884198 - Train Accuracy: 0.8167410714285714\n",
            "\t\t\tVal Loss: 0.05799864046275616 - Val Accuracy: 0.638\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.03993364796042442\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.04157271832227707 - Train Accuracy: 0.8066964285714285\n",
            "\t\t\tVal Loss: 0.05999213457107544 - Val Accuracy: 0.63\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1590, Loss 0.04164744168519974\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.04200320573789733 - Train Accuracy: 0.8013392857142857\n",
            "\t\t\tVal Loss: 0.05898499023169279 - Val Accuracy: 0.63\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.04238130524754524\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.04146190189889499 - Train Accuracy: 0.815625\n",
            "\t\t\tVal Loss: 0.057379922829568386 - Val Accuracy: 0.644\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.042917538434267044\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.04181916192173958 - Train Accuracy: 0.8022321428571428\n",
            "\t\t\tVal Loss: 0.05712328664958477 - Val Accuracy: 0.614\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.04086877778172493\n",
            "\t\tTrain step - Step 1710, Loss 0.04099053889513016\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.04125110847609384 - Train Accuracy: 0.8066964285714285\n",
            "\t\t\tVal Loss: 0.05964668933302164 - Val Accuracy: 0.634\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1740, Loss 0.037036165595054626\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.038686419278383254 - Train Accuracy: 0.8419642857142857\n",
            "\t\t\tVal Loss: 0.055514185689389706 - Val Accuracy: 0.662\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1770, Loss 0.036435406655073166\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.036964441516569684 - Train Accuracy: 0.8602678571428571\n",
            "\t\t\tVal Loss: 0.05516176111996174 - Val Accuracy: 0.674\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1800, Loss 0.03751580789685249\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.0366914695927075 - Train Accuracy: 0.8736607142857142\n",
            "\t\t\tVal Loss: 0.05481882859021425 - Val Accuracy: 0.68\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1830, Loss 0.03605448082089424\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.03637522171650614 - Train Accuracy: 0.8631696428571428\n",
            "\t\t\tVal Loss: 0.0551433339715004 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1860, Loss 0.03620288521051407\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.03626197395580155 - Train Accuracy: 0.8709821428571428\n",
            "\t\t\tVal Loss: 0.0574601124972105 - Val Accuracy: 0.644\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1890, Loss 0.03652574121952057\n",
            "\t\tTrain step - Step 1920, Loss 0.03532322496175766\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.03612813821860722 - Train Accuracy: 0.8732142857142857\n",
            "\t\t\tVal Loss: 0.056828039698302746 - Val Accuracy: 0.666\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.03816484287381172\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.03606127649545669 - Train Accuracy: 0.8669642857142857\n",
            "\t\t\tVal Loss: 0.057718909345567226 - Val Accuracy: 0.668\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1980, Loss 0.034893255680799484\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.03587750345468521 - Train Accuracy: 0.8698660714285714\n",
            "\t\t\tVal Loss: 0.05711156502366066 - Val Accuracy: 0.678\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.036388982087373734\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.03565469831228256 - Train Accuracy: 0.8707589285714286\n",
            "\t\t\tVal Loss: 0.0574137968942523 - Val Accuracy: 0.666\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.03628729656338692\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.035610156399863105 - Train Accuracy: 0.8787946428571428\n",
            "\t\t\tVal Loss: 0.056730601005256176 - Val Accuracy: 0.66\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.03617915138602257\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.03583338111639023 - Train Accuracy: 0.8785714285714286\n",
            "\t\t\tVal Loss: 0.058015444315969944 - Val Accuracy: 0.676\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2100, Loss 0.03498712554574013\n",
            "\t\tTrain step - Step 2130, Loss 0.03618066385388374\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.0355659187904426 - Train Accuracy: 0.8801339285714286\n",
            "\t\t\tVal Loss: 0.05779200326651335 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.03518787771463394\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.03562673596399171 - Train Accuracy: 0.8705357142857143\n",
            "\t\t\tVal Loss: 0.057513427920639515 - Val Accuracy: 0.67\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.03477795422077179\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.03554634313498225 - Train Accuracy: 0.8819196428571429\n",
            "\t\t\tVal Loss: 0.057765436358749866 - Val Accuracy: 0.662\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2220, Loss 0.0368034727871418\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.0352142972605569 - Train Accuracy: 0.8832589285714286\n",
            "\t\t\tVal Loss: 0.05661813449114561 - Val Accuracy: 0.692\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2250, Loss 0.03430211544036865\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.03508258046848434 - Train Accuracy: 0.8794642857142857\n",
            "\t\t\tVal Loss: 0.057921767234802246 - Val Accuracy: 0.674\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2280, Loss 0.034592583775520325\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.03510156486715589 - Train Accuracy: 0.8839285714285714\n",
            "\t\t\tVal Loss: 0.057746521197259426 - Val Accuracy: 0.678\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2310, Loss 0.03509519249200821\n",
            "\t\tTrain step - Step 2340, Loss 0.0346166156232357\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.03499937610966819 - Train Accuracy: 0.8700892857142857\n",
            "\t\t\tVal Loss: 0.0569325964897871 - Val Accuracy: 0.674\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2370, Loss 0.03428279235959053\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.03512460078511919 - Train Accuracy: 0.8841517857142858\n",
            "\t\t\tVal Loss: 0.05863720830529928 - Val Accuracy: 0.648\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2400, Loss 0.03604773432016373\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.0350425446672099 - Train Accuracy: 0.8848214285714285\n",
            "\t\t\tVal Loss: 0.05799099616706371 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2430, Loss 0.036229223012924194\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/32 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.03494263557451112 - Train Accuracy: 0.8816964285714286\n",
            "\t\t\tVal Loss: 0.0580933028832078 - Val Accuracy: 0.664\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 23.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 4:\n",
            "\t\tTrain Mean Accuracy: 0.7080165816326531\n",
            "\t\tVal Mean Accuracy: 0.5663714285714286\n",
            "\t\tTest Accuracy: 0.50475\n",
            "\n",
            "STARTING FINE TUNING STAGE 5...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.06805034726858139\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.08252453058958054 - Train Accuracy: 0.04397321428571429\n",
            "\t\t\tVal Loss: 0.08801805600523949 - Val Accuracy: 0.124\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.06900909543037415\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.0669566205569676 - Train Accuracy: 0.17790178571428572\n",
            "\t\t\tVal Loss: 0.08543180488049984 - Val Accuracy: 0.184\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.0668015256524086\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.06538889801927976 - Train Accuracy: 0.22611607142857143\n",
            "\t\t\tVal Loss: 0.08178014121949673 - Val Accuracy: 0.21\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.06316506117582321\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.06433046843324389 - Train Accuracy: 0.2732142857142857\n",
            "\t\t\tVal Loss: 0.07280999049544334 - Val Accuracy: 0.248\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 150, Loss 0.06326115131378174\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.063463829351323 - Train Accuracy: 0.31160714285714286\n",
            "\t\t\tVal Loss: 0.07704492099583149 - Val Accuracy: 0.278\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.061087675392627716\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.0624228515795299 - Train Accuracy: 0.3470982142857143\n",
            "\t\t\tVal Loss: 0.07203796692192554 - Val Accuracy: 0.346\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.06063729152083397\n",
            "\t\tTrain step - Step 240, Loss 0.062060412019491196\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.06190394993339266 - Train Accuracy: 0.37075892857142856\n",
            "\t\t\tVal Loss: 0.07533331215381622 - Val Accuracy: 0.354\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 270, Loss 0.06189468130469322\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.0616277382842132 - Train Accuracy: 0.40334821428571427\n",
            "\t\t\tVal Loss: 0.07555489614605904 - Val Accuracy: 0.378\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.06025618314743042\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.06122639658195632 - Train Accuracy: 0.42142857142857143\n",
            "\t\t\tVal Loss: 0.07975971326231956 - Val Accuracy: 0.334\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.06066090613603592\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.06131515971251896 - Train Accuracy: 0.45714285714285713\n",
            "\t\t\tVal Loss: 0.07409643940627575 - Val Accuracy: 0.398\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.06221626326441765\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.060347960676465716 - Train Accuracy: 0.4823660714285714\n",
            "\t\t\tVal Loss: 0.07670457288622856 - Val Accuracy: 0.408\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.05864627659320831\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.06046982343707766 - Train Accuracy: 0.4924107142857143\n",
            "\t\t\tVal Loss: 0.07316447794437408 - Val Accuracy: 0.418\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 420, Loss 0.061556991189718246\n",
            "\t\tTrain step - Step 450, Loss 0.06121836602687836\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.06034426859446934 - Train Accuracy: 0.5256696428571429\n",
            "\t\t\tVal Loss: 0.07179820165038109 - Val Accuracy: 0.482\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.05879874899983406\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.05985576074038233 - Train Accuracy: 0.5395089285714286\n",
            "\t\t\tVal Loss: 0.07174425013363361 - Val Accuracy: 0.454\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.05737005174160004\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.05925838947296143 - Train Accuracy: 0.5638392857142858\n",
            "\t\t\tVal Loss: 0.06742153503000736 - Val Accuracy: 0.494\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 540, Loss 0.059373997151851654\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.05878027911697115 - Train Accuracy: 0.578125\n",
            "\t\t\tVal Loss: 0.07444873079657555 - Val Accuracy: 0.488\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.058756787329912186\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.05843295965875898 - Train Accuracy: 0.6029017857142858\n",
            "\t\t\tVal Loss: 0.07083708979189396 - Val Accuracy: 0.492\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.05792294442653656\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.05869873123509543 - Train Accuracy: 0.6116071428571429\n",
            "\t\t\tVal Loss: 0.07340196706354618 - Val Accuracy: 0.472\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.055427227169275284\n",
            "\t\tTrain step - Step 660, Loss 0.05779670178890228\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.058476642199925016 - Train Accuracy: 0.6316964285714286\n",
            "\t\t\tVal Loss: 0.07010853476822376 - Val Accuracy: 0.52\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.057741012424230576\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.05824799867612975 - Train Accuracy: 0.6379464285714286\n",
            "\t\t\tVal Loss: 0.07285606674849987 - Val Accuracy: 0.532\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.056747663766145706\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.057808446351970945 - Train Accuracy: 0.6524553571428572\n",
            "\t\t\tVal Loss: 0.07133461534976959 - Val Accuracy: 0.512\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.056199077516794205\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.05765413812228611 - Train Accuracy: 0.6651785714285714\n",
            "\t\t\tVal Loss: 0.07452761940658092 - Val Accuracy: 0.504\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.05729362741112709\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.057539243144648415 - Train Accuracy: 0.6732142857142858\n",
            "\t\t\tVal Loss: 0.06961614452302456 - Val Accuracy: 0.594\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 810, Loss 0.05903001129627228\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.057383056197847636 - Train Accuracy: 0.6745535714285714\n",
            "\t\t\tVal Loss: 0.06958387792110443 - Val Accuracy: 0.6\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.057555846869945526\n",
            "\t\tTrain step - Step 870, Loss 0.061044011265039444\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.05730297512241772 - Train Accuracy: 0.6787946428571429\n",
            "\t\t\tVal Loss: 0.07410405948758125 - Val Accuracy: 0.532\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.05607524886727333\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.05742600645337786 - Train Accuracy: 0.7020089285714286\n",
            "\t\t\tVal Loss: 0.06833939626812935 - Val Accuracy: 0.574\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 930, Loss 0.057776354253292084\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.05696823469230107 - Train Accuracy: 0.7109375\n",
            "\t\t\tVal Loss: 0.07140479423105717 - Val Accuracy: 0.57\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.05704241618514061\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.05654131865927151 - Train Accuracy: 0.7113839285714286\n",
            "\t\t\tVal Loss: 0.07302930019795895 - Val Accuracy: 0.556\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.05416079983115196\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.056330777491841996 - Train Accuracy: 0.7379464285714286\n",
            "\t\t\tVal Loss: 0.07185819000005722 - Val Accuracy: 0.572\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.05561192333698273\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.05626957608120782 - Train Accuracy: 0.7299107142857143\n",
            "\t\t\tVal Loss: 0.07210508920252323 - Val Accuracy: 0.594\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1050, Loss 0.05461037904024124\n",
            "\t\tTrain step - Step 1080, Loss 0.05621541291475296\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.055945227508034025 - Train Accuracy: 0.7328125\n",
            "\t\t\tVal Loss: 0.0675089843571186 - Val Accuracy: 0.63\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.056956738233566284\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.05581078220691 - Train Accuracy: 0.7415178571428571\n",
            "\t\t\tVal Loss: 0.07411854714155197 - Val Accuracy: 0.594\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.05483242869377136\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.05567400551268033 - Train Accuracy: 0.7571428571428571\n",
            "\t\t\tVal Loss: 0.06914552301168442 - Val Accuracy: 0.584\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.05436130240559578\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.05567508105720793 - Train Accuracy: 0.7537946428571428\n",
            "\t\t\tVal Loss: 0.07242095470428467 - Val Accuracy: 0.564\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1200, Loss 0.05699095502495766\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.05596722481506211 - Train Accuracy: 0.75\n",
            "\t\t\tVal Loss: 0.07419108413159847 - Val Accuracy: 0.608\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.057415638118982315\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.05613443542804037 - Train Accuracy: 0.7616071428571428\n",
            "\t\t\tVal Loss: 0.07333025895059109 - Val Accuracy: 0.586\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.05580292269587517\n",
            "\t\tTrain step - Step 1290, Loss 0.05598302185535431\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.05539236877645765 - Train Accuracy: 0.7729910714285714\n",
            "\t\t\tVal Loss: 0.06936513539403677 - Val Accuracy: 0.608\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1320, Loss 0.055278751999139786\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.055530368430273876 - Train Accuracy: 0.7727678571428571\n",
            "\t\t\tVal Loss: 0.07018927857279778 - Val Accuracy: 0.592\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.0558660551905632\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.055720949811594825 - Train Accuracy: 0.7720982142857142\n",
            "\t\t\tVal Loss: 0.07225773297250271 - Val Accuracy: 0.578\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.05439691245555878\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.05469322907073157 - Train Accuracy: 0.7866071428571428\n",
            "\t\t\tVal Loss: 0.0749454703181982 - Val Accuracy: 0.574\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.053871411830186844\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.054819368358169286 - Train Accuracy: 0.7879464285714286\n",
            "\t\t\tVal Loss: 0.07171748764812946 - Val Accuracy: 0.598\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1440, Loss 0.05341850221157074\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.05502260391201292 - Train Accuracy: 0.7964285714285714\n",
            "\t\t\tVal Loss: 0.07182064279913902 - Val Accuracy: 0.582\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.05427621677517891\n",
            "\t\tTrain step - Step 1500, Loss 0.0562397837638855\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.05430276372603008 - Train Accuracy: 0.7993303571428572\n",
            "\t\t\tVal Loss: 0.07532343454658985 - Val Accuracy: 0.582\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.056063804775476456\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.05580791937453406 - Train Accuracy: 0.7886160714285714\n",
            "\t\t\tVal Loss: 0.07521096616983414 - Val Accuracy: 0.61\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.05490599945187569\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.05548258530242103 - Train Accuracy: 0.7881696428571429\n",
            "\t\t\tVal Loss: 0.0710136704146862 - Val Accuracy: 0.62\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1590, Loss 0.05490805581212044\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.0544802012188094 - Train Accuracy: 0.8129464285714286\n",
            "\t\t\tVal Loss: 0.07206770405173302 - Val Accuracy: 0.598\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.05493170768022537\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.05479354464582035 - Train Accuracy: 0.8024553571428571\n",
            "\t\t\tVal Loss: 0.0707191452383995 - Val Accuracy: 0.6\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.05519462376832962\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.05400711223483086 - Train Accuracy: 0.8220982142857143\n",
            "\t\t\tVal Loss: 0.07091200724244118 - Val Accuracy: 0.624\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.0531163215637207\n",
            "\t\tTrain step - Step 1710, Loss 0.0554974339902401\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.054662920641047615 - Train Accuracy: 0.8073660714285714\n",
            "\t\t\tVal Loss: 0.0773528628051281 - Val Accuracy: 0.588\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1740, Loss 0.05135822296142578\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.05210651925631932 - Train Accuracy: 0.8502232142857142\n",
            "\t\t\tVal Loss: 0.06934496201574802 - Val Accuracy: 0.68\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1770, Loss 0.04999981448054314\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.05014031529426575 - Train Accuracy: 0.8533482142857143\n",
            "\t\t\tVal Loss: 0.06831884942948818 - Val Accuracy: 0.662\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1800, Loss 0.05117931216955185\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.04977372948612486 - Train Accuracy: 0.8613839285714285\n",
            "\t\t\tVal Loss: 0.06947859190404415 - Val Accuracy: 0.642\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1830, Loss 0.04909428954124451\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.049701911423887524 - Train Accuracy: 0.8587053571428571\n",
            "\t\t\tVal Loss: 0.07126565650105476 - Val Accuracy: 0.652\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1860, Loss 0.04987715557217598\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.04932803341320583 - Train Accuracy: 0.8625\n",
            "\t\t\tVal Loss: 0.06942370347678661 - Val Accuracy: 0.662\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1890, Loss 0.05037054046988487\n",
            "\t\tTrain step - Step 1920, Loss 0.05097028240561485\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.04919653055923326 - Train Accuracy: 0.8662946428571429\n",
            "\t\t\tVal Loss: 0.07090635783970356 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.04865235835313797\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.04906507294092859 - Train Accuracy: 0.8580357142857142\n",
            "\t\t\tVal Loss: 0.0715495552867651 - Val Accuracy: 0.64\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1980, Loss 0.04748724028468132\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.049217403892959866 - Train Accuracy: 0.8604910714285714\n",
            "\t\t\tVal Loss: 0.07250272668898106 - Val Accuracy: 0.65\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.05051203444600105\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.04884510434099606 - Train Accuracy: 0.8604910714285714\n",
            "\t\t\tVal Loss: 0.07166138477623463 - Val Accuracy: 0.652\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.04998478665947914\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.04897389113903046 - Train Accuracy: 0.8667410714285714\n",
            "\t\t\tVal Loss: 0.07188916765153408 - Val Accuracy: 0.65\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.04947914183139801\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.04897827793444906 - Train Accuracy: 0.859375\n",
            "\t\t\tVal Loss: 0.0725669227540493 - Val Accuracy: 0.664\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2100, Loss 0.04821660742163658\n",
            "\t\tTrain step - Step 2130, Loss 0.04739615321159363\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.04874354196446282 - Train Accuracy: 0.8600446428571429\n",
            "\t\t\tVal Loss: 0.07413342036306858 - Val Accuracy: 0.646\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.04965272173285484\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.04860913093600954 - Train Accuracy: 0.8569196428571428\n",
            "\t\t\tVal Loss: 0.07192624546587467 - Val Accuracy: 0.644\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.04841875284910202\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.04864456462008612 - Train Accuracy: 0.865625\n",
            "\t\t\tVal Loss: 0.0721643827855587 - Val Accuracy: 0.654\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2220, Loss 0.047397010028362274\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.048559757747820446 - Train Accuracy: 0.8685267857142858\n",
            "\t\t\tVal Loss: 0.07304767891764641 - Val Accuracy: 0.658\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2250, Loss 0.049242112785577774\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.04826272630265781 - Train Accuracy: 0.8774553571428572\n",
            "\t\t\tVal Loss: 0.07312957756221294 - Val Accuracy: 0.648\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2280, Loss 0.04822346568107605\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.04823874905705452 - Train Accuracy: 0.8698660714285714\n",
            "\t\t\tVal Loss: 0.07285350933670998 - Val Accuracy: 0.646\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2310, Loss 0.04702095314860344\n",
            "\t\tTrain step - Step 2340, Loss 0.04829344525933266\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.04818968187485422 - Train Accuracy: 0.8752232142857143\n",
            "\t\t\tVal Loss: 0.07412081584334373 - Val Accuracy: 0.642\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2370, Loss 0.046764153987169266\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.048371177379574096 - Train Accuracy: 0.8705357142857143\n",
            "\t\t\tVal Loss: 0.07301896996796131 - Val Accuracy: 0.632\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2400, Loss 0.04932529479265213\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.048280216327735354 - Train Accuracy: 0.8647321428571428\n",
            "\t\t\tVal Loss: 0.07189040072262287 - Val Accuracy: 0.664\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2430, Loss 0.04818696528673172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/40 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.04822723301393645 - Train Accuracy: 0.8752232142857143\n",
            "\t\t\tVal Loss: 0.07350767590105534 - Val Accuracy: 0.644\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:01<00:00, 23.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 5:\n",
            "\t\tTrain Mean Accuracy: 0.6940497448979591\n",
            "\t\tVal Mean Accuracy: 0.5461428571428572\n",
            "\t\tTest Accuracy: 0.4372\n",
            "\n",
            "STARTING FINE TUNING STAGE 6...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.08081528544425964\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.09564583088670459 - Train Accuracy: 0.06651785714285714\n",
            "\t\t\tVal Loss: 0.10059690847992897 - Val Accuracy: 0.142\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.0786508172750473\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.0803085452743939 - Train Accuracy: 0.20044642857142858\n",
            "\t\t\tVal Loss: 0.09330427460372448 - Val Accuracy: 0.24\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.07591644674539566\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.079280829003879 - Train Accuracy: 0.26138392857142856\n",
            "\t\t\tVal Loss: 0.08595355041325092 - Val Accuracy: 0.276\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.07542812824249268\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.07726254378046309 - Train Accuracy: 0.3040178571428571\n",
            "\t\t\tVal Loss: 0.09424498490989208 - Val Accuracy: 0.27\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 150, Loss 0.07615726441144943\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.07619276280914034 - Train Accuracy: 0.3453125\n",
            "\t\t\tVal Loss: 0.08513690531253815 - Val Accuracy: 0.312\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.07457252591848373\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.07553815245628356 - Train Accuracy: 0.3767857142857143\n",
            "\t\t\tVal Loss: 0.08869670517742634 - Val Accuracy: 0.386\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.07534301280975342\n",
            "\t\tTrain step - Step 240, Loss 0.07626700401306152\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.07456273521695818 - Train Accuracy: 0.41183035714285715\n",
            "\t\t\tVal Loss: 0.0931163802742958 - Val Accuracy: 0.398\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 270, Loss 0.07678238302469254\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.07404867176498686 - Train Accuracy: 0.42879464285714286\n",
            "\t\t\tVal Loss: 0.08443226106464863 - Val Accuracy: 0.45\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.07476961612701416\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.0739038233246122 - Train Accuracy: 0.4654017857142857\n",
            "\t\t\tVal Loss: 0.08326924964785576 - Val Accuracy: 0.45\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.07234890758991241\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.07350118117673056 - Train Accuracy: 0.484375\n",
            "\t\t\tVal Loss: 0.08506100624799728 - Val Accuracy: 0.416\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.07294091582298279\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.07325141089303153 - Train Accuracy: 0.5058035714285715\n",
            "\t\t\tVal Loss: 0.08532114885747433 - Val Accuracy: 0.456\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.07103727012872696\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.07241827717849186 - Train Accuracy: 0.5272321428571428\n",
            "\t\t\tVal Loss: 0.08894226886332035 - Val Accuracy: 0.448\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 420, Loss 0.07323221862316132\n",
            "\t\tTrain step - Step 450, Loss 0.07396344840526581\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.07254401402814048 - Train Accuracy: 0.5412946428571429\n",
            "\t\t\tVal Loss: 0.08254813030362129 - Val Accuracy: 0.488\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.07067469507455826\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.0720283459339823 - Train Accuracy: 0.5535714285714286\n",
            "\t\t\tVal Loss: 0.08295178599655628 - Val Accuracy: 0.508\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.07176689058542252\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.07234448726688113 - Train Accuracy: 0.571875\n",
            "\t\t\tVal Loss: 0.08656815811991692 - Val Accuracy: 0.492\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 540, Loss 0.0719187781214714\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.07232918441295624 - Train Accuracy: 0.5881696428571429\n",
            "\t\t\tVal Loss: 0.08763254061341286 - Val Accuracy: 0.5\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.07188355922698975\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.07189221744026457 - Train Accuracy: 0.5991071428571428\n",
            "\t\t\tVal Loss: 0.08371671289205551 - Val Accuracy: 0.53\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.06881538033485413\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.07149462401866913 - Train Accuracy: 0.6064732142857143\n",
            "\t\t\tVal Loss: 0.08274072036147118 - Val Accuracy: 0.522\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.06990578770637512\n",
            "\t\tTrain step - Step 660, Loss 0.07130726426839828\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.07175206925187792 - Train Accuracy: 0.6220982142857143\n",
            "\t\t\tVal Loss: 0.08267582952976227 - Val Accuracy: 0.568\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.0716019794344902\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.07124759320701872 - Train Accuracy: 0.6310267857142857\n",
            "\t\t\tVal Loss: 0.08458807319402695 - Val Accuracy: 0.548\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.07144644856452942\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.07076259063822883 - Train Accuracy: 0.6470982142857142\n",
            "\t\t\tVal Loss: 0.08315064758062363 - Val Accuracy: 0.542\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.07074158638715744\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.07117765162672315 - Train Accuracy: 0.6517857142857143\n",
            "\t\t\tVal Loss: 0.08865920267999172 - Val Accuracy: 0.584\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.07061140239238739\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.07055671874965941 - Train Accuracy: 0.665625\n",
            "\t\t\tVal Loss: 0.08775750361382961 - Val Accuracy: 0.55\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 810, Loss 0.06862116605043411\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.07044598587921687 - Train Accuracy: 0.6752232142857143\n",
            "\t\t\tVal Loss: 0.0847557932138443 - Val Accuracy: 0.564\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.07203464210033417\n",
            "\t\tTrain step - Step 870, Loss 0.07000749558210373\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.07038688510656357 - Train Accuracy: 0.6790178571428571\n",
            "\t\t\tVal Loss: 0.08479075320065022 - Val Accuracy: 0.596\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.07125350087881088\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.0706601272736277 - Train Accuracy: 0.6845982142857143\n",
            "\t\t\tVal Loss: 0.083820266649127 - Val Accuracy: 0.552\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 930, Loss 0.06980876624584198\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.07024250051804952 - Train Accuracy: 0.703125\n",
            "\t\t\tVal Loss: 0.08439237251877785 - Val Accuracy: 0.546\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.06927452981472015\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.06996678795133318 - Train Accuracy: 0.7118303571428571\n",
            "\t\t\tVal Loss: 0.08182783797383308 - Val Accuracy: 0.59\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.06904232501983643\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.06998485284192221 - Train Accuracy: 0.7147321428571428\n",
            "\t\t\tVal Loss: 0.08546560630202293 - Val Accuracy: 0.564\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.06809154152870178\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.06995370558329991 - Train Accuracy: 0.7162946428571428\n",
            "\t\t\tVal Loss: 0.08419176377356052 - Val Accuracy: 0.606\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1050, Loss 0.07010700553655624\n",
            "\t\tTrain step - Step 1080, Loss 0.07043719291687012\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.06939204782247543 - Train Accuracy: 0.73125\n",
            "\t\t\tVal Loss: 0.08376872725784779 - Val Accuracy: 0.58\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.07074251025915146\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.0692597108227866 - Train Accuracy: 0.7421875\n",
            "\t\t\tVal Loss: 0.08242409490048885 - Val Accuracy: 0.606\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.06721416115760803\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.06903810586248126 - Train Accuracy: 0.7459821428571428\n",
            "\t\t\tVal Loss: 0.08307252451777458 - Val Accuracy: 0.608\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.0694352462887764\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.06903009904282434 - Train Accuracy: 0.7401785714285715\n",
            "\t\t\tVal Loss: 0.08445009589195251 - Val Accuracy: 0.598\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1200, Loss 0.07017819583415985\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.06967139158930097 - Train Accuracy: 0.7366071428571429\n",
            "\t\t\tVal Loss: 0.0800915826112032 - Val Accuracy: 0.636\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.0684794932603836\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.06977888409580503 - Train Accuracy: 0.7497767857142857\n",
            "\t\t\tVal Loss: 0.08281991630792618 - Val Accuracy: 0.606\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.06814794987440109\n",
            "\t\tTrain step - Step 1290, Loss 0.07016514986753464\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.06929261088371277 - Train Accuracy: 0.7582589285714286\n",
            "\t\t\tVal Loss: 0.08290728740394115 - Val Accuracy: 0.624\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1320, Loss 0.06953495740890503\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.06883039942809514 - Train Accuracy: 0.7569196428571429\n",
            "\t\t\tVal Loss: 0.08750413730740547 - Val Accuracy: 0.62\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.06837904453277588\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.06845207065343857 - Train Accuracy: 0.7754464285714285\n",
            "\t\t\tVal Loss: 0.08159753680229187 - Val Accuracy: 0.618\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.06833694875240326\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.06861978960888726 - Train Accuracy: 0.7709821428571428\n",
            "\t\t\tVal Loss: 0.07976598478853703 - Val Accuracy: 0.62\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.06832487136125565\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.0689955568739346 - Train Accuracy: 0.7587053571428571\n",
            "\t\t\tVal Loss: 0.08679429814219475 - Val Accuracy: 0.552\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1440, Loss 0.0696697011590004\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.06892730104071754 - Train Accuracy: 0.76875\n",
            "\t\t\tVal Loss: 0.0827190987765789 - Val Accuracy: 0.626\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.06863092631101608\n",
            "\t\tTrain step - Step 1500, Loss 0.06778258085250854\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.06882687764508384 - Train Accuracy: 0.7783482142857143\n",
            "\t\t\tVal Loss: 0.08346195705235004 - Val Accuracy: 0.624\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.06932800263166428\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.06850728605474744 - Train Accuracy: 0.7870535714285715\n",
            "\t\t\tVal Loss: 0.09031890891492367 - Val Accuracy: 0.592\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.06767934560775757\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.0686238203729902 - Train Accuracy: 0.7872767857142857\n",
            "\t\t\tVal Loss: 0.0879304651170969 - Val Accuracy: 0.612\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1590, Loss 0.06873833388090134\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.06841245038168771 - Train Accuracy: 0.7955357142857142\n",
            "\t\t\tVal Loss: 0.08080535009503365 - Val Accuracy: 0.636\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.06612785160541534\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.06773014494350978 - Train Accuracy: 0.8073660714285714\n",
            "\t\t\tVal Loss: 0.08181291073560715 - Val Accuracy: 0.632\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.06848098337650299\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.06770012591566359 - Train Accuracy: 0.7948660714285715\n",
            "\t\t\tVal Loss: 0.08797005377709866 - Val Accuracy: 0.6\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.0687965676188469\n",
            "\t\tTrain step - Step 1710, Loss 0.0676802322268486\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.06856426979814256 - Train Accuracy: 0.7933035714285714\n",
            "\t\t\tVal Loss: 0.08066905476152897 - Val Accuracy: 0.602\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1740, Loss 0.06411334872245789\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.06559405316199575 - Train Accuracy: 0.8466517857142857\n",
            "\t\t\tVal Loss: 0.08173984847962856 - Val Accuracy: 0.646\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1770, Loss 0.06489747762680054\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.06390596798488073 - Train Accuracy: 0.8466517857142857\n",
            "\t\t\tVal Loss: 0.08216060511767864 - Val Accuracy: 0.63\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1800, Loss 0.06455206871032715\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.06350808643868991 - Train Accuracy: 0.8426339285714286\n",
            "\t\t\tVal Loss: 0.08109837025403976 - Val Accuracy: 0.652\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1830, Loss 0.06194094941020012\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.06306194269231387 - Train Accuracy: 0.8375\n",
            "\t\t\tVal Loss: 0.0830162912607193 - Val Accuracy: 0.658\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1860, Loss 0.06118400767445564\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.06299699332032885 - Train Accuracy: 0.8517857142857143\n",
            "\t\t\tVal Loss: 0.08340591192245483 - Val Accuracy: 0.638\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1890, Loss 0.06147235259413719\n",
            "\t\tTrain step - Step 1920, Loss 0.06138348579406738\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.06296309328504972 - Train Accuracy: 0.8428571428571429\n",
            "\t\t\tVal Loss: 0.08343876339495182 - Val Accuracy: 0.662\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.06397071480751038\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.06288217529654502 - Train Accuracy: 0.8495535714285715\n",
            "\t\t\tVal Loss: 0.08459526300430298 - Val Accuracy: 0.644\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1980, Loss 0.06137712672352791\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.06277791112661361 - Train Accuracy: 0.8412946428571428\n",
            "\t\t\tVal Loss: 0.08335215412080288 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.0630006194114685\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.0625511544091361 - Train Accuracy: 0.8526785714285714\n",
            "\t\t\tVal Loss: 0.08317295089364052 - Val Accuracy: 0.654\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.06212032213807106\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.0627332332943167 - Train Accuracy: 0.8513392857142857\n",
            "\t\t\tVal Loss: 0.08459914848208427 - Val Accuracy: 0.668\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.06251545995473862\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.062460775460515705 - Train Accuracy: 0.8453125\n",
            "\t\t\tVal Loss: 0.08542388305068016 - Val Accuracy: 0.63\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2100, Loss 0.062484972178936005\n",
            "\t\tTrain step - Step 2130, Loss 0.06243747100234032\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.0623304301074573 - Train Accuracy: 0.8399553571428572\n",
            "\t\t\tVal Loss: 0.08363180980086327 - Val Accuracy: 0.664\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.06153620406985283\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.062452675295727594 - Train Accuracy: 0.8444196428571429\n",
            "\t\t\tVal Loss: 0.08556785248219967 - Val Accuracy: 0.636\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.06180862337350845\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.06222526633313724 - Train Accuracy: 0.8439732142857143\n",
            "\t\t\tVal Loss: 0.08410954475402832 - Val Accuracy: 0.618\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2220, Loss 0.062329720705747604\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.06226083167961666 - Train Accuracy: 0.8517857142857143\n",
            "\t\t\tVal Loss: 0.08397266082465649 - Val Accuracy: 0.636\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2250, Loss 0.06250687688589096\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.06185359124626432 - Train Accuracy: 0.8482142857142857\n",
            "\t\t\tVal Loss: 0.08411786518990993 - Val Accuracy: 0.646\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2280, Loss 0.06226839870214462\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.061941625390733994 - Train Accuracy: 0.8529017857142858\n",
            "\t\t\tVal Loss: 0.08505731448531151 - Val Accuracy: 0.616\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2310, Loss 0.061974767595529556\n",
            "\t\tTrain step - Step 2340, Loss 0.061633653938770294\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.06195972636342049 - Train Accuracy: 0.8484375\n",
            "\t\t\tVal Loss: 0.08358577080070972 - Val Accuracy: 0.66\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2370, Loss 0.06001691520214081\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.06183465069958142 - Train Accuracy: 0.8477678571428572\n",
            "\t\t\tVal Loss: 0.08442038483917713 - Val Accuracy: 0.64\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2400, Loss 0.06311001628637314\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.06173913595931871 - Train Accuracy: 0.853125\n",
            "\t\t\tVal Loss: 0.08435517363250256 - Val Accuracy: 0.636\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2430, Loss 0.06280094385147095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/47 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.06191024961216109 - Train Accuracy: 0.8457589285714285\n",
            "\t\t\tVal Loss: 0.08521337434649467 - Val Accuracy: 0.63\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 47/47 [00:01<00:00, 23.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 6:\n",
            "\t\tTrain Mean Accuracy: 0.6900605867346938\n",
            "\t\tVal Mean Accuracy: 0.5600857142857143\n",
            "\t\tTest Accuracy: 0.4083333333333333\n",
            "\n",
            "STARTING FINE TUNING STAGE 7...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.09352641552686691\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.10847006397587912 - Train Accuracy: 0.04977678571428571\n",
            "\t\t\tVal Loss: 0.11120735481381416 - Val Accuracy: 0.068\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.0914379134774208\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.09393556650195803 - Train Accuracy: 0.15223214285714284\n",
            "\t\t\tVal Loss: 0.10062510333955288 - Val Accuracy: 0.176\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.09293118864297867\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.0926842253123011 - Train Accuracy: 0.21450892857142856\n",
            "\t\t\tVal Loss: 0.09076155722141266 - Val Accuracy: 0.254\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.09271261096000671\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.0911753516112055 - Train Accuracy: 0.2716517857142857\n",
            "\t\t\tVal Loss: 0.09345237538218498 - Val Accuracy: 0.234\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 150, Loss 0.09066351503133774\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.08942688682249614 - Train Accuracy: 0.3118303571428571\n",
            "\t\t\tVal Loss: 0.08961286954581738 - Val Accuracy: 0.314\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.09005843847990036\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.08881235612290246 - Train Accuracy: 0.35066964285714286\n",
            "\t\t\tVal Loss: 0.08834601007401943 - Val Accuracy: 0.344\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.0888710767030716\n",
            "\t\tTrain step - Step 240, Loss 0.08967982977628708\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.08851208112069539 - Train Accuracy: 0.38236607142857143\n",
            "\t\t\tVal Loss: 0.09434160031378269 - Val Accuracy: 0.346\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 270, Loss 0.08779212832450867\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.08791703028338296 - Train Accuracy: 0.4160714285714286\n",
            "\t\t\tVal Loss: 0.09128461219370365 - Val Accuracy: 0.37\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.08451378345489502\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.08716228710753578 - Train Accuracy: 0.4470982142857143\n",
            "\t\t\tVal Loss: 0.09109053201973438 - Val Accuracy: 0.424\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.08845914900302887\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.0875080149088587 - Train Accuracy: 0.47410714285714284\n",
            "\t\t\tVal Loss: 0.08876519091427326 - Val Accuracy: 0.444\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.08911318331956863\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.08702577629259654 - Train Accuracy: 0.48549107142857145\n",
            "\t\t\tVal Loss: 0.09067993238568306 - Val Accuracy: 0.42\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.0865459218621254\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.0864504303250994 - Train Accuracy: 0.5029017857142857\n",
            "\t\t\tVal Loss: 0.09041677601635456 - Val Accuracy: 0.434\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 420, Loss 0.08241384476423264\n",
            "\t\tTrain step - Step 450, Loss 0.08498864620923996\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.08654648172003883 - Train Accuracy: 0.5328125\n",
            "\t\t\tVal Loss: 0.08744785375893116 - Val Accuracy: 0.462\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.08793743699789047\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.0861160912684032 - Train Accuracy: 0.5580357142857143\n",
            "\t\t\tVal Loss: 0.08671731129288673 - Val Accuracy: 0.51\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.08652903139591217\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.08556598467486246 - Train Accuracy: 0.5609375\n",
            "\t\t\tVal Loss: 0.09006423875689507 - Val Accuracy: 0.494\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 540, Loss 0.08400261402130127\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.08499297414507184 - Train Accuracy: 0.5883928571428572\n",
            "\t\t\tVal Loss: 0.08650052733719349 - Val Accuracy: 0.47\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.08503910154104233\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.0854950127857072 - Train Accuracy: 0.5982142857142857\n",
            "\t\t\tVal Loss: 0.08866859786212444 - Val Accuracy: 0.496\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.08504179120063782\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.0856380962899753 - Train Accuracy: 0.6073660714285715\n",
            "\t\t\tVal Loss: 0.090353699401021 - Val Accuracy: 0.51\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.08471597731113434\n",
            "\t\tTrain step - Step 660, Loss 0.08453206717967987\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.08555360862186977 - Train Accuracy: 0.6209821428571428\n",
            "\t\t\tVal Loss: 0.08849484100937843 - Val Accuracy: 0.506\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.08506257832050323\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.08533713626010077 - Train Accuracy: 0.6357142857142857\n",
            "\t\t\tVal Loss: 0.09079381264746189 - Val Accuracy: 0.526\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.08567273616790771\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.08498691320419312 - Train Accuracy: 0.6448660714285714\n",
            "\t\t\tVal Loss: 0.08607728034257889 - Val Accuracy: 0.566\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.08283782750368118\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.08464936741760799 - Train Accuracy: 0.6515625\n",
            "\t\t\tVal Loss: 0.08551020175218582 - Val Accuracy: 0.586\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.0832478329539299\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.08459265870707376 - Train Accuracy: 0.6607142857142857\n",
            "\t\t\tVal Loss: 0.08441901579499245 - Val Accuracy: 0.532\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 810, Loss 0.08554869145154953\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.08419519130672727 - Train Accuracy: 0.6741071428571429\n",
            "\t\t\tVal Loss: 0.08694732002913952 - Val Accuracy: 0.57\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.083427295088768\n",
            "\t\tTrain step - Step 870, Loss 0.08584952354431152\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.08370801338127681 - Train Accuracy: 0.6808035714285714\n",
            "\t\t\tVal Loss: 0.09119266830384731 - Val Accuracy: 0.538\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.08389869332313538\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.08434623224394662 - Train Accuracy: 0.6953125\n",
            "\t\t\tVal Loss: 0.08743392117321491 - Val Accuracy: 0.568\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 930, Loss 0.0856945589184761\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.08467956015041896 - Train Accuracy: 0.6955357142857143\n",
            "\t\t\tVal Loss: 0.08952698297798634 - Val Accuracy: 0.566\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.08408549427986145\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.08426988188709532 - Train Accuracy: 0.7008928571428571\n",
            "\t\t\tVal Loss: 0.08679721504449844 - Val Accuracy: 0.56\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.08386439830064774\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.08359125767435346 - Train Accuracy: 0.7055803571428572\n",
            "\t\t\tVal Loss: 0.08612030372023582 - Val Accuracy: 0.588\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.07965582609176636\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.08349853030272893 - Train Accuracy: 0.7225446428571428\n",
            "\t\t\tVal Loss: 0.0898792203515768 - Val Accuracy: 0.542\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1050, Loss 0.08076027035713196\n",
            "\t\tTrain step - Step 1080, Loss 0.08165759593248367\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.08346568814345769 - Train Accuracy: 0.7205357142857143\n",
            "\t\t\tVal Loss: 0.08570113964378834 - Val Accuracy: 0.59\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.08342702686786652\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.08338729249579566 - Train Accuracy: 0.7174107142857142\n",
            "\t\t\tVal Loss: 0.08588854596018791 - Val Accuracy: 0.6\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.08289023488759995\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.0832450128027371 - Train Accuracy: 0.7397321428571428\n",
            "\t\t\tVal Loss: 0.08463269285857677 - Val Accuracy: 0.626\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.08198046684265137\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.08255780786275864 - Train Accuracy: 0.7410714285714286\n",
            "\t\t\tVal Loss: 0.08913303539156914 - Val Accuracy: 0.588\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1200, Loss 0.08102115243673325\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.08274818339518138 - Train Accuracy: 0.7459821428571428\n",
            "\t\t\tVal Loss: 0.09043572470545769 - Val Accuracy: 0.602\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.08334937691688538\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.08268141810383116 - Train Accuracy: 0.7587053571428571\n",
            "\t\t\tVal Loss: 0.09314550459384918 - Val Accuracy: 0.644\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.08090003579854965\n",
            "\t\tTrain step - Step 1290, Loss 0.08333155512809753\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.08252049578087671 - Train Accuracy: 0.7627232142857143\n",
            "\t\t\tVal Loss: 0.08572113886475563 - Val Accuracy: 0.592\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1320, Loss 0.08296596258878708\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.08334149590560368 - Train Accuracy: 0.7627232142857143\n",
            "\t\t\tVal Loss: 0.09091818146407604 - Val Accuracy: 0.588\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.08330898731946945\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.08286670105797904 - Train Accuracy: 0.7709821428571428\n",
            "\t\t\tVal Loss: 0.08787643350660801 - Val Accuracy: 0.592\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.08283185958862305\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.08219693409545081 - Train Accuracy: 0.7674107142857143\n",
            "\t\t\tVal Loss: 0.08473494090139866 - Val Accuracy: 0.644\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.08063854277133942\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.08207788233246122 - Train Accuracy: 0.7890625\n",
            "\t\t\tVal Loss: 0.08864539302885532 - Val Accuracy: 0.626\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1440, Loss 0.08109719306230545\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.08278780153819493 - Train Accuracy: 0.7770089285714286\n",
            "\t\t\tVal Loss: 0.08714435435831547 - Val Accuracy: 0.62\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.08191820234060287\n",
            "\t\tTrain step - Step 1500, Loss 0.08192573487758636\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.08222933752196175 - Train Accuracy: 0.7839285714285714\n",
            "\t\t\tVal Loss: 0.08937850221991539 - Val Accuracy: 0.622\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.08431636542081833\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.08254013614995138 - Train Accuracy: 0.7892857142857143\n",
            "\t\t\tVal Loss: 0.09137765876948833 - Val Accuracy: 0.61\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.08228431642055511\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.08253558576107026 - Train Accuracy: 0.7803571428571429\n",
            "\t\t\tVal Loss: 0.0861231479793787 - Val Accuracy: 0.624\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1590, Loss 0.08094489574432373\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.08228989371231624 - Train Accuracy: 0.7912946428571429\n",
            "\t\t\tVal Loss: 0.08928079903125763 - Val Accuracy: 0.63\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.08018763363361359\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.08207882067986898 - Train Accuracy: 0.7897321428571429\n",
            "\t\t\tVal Loss: 0.0896858461201191 - Val Accuracy: 0.602\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.08193749189376831\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.0821678129690034 - Train Accuracy: 0.784375\n",
            "\t\t\tVal Loss: 0.09357778169214725 - Val Accuracy: 0.584\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.08131305873394012\n",
            "\t\tTrain step - Step 1710, Loss 0.08291700482368469\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.08252524669681277 - Train Accuracy: 0.7866071428571428\n",
            "\t\t\tVal Loss: 0.0920326542109251 - Val Accuracy: 0.614\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1740, Loss 0.07776766270399094\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.07908342480659485 - Train Accuracy: 0.8323660714285714\n",
            "\t\t\tVal Loss: 0.08563918434083462 - Val Accuracy: 0.646\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1770, Loss 0.07671724259853363\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.07767947954790932 - Train Accuracy: 0.8308035714285714\n",
            "\t\t\tVal Loss: 0.08507834561169147 - Val Accuracy: 0.642\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1800, Loss 0.07708650082349777\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.07705117591789791 - Train Accuracy: 0.8444196428571429\n",
            "\t\t\tVal Loss: 0.08442674949765205 - Val Accuracy: 0.644\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1830, Loss 0.07774815708398819\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.07686060922486442 - Train Accuracy: 0.8395089285714286\n",
            "\t\t\tVal Loss: 0.08816472068428993 - Val Accuracy: 0.642\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1860, Loss 0.07676755636930466\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.07656965660197394 - Train Accuracy: 0.8455357142857143\n",
            "\t\t\tVal Loss: 0.08636150881648064 - Val Accuracy: 0.654\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1890, Loss 0.07667072117328644\n",
            "\t\tTrain step - Step 1920, Loss 0.07676234841346741\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.07644967160054615 - Train Accuracy: 0.8383928571428572\n",
            "\t\t\tVal Loss: 0.0854248721152544 - Val Accuracy: 0.638\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.07809602469205856\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.07633597297327858 - Train Accuracy: 0.846875\n",
            "\t\t\tVal Loss: 0.08680067025125027 - Val Accuracy: 0.646\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1980, Loss 0.0758744329214096\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.07618756485836846 - Train Accuracy: 0.8517857142857143\n",
            "\t\t\tVal Loss: 0.08694411441683769 - Val Accuracy: 0.634\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.07624103873968124\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.07609602021319525 - Train Accuracy: 0.8354910714285714\n",
            "\t\t\tVal Loss: 0.08526220358908176 - Val Accuracy: 0.642\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.07747680693864822\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.07611788702862603 - Train Accuracy: 0.8529017857142858\n",
            "\t\t\tVal Loss: 0.08826790936291218 - Val Accuracy: 0.63\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.07552926242351532\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.07592830934694834 - Train Accuracy: 0.8448660714285714\n",
            "\t\t\tVal Loss: 0.08765633404254913 - Val Accuracy: 0.652\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2100, Loss 0.07670490443706512\n",
            "\t\tTrain step - Step 2130, Loss 0.0762300118803978\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.0758668731365885 - Train Accuracy: 0.8412946428571428\n",
            "\t\t\tVal Loss: 0.08926950395107269 - Val Accuracy: 0.658\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.07576685398817062\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.07575546311480659 - Train Accuracy: 0.8482142857142857\n",
            "\t\t\tVal Loss: 0.08725428394973278 - Val Accuracy: 0.664\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.07554545998573303\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.07567967070000513 - Train Accuracy: 0.8493303571428571\n",
            "\t\t\tVal Loss: 0.09009554982185364 - Val Accuracy: 0.638\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2220, Loss 0.07616514712572098\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.07562748321465083 - Train Accuracy: 0.8566964285714286\n",
            "\t\t\tVal Loss: 0.08884074538946152 - Val Accuracy: 0.646\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2250, Loss 0.07443981617689133\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.07524812689849308 - Train Accuracy: 0.8544642857142857\n",
            "\t\t\tVal Loss: 0.08827967569231987 - Val Accuracy: 0.66\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2280, Loss 0.07497142255306244\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.0753140008875302 - Train Accuracy: 0.8533482142857143\n",
            "\t\t\tVal Loss: 0.08848515152931213 - Val Accuracy: 0.64\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2310, Loss 0.0767512172460556\n",
            "\t\tTrain step - Step 2340, Loss 0.07563325762748718\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.07532573214599064 - Train Accuracy: 0.8625\n",
            "\t\t\tVal Loss: 0.08884508907794952 - Val Accuracy: 0.64\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2370, Loss 0.07498332113027573\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.07540220852409091 - Train Accuracy: 0.8551339285714286\n",
            "\t\t\tVal Loss: 0.08881497010588646 - Val Accuracy: 0.646\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2400, Loss 0.07567638158798218\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.07529325761965343 - Train Accuracy: 0.8580357142857142\n",
            "\t\t\tVal Loss: 0.08890358172357082 - Val Accuracy: 0.642\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2430, Loss 0.07629459351301193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/55 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.07522905085768018 - Train Accuracy: 0.8582589285714286\n",
            "\t\t\tVal Loss: 0.08907974883913994 - Val Accuracy: 0.64\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 55/55 [00:02<00:00, 23.76it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 7:\n",
            "\t\tTrain Mean Accuracy: 0.685031887755102\n",
            "\t\tVal Mean Accuracy: 0.5508571428571429\n",
            "\t\tTest Accuracy: 0.368\n",
            "\n",
            "STARTING FINE TUNING STAGE 8...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n",
            "\t\tTrain step - Step 30, Loss 0.10507328063249588\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.12086161183459418 - Train Accuracy: 0.06964285714285715\n",
            "\t\t\tVal Loss: 0.11628197133541107 - Val Accuracy: 0.144\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.10381918400526047\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.10478063098021916 - Train Accuracy: 0.19419642857142858\n",
            "\t\t\tVal Loss: 0.1131639089435339 - Val Accuracy: 0.204\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.10367349535226822\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.1045571322951998 - Train Accuracy: 0.23102678571428573\n",
            "\t\t\tVal Loss: 0.10463538579642773 - Val Accuracy: 0.29\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.10614266991615295\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.10331892179591315 - Train Accuracy: 0.27700892857142856\n",
            "\t\t\tVal Loss: 0.10836915485560894 - Val Accuracy: 0.29\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 150, Loss 0.1012830063700676\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.10272715411015919 - Train Accuracy: 0.3073660714285714\n",
            "\t\t\tVal Loss: 0.10720912180840969 - Val Accuracy: 0.308\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.10002797096967697\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.10160947101456778 - Train Accuracy: 0.3419642857142857\n",
            "\t\t\tVal Loss: 0.10802513174712658 - Val Accuracy: 0.344\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.10151305049657822\n",
            "\t\tTrain step - Step 240, Loss 0.10138110816478729\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.10157141749347959 - Train Accuracy: 0.37790178571428573\n",
            "\t\t\tVal Loss: 0.10412735491991043 - Val Accuracy: 0.336\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 270, Loss 0.0970226302742958\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.10065633995192391 - Train Accuracy: 0.3904017857142857\n",
            "\t\t\tVal Loss: 0.10657740943133831 - Val Accuracy: 0.374\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.10275349020957947\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.10091208879436765 - Train Accuracy: 0.4133928571428571\n",
            "\t\t\tVal Loss: 0.10229648277163506 - Val Accuracy: 0.428\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.09981244802474976\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.09995568373373577 - Train Accuracy: 0.43794642857142857\n",
            "\t\t\tVal Loss: 0.10329405218362808 - Val Accuracy: 0.424\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.09802515059709549\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.1002663152558463 - Train Accuracy: 0.45022321428571427\n",
            "\t\t\tVal Loss: 0.10603603906929493 - Val Accuracy: 0.484\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.09792100638151169\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.10034328422376088 - Train Accuracy: 0.47232142857142856\n",
            "\t\t\tVal Loss: 0.10383473709225655 - Val Accuracy: 0.44\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 420, Loss 0.09685871005058289\n",
            "\t\tTrain step - Step 450, Loss 0.1007096916437149\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.09993984933410371 - Train Accuracy: 0.4979910714285714\n",
            "\t\t\tVal Loss: 0.10380785167217255 - Val Accuracy: 0.498\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.09713772684335709\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.09969454769577299 - Train Accuracy: 0.5006696428571429\n",
            "\t\t\tVal Loss: 0.10685046203434467 - Val Accuracy: 0.446\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.1003318578004837\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.09938974763665881 - Train Accuracy: 0.5330357142857143\n",
            "\t\t\tVal Loss: 0.10337063483893871 - Val Accuracy: 0.486\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 540, Loss 0.10058437287807465\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.09958291756255286 - Train Accuracy: 0.5386160714285714\n",
            "\t\t\tVal Loss: 0.09990880824625492 - Val Accuracy: 0.472\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.0989077240228653\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.09931316631180899 - Train Accuracy: 0.5511160714285714\n",
            "\t\t\tVal Loss: 0.10332305170595646 - Val Accuracy: 0.496\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.10014557838439941\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.09931450209447316 - Train Accuracy: 0.5651785714285714\n",
            "\t\t\tVal Loss: 0.10585981048643589 - Val Accuracy: 0.498\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.10006840527057648\n",
            "\t\tTrain step - Step 660, Loss 0.09946578741073608\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.09862854246582303 - Train Accuracy: 0.5758928571428571\n",
            "\t\t\tVal Loss: 0.1021591629832983 - Val Accuracy: 0.564\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.09694528579711914\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.09903979024716786 - Train Accuracy: 0.5886160714285714\n",
            "\t\t\tVal Loss: 0.10875038057565689 - Val Accuracy: 0.492\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.09912246465682983\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.09930890628269741 - Train Accuracy: 0.5997767857142857\n",
            "\t\t\tVal Loss: 0.1069569569081068 - Val Accuracy: 0.488\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.09660790115594864\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.09861735041652407 - Train Accuracy: 0.6060267857142857\n",
            "\t\t\tVal Loss: 0.10255243256688118 - Val Accuracy: 0.512\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.09894569218158722\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.0982971517103059 - Train Accuracy: 0.6209821428571428\n",
            "\t\t\tVal Loss: 0.10408169403672218 - Val Accuracy: 0.528\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 810, Loss 0.09714861959218979\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.09792395957878658 - Train Accuracy: 0.6354910714285714\n",
            "\t\t\tVal Loss: 0.10316553339362144 - Val Accuracy: 0.556\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.09836117178201675\n",
            "\t\tTrain step - Step 870, Loss 0.09901275485754013\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.09791808703116008 - Train Accuracy: 0.6419642857142858\n",
            "\t\t\tVal Loss: 0.10109228082001209 - Val Accuracy: 0.594\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.09900437295436859\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.09765177773577827 - Train Accuracy: 0.64375\n",
            "\t\t\tVal Loss: 0.10330300219357014 - Val Accuracy: 0.524\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 930, Loss 0.09741320461034775\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.097787130517619 - Train Accuracy: 0.6589285714285714\n",
            "\t\t\tVal Loss: 0.10366789437830448 - Val Accuracy: 0.562\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.0988784208893776\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.09778332476105009 - Train Accuracy: 0.6761160714285714\n",
            "\t\t\tVal Loss: 0.10424460470676422 - Val Accuracy: 0.536\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.09823150187730789\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.09724693915673664 - Train Accuracy: 0.6823660714285714\n",
            "\t\t\tVal Loss: 0.10526536777615547 - Val Accuracy: 0.548\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.0966256856918335\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.09747263533728463 - Train Accuracy: 0.6720982142857143\n",
            "\t\t\tVal Loss: 0.1000500749796629 - Val Accuracy: 0.566\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1050, Loss 0.09641864895820618\n",
            "\t\tTrain step - Step 1080, Loss 0.10040835291147232\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.0976267261164529 - Train Accuracy: 0.6854910714285715\n",
            "\t\t\tVal Loss: 0.10135822184383869 - Val Accuracy: 0.55\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.09744184464216232\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.09729268763746535 - Train Accuracy: 0.7011160714285715\n",
            "\t\t\tVal Loss: 0.10232189856469631 - Val Accuracy: 0.564\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.09679557383060455\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.09687495636088507 - Train Accuracy: 0.7046875\n",
            "\t\t\tVal Loss: 0.10474622249603271 - Val Accuracy: 0.562\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.09740250557661057\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.09757640255349023 - Train Accuracy: 0.6984375\n",
            "\t\t\tVal Loss: 0.10217747837305069 - Val Accuracy: 0.614\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1200, Loss 0.09905679523944855\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.09762246693883624 - Train Accuracy: 0.7176339285714286\n",
            "\t\t\tVal Loss: 0.10542431101202965 - Val Accuracy: 0.576\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.09658225625753403\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.09675638505390712 - Train Accuracy: 0.7236607142857143\n",
            "\t\t\tVal Loss: 0.10680588707327843 - Val Accuracy: 0.578\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.09542582184076309\n",
            "\t\tTrain step - Step 1290, Loss 0.09732796251773834\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.09708716379744665 - Train Accuracy: 0.7169642857142857\n",
            "\t\t\tVal Loss: 0.09856215864419937 - Val Accuracy: 0.602\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1320, Loss 0.09693506360054016\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.09661083029849189 - Train Accuracy: 0.7223214285714286\n",
            "\t\t\tVal Loss: 0.10218054987490177 - Val Accuracy: 0.624\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.09728524833917618\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.09644967764616012 - Train Accuracy: 0.7379464285714286\n",
            "\t\t\tVal Loss: 0.10188839584589005 - Val Accuracy: 0.632\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.09641286730766296\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.09728178977966309 - Train Accuracy: 0.7412946428571429\n",
            "\t\t\tVal Loss: 0.09724341705441475 - Val Accuracy: 0.594\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.09716407209634781\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.09665655323437282 - Train Accuracy: 0.7390625\n",
            "\t\t\tVal Loss: 0.10262550413608551 - Val Accuracy: 0.622\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1440, Loss 0.09587996453046799\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.09628444910049438 - Train Accuracy: 0.753125\n",
            "\t\t\tVal Loss: 0.10387438163161278 - Val Accuracy: 0.604\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.09528052061796188\n",
            "\t\tTrain step - Step 1500, Loss 0.09544618427753448\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.09658313138144357 - Train Accuracy: 0.7493303571428571\n",
            "\t\t\tVal Loss: 0.09827267378568649 - Val Accuracy: 0.634\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.09630744904279709\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.09617348653929574 - Train Accuracy: 0.7504464285714286\n",
            "\t\t\tVal Loss: 0.10581717267632484 - Val Accuracy: 0.634\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.09681139886379242\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.09680017403193883 - Train Accuracy: 0.7504464285714286\n",
            "\t\t\tVal Loss: 0.09805542975664139 - Val Accuracy: 0.592\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1590, Loss 0.09648655354976654\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.09653367740767342 - Train Accuracy: 0.7582589285714286\n",
            "\t\t\tVal Loss: 0.0995629783719778 - Val Accuracy: 0.62\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.09598445892333984\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.09628863015345164 - Train Accuracy: 0.7582589285714286\n",
            "\t\t\tVal Loss: 0.10643179900944233 - Val Accuracy: 0.604\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.09738216549158096\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.09636981998171125 - Train Accuracy: 0.7691964285714286\n",
            "\t\t\tVal Loss: 0.10034866444766521 - Val Accuracy: 0.636\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.09429989755153656\n",
            "\t\tTrain step - Step 1710, Loss 0.09646202623844147\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.09581003061362675 - Train Accuracy: 0.7676339285714285\n",
            "\t\t\tVal Loss: 0.10213577561080456 - Val Accuracy: 0.638\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1740, Loss 0.09244667738676071\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.09334173947572708 - Train Accuracy: 0.7982142857142858\n",
            "\t\t\tVal Loss: 0.09972691163420677 - Val Accuracy: 0.646\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1770, Loss 0.09386951476335526\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.09195675019706999 - Train Accuracy: 0.8029017857142857\n",
            "\t\t\tVal Loss: 0.09858973696827888 - Val Accuracy: 0.634\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1800, Loss 0.09150968492031097\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.09113475467477526 - Train Accuracy: 0.8066964285714285\n",
            "\t\t\tVal Loss: 0.09986482188105583 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1830, Loss 0.0910380631685257\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.09109641505139214 - Train Accuracy: 0.8087053571428572\n",
            "\t\t\tVal Loss: 0.09953160583972931 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1860, Loss 0.0908658355474472\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.09074906770672117 - Train Accuracy: 0.8080357142857143\n",
            "\t\t\tVal Loss: 0.10066157020628452 - Val Accuracy: 0.638\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1890, Loss 0.09001307934522629\n",
            "\t\tTrain step - Step 1920, Loss 0.09047646075487137\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.09072213023900985 - Train Accuracy: 0.8147321428571429\n",
            "\t\t\tVal Loss: 0.10130583122372627 - Val Accuracy: 0.638\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.09025993198156357\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.09041424436228616 - Train Accuracy: 0.8111607142857142\n",
            "\t\t\tVal Loss: 0.10094788856804371 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1980, Loss 0.08991201967000961\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.09035984639610563 - Train Accuracy: 0.8102678571428571\n",
            "\t\t\tVal Loss: 0.1041603796184063 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.09124574810266495\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.09053030333348683 - Train Accuracy: 0.8191964285714286\n",
            "\t\t\tVal Loss: 0.10247497074306011 - Val Accuracy: 0.626\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.09082930535078049\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.09019332442964827 - Train Accuracy: 0.8040178571428571\n",
            "\t\t\tVal Loss: 0.10211065597832203 - Val Accuracy: 0.65\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.08957625180482864\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.09005738816090993 - Train Accuracy: 0.8091517857142857\n",
            "\t\t\tVal Loss: 0.10264500789344311 - Val Accuracy: 0.646\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2100, Loss 0.08936916291713715\n",
            "\t\tTrain step - Step 2130, Loss 0.09028085321187973\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.09032215518610819 - Train Accuracy: 0.8011160714285714\n",
            "\t\t\tVal Loss: 0.10264705494046211 - Val Accuracy: 0.652\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.09185922145843506\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.09026664027145931 - Train Accuracy: 0.8160714285714286\n",
            "\t\t\tVal Loss: 0.10233958810567856 - Val Accuracy: 0.632\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.08995416760444641\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.08999630702393395 - Train Accuracy: 0.8131696428571429\n",
            "\t\t\tVal Loss: 0.10154501534998417 - Val Accuracy: 0.644\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2220, Loss 0.09015122056007385\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.09010937831231526 - Train Accuracy: 0.8102678571428571\n",
            "\t\t\tVal Loss: 0.10327161476016045 - Val Accuracy: 0.648\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2250, Loss 0.08896538615226746\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.0895823495728629 - Train Accuracy: 0.8176339285714286\n",
            "\t\t\tVal Loss: 0.10286286659538746 - Val Accuracy: 0.64\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2280, Loss 0.09000840783119202\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.08952378013304302 - Train Accuracy: 0.8223214285714285\n",
            "\t\t\tVal Loss: 0.10293092392385006 - Val Accuracy: 0.626\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2310, Loss 0.08905160427093506\n",
            "\t\tTrain step - Step 2340, Loss 0.09161336719989777\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.08952460842473166 - Train Accuracy: 0.8142857142857143\n",
            "\t\t\tVal Loss: 0.10249993205070496 - Val Accuracy: 0.664\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2370, Loss 0.08851272612810135\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.08971855917147227 - Train Accuracy: 0.8151785714285714\n",
            "\t\t\tVal Loss: 0.10304643027484417 - Val Accuracy: 0.648\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2400, Loss 0.09062644839286804\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.08956197840826852 - Train Accuracy: 0.8207589285714286\n",
            "\t\t\tVal Loss: 0.10290214605629444 - Val Accuracy: 0.636\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2430, Loss 0.08865669369697571\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/63 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.08963584687028613 - Train Accuracy: 0.8140625\n",
            "\t\t\tVal Loss: 0.10209926217794418 - Val Accuracy: 0.664\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 63/63 [00:02<00:00, 23.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 8:\n",
            "\t\tTrain Mean Accuracy: 0.6533609693877551\n",
            "\t\tVal Mean Accuracy: 0.5495428571428572\n",
            "\t\tTest Accuracy: 0.345\n",
            "\n",
            "STARTING FINE TUNING STAGE 9...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.11426303535699844\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.1313738744173731 - Train Accuracy: 0.0921875\n",
            "\t\t\tVal Loss: 0.14460070431232452 - Val Accuracy: 0.158\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.11395502090454102\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.1159219652414322 - Train Accuracy: 0.23370535714285715\n",
            "\t\t\tVal Loss: 0.12822476960718632 - Val Accuracy: 0.262\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.1150880977511406\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.11605699339083263 - Train Accuracy: 0.26808035714285716\n",
            "\t\t\tVal Loss: 0.1288835145533085 - Val Accuracy: 0.306\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.11272665858268738\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.11434067828314645 - Train Accuracy: 0.2955357142857143\n",
            "\t\t\tVal Loss: 0.12398938648402691 - Val Accuracy: 0.322\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 150, Loss 0.11260486394166946\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.11324497461318969 - Train Accuracy: 0.3267857142857143\n",
            "\t\t\tVal Loss: 0.12452305480837822 - Val Accuracy: 0.356\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.11295587569475174\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.11311917730740138 - Train Accuracy: 0.3502232142857143\n",
            "\t\t\tVal Loss: 0.1253592073917389 - Val Accuracy: 0.404\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.11317767202854156\n",
            "\t\tTrain step - Step 240, Loss 0.1127919927239418\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.11257624604872295 - Train Accuracy: 0.3890625\n",
            "\t\t\tVal Loss: 0.12314244173467159 - Val Accuracy: 0.472\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 270, Loss 0.11448661237955093\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.11208172334092004 - Train Accuracy: 0.4174107142857143\n",
            "\t\t\tVal Loss: 0.1249803714454174 - Val Accuracy: 0.446\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.11624211817979813\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.11203837799174445 - Train Accuracy: 0.44308035714285715\n",
            "\t\t\tVal Loss: 0.1226237379014492 - Val Accuracy: 0.48\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.11078505963087082\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.11205717091049466 - Train Accuracy: 0.4689732142857143\n",
            "\t\t\tVal Loss: 0.12395956926047802 - Val Accuracy: 0.47\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.10812358558177948\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.11131852035011564 - Train Accuracy: 0.48928571428571427\n",
            "\t\t\tVal Loss: 0.12221390753984451 - Val Accuracy: 0.504\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.11180911958217621\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.11110154007162366 - Train Accuracy: 0.4993303571428571\n",
            "\t\t\tVal Loss: 0.11984743177890778 - Val Accuracy: 0.524\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 420, Loss 0.10933925211429596\n",
            "\t\tTrain step - Step 450, Loss 0.11080970615148544\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.1110163158604077 - Train Accuracy: 0.5292410714285715\n",
            "\t\t\tVal Loss: 0.12241421639919281 - Val Accuracy: 0.522\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.11192454397678375\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.11120071091822216 - Train Accuracy: 0.5323660714285714\n",
            "\t\t\tVal Loss: 0.12614569254219532 - Val Accuracy: 0.482\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.11089777946472168\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.11063552030495234 - Train Accuracy: 0.5533482142857142\n",
            "\t\t\tVal Loss: 0.12075753509998322 - Val Accuracy: 0.554\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 540, Loss 0.11380273848772049\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.11093443802424839 - Train Accuracy: 0.5707589285714286\n",
            "\t\t\tVal Loss: 0.12263685837388039 - Val Accuracy: 0.532\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.11020338535308838\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.11072679119450705 - Train Accuracy: 0.578125\n",
            "\t\t\tVal Loss: 0.11966652981936932 - Val Accuracy: 0.56\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.11076465994119644\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.11037959030696325 - Train Accuracy: 0.5879464285714285\n",
            "\t\t\tVal Loss: 0.12089061923325062 - Val Accuracy: 0.596\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.11127766966819763\n",
            "\t\tTrain step - Step 660, Loss 0.11000685393810272\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.11015772010598864 - Train Accuracy: 0.6100446428571429\n",
            "\t\t\tVal Loss: 0.1174611933529377 - Val Accuracy: 0.586\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.11081098020076752\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.11015163596187319 - Train Accuracy: 0.6120535714285714\n",
            "\t\t\tVal Loss: 0.1219027154147625 - Val Accuracy: 0.562\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.10845492780208588\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.10990297687905175 - Train Accuracy: 0.6357142857142857\n",
            "\t\t\tVal Loss: 0.12105526588857174 - Val Accuracy: 0.616\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.11038727313280106\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.10953499568360192 - Train Accuracy: 0.6325892857142857\n",
            "\t\t\tVal Loss: 0.12210475280880928 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.10932858288288116\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.11022518277168274 - Train Accuracy: 0.6589285714285714\n",
            "\t\t\tVal Loss: 0.12130468524992466 - Val Accuracy: 0.594\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 810, Loss 0.1081826388835907\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.10980064996651241 - Train Accuracy: 0.65625\n",
            "\t\t\tVal Loss: 0.12272438779473305 - Val Accuracy: 0.572\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.11029088497161865\n",
            "\t\tTrain step - Step 870, Loss 0.111246258020401\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.11001629361084529 - Train Accuracy: 0.6479910714285714\n",
            "\t\t\tVal Loss: 0.11577143520116806 - Val Accuracy: 0.622\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.10916341841220856\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.10950422627585275 - Train Accuracy: 0.6756696428571428\n",
            "\t\t\tVal Loss: 0.11874584294855595 - Val Accuracy: 0.63\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 930, Loss 0.10800254344940186\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.10957617333957127 - Train Accuracy: 0.6714285714285714\n",
            "\t\t\tVal Loss: 0.12088100425899029 - Val Accuracy: 0.622\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.1121739000082016\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.10917730012110301 - Train Accuracy: 0.6866071428571429\n",
            "\t\t\tVal Loss: 0.11972615495324135 - Val Accuracy: 0.632\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.11089001595973969\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.10963149922234672 - Train Accuracy: 0.6819196428571429\n",
            "\t\t\tVal Loss: 0.11653542146086693 - Val Accuracy: 0.62\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.10750671476125717\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.1093578549368041 - Train Accuracy: 0.7013392857142857\n",
            "\t\t\tVal Loss: 0.12259018048644066 - Val Accuracy: 0.632\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1050, Loss 0.1076166108250618\n",
            "\t\tTrain step - Step 1080, Loss 0.10870763659477234\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.10900476149150304 - Train Accuracy: 0.7\n",
            "\t\t\tVal Loss: 0.11993231065571308 - Val Accuracy: 0.67\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.10787246376276016\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.10888036383049829 - Train Accuracy: 0.7091517857142857\n",
            "\t\t\tVal Loss: 0.11753339879214764 - Val Accuracy: 0.63\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.10711946338415146\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.108864954326834 - Train Accuracy: 0.7169642857142857\n",
            "\t\t\tVal Loss: 0.11878661252558231 - Val Accuracy: 0.662\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.10977017879486084\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.10881713181734085 - Train Accuracy: 0.7122767857142858\n",
            "\t\t\tVal Loss: 0.11896842904388905 - Val Accuracy: 0.636\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1200, Loss 0.1103377416729927\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.10891575110810144 - Train Accuracy: 0.7279017857142858\n",
            "\t\t\tVal Loss: 0.11708621308207512 - Val Accuracy: 0.652\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.10893502086400986\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.1091095358133316 - Train Accuracy: 0.7354910714285714\n",
            "\t\t\tVal Loss: 0.12001837603747845 - Val Accuracy: 0.664\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.10801547765731812\n",
            "\t\tTrain step - Step 1290, Loss 0.11052574217319489\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.10817513998065675 - Train Accuracy: 0.7299107142857143\n",
            "\t\t\tVal Loss: 0.1262775994837284 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1320, Loss 0.10727306455373764\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.10855878868273326 - Train Accuracy: 0.7359375\n",
            "\t\t\tVal Loss: 0.12449902296066284 - Val Accuracy: 0.632\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.10786160826683044\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.10843707408223834 - Train Accuracy: 0.7495535714285714\n",
            "\t\t\tVal Loss: 0.12006832100450993 - Val Accuracy: 0.636\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.10793035477399826\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.10837122074195317 - Train Accuracy: 0.7444196428571429\n",
            "\t\t\tVal Loss: 0.11590263620018959 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.10790464282035828\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.1083149601306234 - Train Accuracy: 0.7524553571428572\n",
            "\t\t\tVal Loss: 0.11799048632383347 - Val Accuracy: 0.668\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1440, Loss 0.11030181497335434\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.10872578003576823 - Train Accuracy: 0.7558035714285715\n",
            "\t\t\tVal Loss: 0.11545794643461704 - Val Accuracy: 0.67\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.10831344127655029\n",
            "\t\tTrain step - Step 1500, Loss 0.10685985535383224\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.10810312245573317 - Train Accuracy: 0.7564732142857142\n",
            "\t\t\tVal Loss: 0.11899536848068237 - Val Accuracy: 0.66\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.11185842007398605\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.10866067324365888 - Train Accuracy: 0.7450892857142857\n",
            "\t\t\tVal Loss: 0.11639255285263062 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.10762444138526917\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.10801656161035811 - Train Accuracy: 0.7696428571428572\n",
            "\t\t\tVal Loss: 0.12087980471551418 - Val Accuracy: 0.65\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1590, Loss 0.10606956481933594\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.10771997826439994 - Train Accuracy: 0.7734375\n",
            "\t\t\tVal Loss: 0.12353510782122612 - Val Accuracy: 0.636\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.11030521243810654\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.10788729105676924 - Train Accuracy: 0.7680803571428572\n",
            "\t\t\tVal Loss: 0.118313018232584 - Val Accuracy: 0.652\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.11022325605154037\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.10780390905482429 - Train Accuracy: 0.7767857142857143\n",
            "\t\t\tVal Loss: 0.12446638196706772 - Val Accuracy: 0.656\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.10826514661312103\n",
            "\t\tTrain step - Step 1710, Loss 0.10818243771791458\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.10792262469019209 - Train Accuracy: 0.7756696428571429\n",
            "\t\t\tVal Loss: 0.11505364812910557 - Val Accuracy: 0.664\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1740, Loss 0.10257526487112045\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.10537857030119215 - Train Accuracy: 0.7908482142857143\n",
            "\t\t\tVal Loss: 0.11831710673868656 - Val Accuracy: 0.724\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1770, Loss 0.1034957692027092\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.10361020628895079 - Train Accuracy: 0.8140625\n",
            "\t\t\tVal Loss: 0.11781432293355465 - Val Accuracy: 0.718\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1800, Loss 0.10234056413173676\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.10329841077327728 - Train Accuracy: 0.8122767857142857\n",
            "\t\t\tVal Loss: 0.1182685662060976 - Val Accuracy: 0.71\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1830, Loss 0.10549191385507584\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.1031685397028923 - Train Accuracy: 0.8200892857142857\n",
            "\t\t\tVal Loss: 0.11859122104942799 - Val Accuracy: 0.726\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1860, Loss 0.10178525745868683\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.10292451041085379 - Train Accuracy: 0.8212053571428571\n",
            "\t\t\tVal Loss: 0.11875791288912296 - Val Accuracy: 0.69\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1890, Loss 0.10222584754228592\n",
            "\t\tTrain step - Step 1920, Loss 0.10263586044311523\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.1029719312276159 - Train Accuracy: 0.8165178571428572\n",
            "\t\t\tVal Loss: 0.11927488632500172 - Val Accuracy: 0.696\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.10273456573486328\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.10294811597892216 - Train Accuracy: 0.8071428571428572\n",
            "\t\t\tVal Loss: 0.12020535580813885 - Val Accuracy: 0.708\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1980, Loss 0.1010243222117424\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.10298075037343161 - Train Accuracy: 0.8140625\n",
            "\t\t\tVal Loss: 0.12018474377691746 - Val Accuracy: 0.702\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.10133394598960876\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.10248769585575376 - Train Accuracy: 0.821875\n",
            "\t\t\tVal Loss: 0.11954109370708466 - Val Accuracy: 0.7\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.10055720806121826\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.10255939832755498 - Train Accuracy: 0.8234375\n",
            "\t\t\tVal Loss: 0.11989491619169712 - Val Accuracy: 0.698\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.10196443647146225\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.1025587186217308 - Train Accuracy: 0.8176339285714286\n",
            "\t\t\tVal Loss: 0.1198334600776434 - Val Accuracy: 0.708\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2100, Loss 0.10182765871286392\n",
            "\t\tTrain step - Step 2130, Loss 0.1013917326927185\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.10244930556842259 - Train Accuracy: 0.8178571428571428\n",
            "\t\t\tVal Loss: 0.12114223651587963 - Val Accuracy: 0.71\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.10214228183031082\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.10235757891620909 - Train Accuracy: 0.8209821428571429\n",
            "\t\t\tVal Loss: 0.12008657306432724 - Val Accuracy: 0.71\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.1019020602107048\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.1023697772196361 - Train Accuracy: 0.8145089285714285\n",
            "\t\t\tVal Loss: 0.12106961384415627 - Val Accuracy: 0.706\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2220, Loss 0.1017429530620575\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.10212010954107557 - Train Accuracy: 0.8176339285714286\n",
            "\t\t\tVal Loss: 0.1199569683521986 - Val Accuracy: 0.702\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2250, Loss 0.10148588567972183\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.10202495221580778 - Train Accuracy: 0.8252232142857143\n",
            "\t\t\tVal Loss: 0.12084208056330681 - Val Accuracy: 0.704\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2280, Loss 0.10220058262348175\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.10201152499232974 - Train Accuracy: 0.8303571428571429\n",
            "\t\t\tVal Loss: 0.12058247998356819 - Val Accuracy: 0.706\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2310, Loss 0.10110406577587128\n",
            "\t\tTrain step - Step 2340, Loss 0.10359261929988861\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.10182941683701106 - Train Accuracy: 0.8328125\n",
            "\t\t\tVal Loss: 0.12026545219123363 - Val Accuracy: 0.692\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2370, Loss 0.1016034260392189\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.1018368878534862 - Train Accuracy: 0.8238839285714286\n",
            "\t\t\tVal Loss: 0.12006583623588085 - Val Accuracy: 0.704\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2400, Loss 0.10397782921791077\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.10211572498083114 - Train Accuracy: 0.81875\n",
            "\t\t\tVal Loss: 0.12032232992351055 - Val Accuracy: 0.676\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2430, Loss 0.10043513029813766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/71 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.10194416280303682 - Train Accuracy: 0.8225446428571429\n",
            "\t\t\tVal Loss: 0.12071153521537781 - Val Accuracy: 0.714\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 71/71 [00:02<00:00, 24.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 9:\n",
            "\t\tTrain Mean Accuracy: 0.6687818877551022\n",
            "\t\tVal Mean Accuracy: 0.6072000000000002\n",
            "\t\tTest Accuracy: 0.3045555555555556\n",
            "\n",
            "STARTING FINE TUNING STAGE 10...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tTrain step - Step 30, Loss 0.13244080543518066\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.14683696457317896 - Train Accuracy: 0.06584821428571429\n",
            "\t\t\tVal Loss: 0.148294597864151 - Val Accuracy: 0.1\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.13357891142368317\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.13272118398121424 - Train Accuracy: 0.17388392857142856\n",
            "\t\t\tVal Loss: 0.135520588606596 - Val Accuracy: 0.192\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.13030777871608734\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.13218124977179935 - Train Accuracy: 0.215625\n",
            "\t\t\tVal Loss: 0.13758978992700577 - Val Accuracy: 0.206\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.13131222128868103\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.1309738435915538 - Train Accuracy: 0.25245535714285716\n",
            "\t\t\tVal Loss: 0.1373966559767723 - Val Accuracy: 0.256\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 150, Loss 0.13125643134117126\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.13015936570508138 - Train Accuracy: 0.29375\n",
            "\t\t\tVal Loss: 0.133500088006258 - Val Accuracy: 0.27\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.12940482795238495\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.12869591670376915 - Train Accuracy: 0.31339285714285714\n",
            "\t\t\tVal Loss: 0.1352332942187786 - Val Accuracy: 0.282\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.12822863459587097\n",
            "\t\tTrain step - Step 240, Loss 0.1299760341644287\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.12870191633701325 - Train Accuracy: 0.3339285714285714\n",
            "\t\t\tVal Loss: 0.13412682339549065 - Val Accuracy: 0.298\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 270, Loss 0.13066676259040833\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.12803422404187068 - Train Accuracy: 0.3549107142857143\n",
            "\t\t\tVal Loss: 0.13124603033065796 - Val Accuracy: 0.334\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.12507519125938416\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.127500738629273 - Train Accuracy: 0.37455357142857143\n",
            "\t\t\tVal Loss: 0.13074181228876114 - Val Accuracy: 0.396\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.126360684633255\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.12785648490701404 - Train Accuracy: 0.3991071428571429\n",
            "\t\t\tVal Loss: 0.1311735212802887 - Val Accuracy: 0.348\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.12902337312698364\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.1276064510856356 - Train Accuracy: 0.4107142857142857\n",
            "\t\t\tVal Loss: 0.12825345620512962 - Val Accuracy: 0.376\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.12945803999900818\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.12744322504316058 - Train Accuracy: 0.4328125\n",
            "\t\t\tVal Loss: 0.12971476092934608 - Val Accuracy: 0.39\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 420, Loss 0.12679490447044373\n",
            "\t\tTrain step - Step 450, Loss 0.12624910473823547\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.1266533251319613 - Train Accuracy: 0.4497767857142857\n",
            "\t\t\tVal Loss: 0.1336778849363327 - Val Accuracy: 0.416\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.12588876485824585\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.12656164254461016 - Train Accuracy: 0.46205357142857145\n",
            "\t\t\tVal Loss: 0.12761986069381237 - Val Accuracy: 0.43\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.12523098289966583\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.12647442796400615 - Train Accuracy: 0.484375\n",
            "\t\t\tVal Loss: 0.13248487375676632 - Val Accuracy: 0.398\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 540, Loss 0.12539368867874146\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.12630385288170407 - Train Accuracy: 0.4921875\n",
            "\t\t\tVal Loss: 0.13039547018706799 - Val Accuracy: 0.472\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.12442906945943832\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.12635324490921837 - Train Accuracy: 0.5136160714285715\n",
            "\t\t\tVal Loss: 0.13169514201581478 - Val Accuracy: 0.444\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.12762242555618286\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.12621992485863823 - Train Accuracy: 0.5167410714285714\n",
            "\t\t\tVal Loss: 0.12904087081551552 - Val Accuracy: 0.486\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.1265733391046524\n",
            "\t\tTrain step - Step 660, Loss 0.12673749029636383\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.12610420840127126 - Train Accuracy: 0.5325892857142858\n",
            "\t\t\tVal Loss: 0.13244301080703735 - Val Accuracy: 0.48\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.12539583444595337\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.12617086406264985 - Train Accuracy: 0.5488839285714285\n",
            "\t\t\tVal Loss: 0.1274934895336628 - Val Accuracy: 0.488\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.12556041777133942\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.1258199170231819 - Train Accuracy: 0.5611607142857142\n",
            "\t\t\tVal Loss: 0.12798776291310787 - Val Accuracy: 0.442\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.12617386877536774\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.12584437876939775 - Train Accuracy: 0.5674107142857143\n",
            "\t\t\tVal Loss: 0.12802468799054623 - Val Accuracy: 0.472\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.12585927546024323\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.12550543525389263 - Train Accuracy: 0.5866071428571429\n",
            "\t\t\tVal Loss: 0.13228373788297176 - Val Accuracy: 0.496\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 810, Loss 0.1224859207868576\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.12576605549880437 - Train Accuracy: 0.5892857142857143\n",
            "\t\t\tVal Loss: 0.12441175617277622 - Val Accuracy: 0.506\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.12423080205917358\n",
            "\t\tTrain step - Step 870, Loss 0.1291111558675766\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.12499554050820215 - Train Accuracy: 0.6102678571428571\n",
            "\t\t\tVal Loss: 0.13110733963549137 - Val Accuracy: 0.536\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.12444762885570526\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.12580427527427673 - Train Accuracy: 0.6075892857142857\n",
            "\t\t\tVal Loss: 0.13316594623029232 - Val Accuracy: 0.484\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 930, Loss 0.1261824518442154\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.12599520598139083 - Train Accuracy: 0.6178571428571429\n",
            "\t\t\tVal Loss: 0.13091844879090786 - Val Accuracy: 0.512\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.12413974851369858\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.12569046510117396 - Train Accuracy: 0.6290178571428572\n",
            "\t\t\tVal Loss: 0.12343190796673298 - Val Accuracy: 0.544\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.12494958937168121\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.12474755474499294 - Train Accuracy: 0.6484375\n",
            "\t\t\tVal Loss: 0.1286535393446684 - Val Accuracy: 0.538\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.1257065236568451\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.12496512596096311 - Train Accuracy: 0.6537946428571428\n",
            "\t\t\tVal Loss: 0.12368625216186047 - Val Accuracy: 0.522\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1050, Loss 0.12432561814785004\n",
            "\t\tTrain step - Step 1080, Loss 0.12505115568637848\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.12507281920739582 - Train Accuracy: 0.6584821428571429\n",
            "\t\t\tVal Loss: 0.13343792781233788 - Val Accuracy: 0.52\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.12522149085998535\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.12489904165267944 - Train Accuracy: 0.6542410714285715\n",
            "\t\t\tVal Loss: 0.13064463809132576 - Val Accuracy: 0.516\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.12601657211780548\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.12517882117203305 - Train Accuracy: 0.6712053571428571\n",
            "\t\t\tVal Loss: 0.12329341657459736 - Val Accuracy: 0.548\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.12471425533294678\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.12486095194305692 - Train Accuracy: 0.6785714285714286\n",
            "\t\t\tVal Loss: 0.12557656690478325 - Val Accuracy: 0.528\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1200, Loss 0.12272720038890839\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.12409273662737437 - Train Accuracy: 0.6888392857142858\n",
            "\t\t\tVal Loss: 0.12575982511043549 - Val Accuracy: 0.546\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.12345560640096664\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.1245909435408456 - Train Accuracy: 0.6877232142857143\n",
            "\t\t\tVal Loss: 0.13017198257148266 - Val Accuracy: 0.556\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.12736091017723083\n",
            "\t\tTrain step - Step 1290, Loss 0.12280537933111191\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.12437932597739355 - Train Accuracy: 0.7013392857142857\n",
            "\t\t\tVal Loss: 0.13227284513413906 - Val Accuracy: 0.542\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1320, Loss 0.12309915572404861\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.12436179454837526 - Train Accuracy: 0.6872767857142857\n",
            "\t\t\tVal Loss: 0.1319153904914856 - Val Accuracy: 0.564\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.12698693573474884\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.12454673945903778 - Train Accuracy: 0.6991071428571428\n",
            "\t\t\tVal Loss: 0.12529212795197964 - Val Accuracy: 0.55\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.12358266860246658\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.12430900952645711 - Train Accuracy: 0.7118303571428571\n",
            "\t\t\tVal Loss: 0.12727095931768417 - Val Accuracy: 0.554\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.12424851953983307\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.1241864983524595 - Train Accuracy: 0.7147321428571428\n",
            "\t\t\tVal Loss: 0.13063631020486355 - Val Accuracy: 0.57\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1440, Loss 0.12480267882347107\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.12418897769280843 - Train Accuracy: 0.7261160714285714\n",
            "\t\t\tVal Loss: 0.12813914194703102 - Val Accuracy: 0.594\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.12279954552650452\n",
            "\t\tTrain step - Step 1500, Loss 0.1257837414741516\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.12358835084097726 - Train Accuracy: 0.7265625\n",
            "\t\t\tVal Loss: 0.1311051920056343 - Val Accuracy: 0.55\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.1231062263250351\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.12373749954359872 - Train Accuracy: 0.7290178571428572\n",
            "\t\t\tVal Loss: 0.12465990148484707 - Val Accuracy: 0.584\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.12328645586967468\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.12354741841554642 - Train Accuracy: 0.7415178571428571\n",
            "\t\t\tVal Loss: 0.12662041373550892 - Val Accuracy: 0.602\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1590, Loss 0.12479453533887863\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.12412511238030025 - Train Accuracy: 0.7292410714285714\n",
            "\t\t\tVal Loss: 0.12313860096037388 - Val Accuracy: 0.624\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.12357959151268005\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.12355013404573713 - Train Accuracy: 0.7421875\n",
            "\t\t\tVal Loss: 0.1343739815056324 - Val Accuracy: 0.55\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.12244290113449097\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.12360701220376151 - Train Accuracy: 0.7428571428571429\n",
            "\t\t\tVal Loss: 0.13120233826339245 - Val Accuracy: 0.592\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.12361323833465576\n",
            "\t\tTrain step - Step 1710, Loss 0.12181524187326431\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.12302404599530356 - Train Accuracy: 0.7401785714285715\n",
            "\t\t\tVal Loss: 0.12675604224205017 - Val Accuracy: 0.552\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1740, Loss 0.11806849390268326\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.12003041335514614 - Train Accuracy: 0.7765625\n",
            "\t\t\tVal Loss: 0.12687473371624947 - Val Accuracy: 0.614\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1770, Loss 0.11896823346614838\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.11873090841940472 - Train Accuracy: 0.7832589285714285\n",
            "\t\t\tVal Loss: 0.1290187854319811 - Val Accuracy: 0.602\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1800, Loss 0.1177242174744606\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.11814055400235313 - Train Accuracy: 0.7832589285714285\n",
            "\t\t\tVal Loss: 0.12812410667538643 - Val Accuracy: 0.592\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1830, Loss 0.11780692636966705\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.11785564358745303 - Train Accuracy: 0.7895089285714286\n",
            "\t\t\tVal Loss: 0.13019432686269283 - Val Accuracy: 0.606\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1860, Loss 0.11788953840732574\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.11801057862383979 - Train Accuracy: 0.78125\n",
            "\t\t\tVal Loss: 0.1292490754276514 - Val Accuracy: 0.602\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1890, Loss 0.11826358735561371\n",
            "\t\tTrain step - Step 1920, Loss 0.11830844730138779\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.11766970242772784 - Train Accuracy: 0.7933035714285714\n",
            "\t\t\tVal Loss: 0.12882540374994278 - Val Accuracy: 0.618\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.11837846785783768\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.11770641484430858 - Train Accuracy: 0.790625\n",
            "\t\t\tVal Loss: 0.12969605438411236 - Val Accuracy: 0.618\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1980, Loss 0.11720437556505203\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.11769652196339199 - Train Accuracy: 0.7866071428571428\n",
            "\t\t\tVal Loss: 0.12944398634135723 - Val Accuracy: 0.574\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.12014419585466385\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.11755396106413432 - Train Accuracy: 0.7883928571428571\n",
            "\t\t\tVal Loss: 0.13006408140063286 - Val Accuracy: 0.62\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.11781254410743713\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.11736123178686414 - Train Accuracy: 0.8024553571428571\n",
            "\t\t\tVal Loss: 0.1301329992711544 - Val Accuracy: 0.58\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.11668567359447479\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.11717933756964548 - Train Accuracy: 0.7928571428571428\n",
            "\t\t\tVal Loss: 0.1296194065362215 - Val Accuracy: 0.596\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2100, Loss 0.11582228541374207\n",
            "\t\tTrain step - Step 2130, Loss 0.11852151900529861\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.11722284789596285 - Train Accuracy: 0.79375\n",
            "\t\t\tVal Loss: 0.13092263974249363 - Val Accuracy: 0.61\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.1191892996430397\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.11715107815606253 - Train Accuracy: 0.7944196428571428\n",
            "\t\t\tVal Loss: 0.1306249424815178 - Val Accuracy: 0.618\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.11715438216924667\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.11719478900943484 - Train Accuracy: 0.7953125\n",
            "\t\t\tVal Loss: 0.130048593506217 - Val Accuracy: 0.606\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2220, Loss 0.1154363825917244\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.11688855120113918 - Train Accuracy: 0.8002232142857143\n",
            "\t\t\tVal Loss: 0.13189986534416676 - Val Accuracy: 0.604\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2250, Loss 0.11745008081197739\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.11662918435675758 - Train Accuracy: 0.7959821428571429\n",
            "\t\t\tVal Loss: 0.13127249106764793 - Val Accuracy: 0.59\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2280, Loss 0.11916682869195938\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.11667699430670057 - Train Accuracy: 0.7948660714285715\n",
            "\t\t\tVal Loss: 0.12991354800760746 - Val Accuracy: 0.612\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2310, Loss 0.1160469502210617\n",
            "\t\tTrain step - Step 2340, Loss 0.11654498428106308\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.11691985364471164 - Train Accuracy: 0.7970982142857143\n",
            "\t\t\tVal Loss: 0.13132410310208797 - Val Accuracy: 0.614\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2370, Loss 0.11515417695045471\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.1167047673038074 - Train Accuracy: 0.8013392857142857\n",
            "\t\t\tVal Loss: 0.13253126107156277 - Val Accuracy: 0.62\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2400, Loss 0.11715476959943771\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.11678619725363595 - Train Accuracy: 0.8080357142857143\n",
            "\t\t\tVal Loss: 0.1314525119960308 - Val Accuracy: 0.614\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2430, Loss 0.11643413454294205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/79 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.11660488609756742 - Train Accuracy: 0.8046875\n",
            "\t\t\tVal Loss: 0.13008437305688858 - Val Accuracy: 0.604\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:03<00:00, 22.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 10:\n",
            "\t\tTrain Mean Accuracy: 0.6253922193877551\n",
            "\t\tVal Mean Accuracy: 0.5067142857142857\n",
            "\t\tTest Accuracy: 0.296\n",
            "\n",
            "\n",
            "Total time: 36 min 30 sec\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciGlvEWabcbD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc454e5f-9254-4d3f-e84e-9a22d7b11ced"
      },
      "source": [
        "import libs.plots as plots\n",
        "\n",
        "method = \"lwf\"\n",
        "plots.plot_accuracy_trend(test_accuracies, method, SEED)\n",
        "plots.plot_confusion_matrix(y_true, y_preds, method, SEED)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amC8Qy-yVw8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c670f15f-abd4-4dbc-d926-f45074ffb346"
      },
      "source": [
        "def save_accuracies(train_accuracies, val_accuracies, test_accuracies, output=OUTPUT_PATH):\n",
        "  with open(f\"{output}_accuracies.csv\", \"w\", encoding=\"utf8\") as f:\n",
        "    f.write(\"mean_train_acc,mean_val_acc,test_acc\\n\")\n",
        "    for train, val, test in zip(train_accuracies, val_accuracies, test_accuracies):\n",
        "      f.write(f\"{train},{val},{test}\\n\")\n",
        "    print(\"********** FILE SAVED **********\")\n",
        "\n",
        "\n",
        "save_accuracies(train_accuracies, val_accuracies, test_accuracies)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "********** FILE SAVED **********\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}