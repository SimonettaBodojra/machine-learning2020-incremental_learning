{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "IL_fine_tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "tvETQMX1ipNf",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1Df_YvI2mdf9SoeA1GZLecH_3_mthCWei\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab Account AI\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "wwN82ZV7ipNg",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RSnex0bmipNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_ROOT = 'cifar-100-python'\n",
        "CODE_ROOT = 'libs'\n",
        "import os\n",
        "if not os.path.isdir(DATASET_ROOT):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !rm -rf 'cifar-100-python.tar.gz'\n",
        "\n",
        "if not os.path.isdir(CODE_ROOT):\n",
        "  !git clone https://lore-lml:29f601e814e0446c5b17a9f6c3684d1cbd316bcf@github.com/lore-lml/machine-learning2020-incremental_learning.git\n",
        "  !mv 'machine-learning2020-incremental_learning/libs' '.'\n",
        "  !rm -rf 'machine-learning2020-incremental_learning'\n",
        "\n",
        "import logging\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import libs.utils as utils\n",
        "from libs.utils import one_hot_encode_labels\n",
        "\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7W9y67yoipNk",
        "colab_type": "text"
      },
      "source": [
        "**SET ARGUMENTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "r0hjWAP3ipNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "arguments = utils.get_arguments()\n",
        "\n",
        "DEVICE = arguments['DEVICE']\n",
        "NUM_CLASSES = arguments[\"NUM_CLASSES\"] \n",
        "\n",
        "BATCH_SIZE = arguments[\"BATCH_SIZE\"]        # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                                            # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = arguments[\"LR\"]                        # The initial Learning Rate\n",
        "MOMENTUM = arguments[\"MOMENTUM\"]            # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = arguments[\"WEIGHT_DECAY\"]    # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = arguments[\"NUM_EPOCHS\"]        # Total number of training epochs (iterations over dataset)\n",
        "GAMMA = arguments[\"GAMMA\"]                  # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = arguments[\"LOG_FREQUENCY\"]\n",
        "MILESTONES = arguments[\"MILESTONES\"]\n",
        "SEED = arguments[\"SEED\"]\n",
        "\n",
        "OUTPUT_PATH = \"RUN1\"\n",
        "LOSS_TYPE = 'bce'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "SaT8eFDNipNm",
        "colab_type": "text"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "m-ydAGw4ipNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms, eval_transforms = utils.get_train_eval_transforms()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "X7Naz_DdipNp",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "G-Xct5sNipNp",
        "colab_type": "code",
        "outputId": "47a10856-bb23-4e9b-a911-587c1a2972cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_val_dataset = utils.get_cifar_with_seed(DATASET_ROOT, train_transforms, src='train', seed=SEED)\n",
        "test_dataset = utils.get_cifar_with_seed(DATASET_ROOT, eval_transforms, src='test', seed=SEED)\n",
        "\n",
        "print(f\"Size Training Set: {len(train_val_dataset)}\")\n",
        "print(f\"Size Test Set: {len(test_dataset)}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size Training Set: 50000\n",
            "Size Test Set: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "31r5Hk_wipNr",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ue0HuTUhipNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net, criterion, optimizer, scheduler = utils.get_resnet(LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, resnet=32, loss_type=LOSS_TYPE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xZDP5yXBipNt",
        "colab_type": "text"
      },
      "source": [
        "**Train, Test, Validation functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "secPALBtipNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(net, train_loader, criterion, optimizer, current_step, device=DEVICE):\n",
        "    net.train()\n",
        "    cumulative_loss =.0\n",
        "    running_corrects = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "\n",
        "        if LOSS_TYPE == 'bce':\n",
        "            labels_enc = one_hot_encode_labels(labels).to(device)\n",
        "\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(images)\n",
        "        \n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        \n",
        "        loss = criterion(outputs, labels_enc) if LOSS_TYPE == 'bce'\\\n",
        "                                              else criterion(outputs, labels)\n",
        "        loss = criterion(outputs, labels_enc)\n",
        "        cumulative_loss += loss.item()\n",
        "        \n",
        "        if current_step != 0 and current_step % LOG_FREQUENCY == 0:\n",
        "                print('\\t\\tTrain step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_step += 1\n",
        "\n",
        "    return cumulative_loss / len(train_loader), running_corrects, current_step\n",
        "\n",
        "def validate(net, val_loader, criterion, optimizer, device=DEVICE):\n",
        "    net.eval()\n",
        "    cumulative_loss =.0\n",
        "    running_corrects = 0\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "\n",
        "        if LOSS_TYPE == 'bce':\n",
        "            labels_enc = one_hot_encode_labels(labels).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = net(images)\n",
        "        \n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        \n",
        "        loss = criterion(outputs, labels_enc) if LOSS_TYPE == 'bce'\\\n",
        "                                              else criterion(outputs, labels)\n",
        "        cumulative_loss += loss.item()\n",
        "\n",
        "\n",
        "    return cumulative_loss / len(val_loader), running_corrects\n",
        "\n",
        "def test(net, test_loader, device=DEVICE):\n",
        "    \n",
        "    running_corrects = 0\n",
        "    for images, labels in tqdm(test_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        net.eval()\n",
        "        outputs = net(images)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "    return running_corrects\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "s5SroLpaipNw",
        "colab_type": "text"
      },
      "source": [
        "**FINE TUNING FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "clnGi_eLipNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fine_tuning(net, train_val_dataset, test_dataset, criterion, optimizer, \n",
        "                scheduler, max_epoch=NUM_EPOCHS, file_path=OUTPUT_PATH, device=DEVICE):\n",
        "    import math, time\n",
        "    incremental_test = []\n",
        "    train_mean_stage_accuracies = []\n",
        "    val_mean_stage_accuracies = []\n",
        "    test_stage_accuracies = []\n",
        "    net = net.to(device)\n",
        "    cudnn.benchmark\n",
        "    start_time = time.time()\n",
        "    for stage in range(10):\n",
        "        print(f\"STARTING FINE TUNING STAGE {stage+1}...\")\n",
        "        # Get indices\n",
        "        # 4000 training, 1000 validation\n",
        "        train_idx, val_idx, test_idx = utils.get_kth_batch(train_val_dataset, test_dataset, stage,\n",
        "                                                                 seed=SEED, train_size=.9, get='indices')\n",
        "        \n",
        "        # Make test set incremental\n",
        "        incremental_test.extend(test_idx)\n",
        "        train_set, val_set, test_set = Subset(train_val_dataset, train_idx),\\\n",
        "                                       Subset(train_val_dataset, val_idx),\\\n",
        "                                       Subset(test_dataset, incremental_test)\n",
        "\n",
        "        # Build data loaders\n",
        "        curr_train_loader = utils.get_train_loader(train_set,batch_size=BATCH_SIZE)\n",
        "        curr_val_loader = utils.get_eval_loader(val_set, batch_size=BATCH_SIZE)\n",
        "        curr_test_loader = utils.get_eval_loader(test_set, batch_size=BATCH_SIZE)\n",
        "\n",
        "        # Init results\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        train_accuracies = []\n",
        "        val_accuracies = []\n",
        "        min_val_loss = -1\n",
        "        current_step = 0\n",
        "        tolerance = 10\n",
        "        for epoch in range(max_epoch):\n",
        "            print(f\"\\tSTARTING EPOCH {epoch+1} - LR={scheduler.get_last_lr()}...\")\n",
        "            curr_result = train_batch(net, curr_train_loader, criterion, optimizer, current_step, device)\n",
        "            curr_train_loss = curr_result[0]\n",
        "            curr_train_accuracy = curr_result[1] / float(BATCH_SIZE * len(curr_train_loader))\n",
        "            current_step = curr_result[2]\n",
        "            \n",
        "            train_losses.append(curr_train_loss)\n",
        "            train_accuracies.append(curr_train_accuracy)\n",
        "            scheduler.step()\n",
        "            \n",
        "            curr_val_loss, val_corrects = validate(net, curr_val_loader, criterion, optimizer, device)\n",
        "            val_losses.append(curr_val_loss)\n",
        "            curr_val_accuracy = val_corrects / float(len(val_set))\n",
        "            val_accuracies.append(curr_val_accuracy)\n",
        "            \n",
        "            print(f\"\\t\\tRESULT EPOCH {epoch+1}:\")\n",
        "            print(f\"\\t\\t\\tTrain Loss: {curr_train_loss} - Train Accuracy: {curr_train_accuracy}\")\n",
        "            print(f\"\\t\\t\\tVal Loss: {curr_val_loss} - Val Accuracy: {curr_val_accuracy}\\n\")\n",
        "            \n",
        "            if math.isnan(curr_val_loss):\n",
        "                tolerance -= 1\n",
        "            else:\n",
        "                tolerance = 10\n",
        "            \n",
        "            if tolerance == 0:\n",
        "                print(f\"STAGE {stage+1} -> EARLY STOPPING\\n\")\n",
        "                break\n",
        "            \n",
        "            if min_val_loss == -1 or min_val_loss > curr_val_loss:\n",
        "                min_val_loss = curr_val_loss\n",
        "                torch.save(net, f\"{file_path}_best_model_finetuning.pth\")\n",
        "        \n",
        "        net = torch.load(f\"{file_path}_best_model_finetuning.pth\").to(device)\n",
        "        epoch_test_accuracy = test(net, curr_test_loader, device) / float(len(test_set))\n",
        "        test_stage_accuracies.append(epoch_test_accuracy)\n",
        "        train_mean_stage_accuracies.append(np.mean(train_accuracies))\n",
        "        val_mean_stage_accuracies.append(np.mean(val_accuracies))\n",
        "        \n",
        "        print(f\"\\n\\tResults STAGE {stage+1}:\")\n",
        "        print(f\"\\t\\tTrain Mean Accuracy: {train_mean_stage_accuracies[stage]}\")\n",
        "        print(f\"\\t\\tVal Mean Accuracy: {val_mean_stage_accuracies[stage]}\")\n",
        "        print(f\"\\t\\tTest Accuracy: {test_stage_accuracies[stage]}\\n\")\n",
        "        break\n",
        "\n",
        "\n",
        "    total_time = int(time.time() - start_time)\n",
        "    min = int(total_time / 60)\n",
        "    sec = total_time % 60\n",
        "    print(f\"\\t\\t\\nTotal time: {min} min {sec} sec\\n\")\n",
        "        \n",
        "    return train_mean_stage_accuracies,\\\n",
        "           val_mean_stage_accuracies,\\\n",
        "           test_stage_accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "bvaYg8SiipNy",
        "colab_type": "text"
      },
      "source": [
        "**FINE TUNING START**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "i_ejvvl4ipNy",
        "colab_type": "code",
        "outputId": "ed47b4fd-c095-4057-d2a5-89248252d3b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_accuracies,\\\n",
        "val_accuracies,\\\n",
        "test_accuracies = fine_tuning(net, train_val_dataset, test_dataset,\n",
        "                              criterion, optimizer, scheduler, NUM_EPOCHS)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STARTING FINE TUNING STAGE 1...\n",
            "\tSTARTING EPOCH 1 - LR=[2]...\n",
            "\t\tTrain step - Step 30, Loss 0.03031882643699646\n",
            "\t\tRESULT EPOCH 1:\n",
            "\t\t\tTrain Loss: 0.0696706974612815 - Train Accuracy: 0.15066964285714285\n",
            "\t\t\tVal Loss: 0.03061675699427724 - Val Accuracy: 0.246\n",
            "\n",
            "\tSTARTING EPOCH 2 - LR=[2]...\n",
            "\t\tTrain step - Step 60, Loss 0.02650192193686962\n",
            "\t\tRESULT EPOCH 2:\n",
            "\t\t\tTrain Loss: 0.02753579073718616 - Train Accuracy: 0.3283482142857143\n",
            "\t\t\tVal Loss: 0.027505188714712858 - Val Accuracy: 0.358\n",
            "\n",
            "\tSTARTING EPOCH 3 - LR=[2]...\n",
            "\t\tTrain step - Step 90, Loss 0.025114838033914566\n",
            "\t\tRESULT EPOCH 3:\n",
            "\t\t\tTrain Loss: 0.024798935492123877 - Train Accuracy: 0.4232142857142857\n",
            "\t\t\tVal Loss: 0.024048271123319864 - Val Accuracy: 0.46\n",
            "\n",
            "\tSTARTING EPOCH 4 - LR=[2]...\n",
            "\t\tTrain step - Step 120, Loss 0.024512698873877525\n",
            "\t\tRESULT EPOCH 4:\n",
            "\t\t\tTrain Loss: 0.022848191005843028 - Train Accuracy: 0.4694196428571429\n",
            "\t\t\tVal Loss: 0.02442140458151698 - Val Accuracy: 0.442\n",
            "\n",
            "\tSTARTING EPOCH 5 - LR=[2]...\n",
            "\t\tTrain step - Step 150, Loss 0.01973157376050949\n",
            "\t\tRESULT EPOCH 5:\n",
            "\t\t\tTrain Loss: 0.02149642338710172 - Train Accuracy: 0.509375\n",
            "\t\t\tVal Loss: 0.026399535592645407 - Val Accuracy: 0.466\n",
            "\n",
            "\tSTARTING EPOCH 6 - LR=[2]...\n",
            "\t\tTrain step - Step 180, Loss 0.019020285457372665\n",
            "\t\tRESULT EPOCH 6:\n",
            "\t\t\tTrain Loss: 0.020287784508296422 - Train Accuracy: 0.5506696428571428\n",
            "\t\t\tVal Loss: 0.020994355902075768 - Val Accuracy: 0.55\n",
            "\n",
            "\tSTARTING EPOCH 7 - LR=[2]...\n",
            "\t\tTrain step - Step 210, Loss 0.019030699506402016\n",
            "\t\tTrain step - Step 240, Loss 0.018226146697998047\n",
            "\t\tRESULT EPOCH 7:\n",
            "\t\t\tTrain Loss: 0.018829451820680073 - Train Accuracy: 0.5908482142857143\n",
            "\t\t\tVal Loss: 0.020148642361164093 - Val Accuracy: 0.568\n",
            "\n",
            "\tSTARTING EPOCH 8 - LR=[2]...\n",
            "\t\tTrain step - Step 270, Loss 0.018785100430250168\n",
            "\t\tRESULT EPOCH 8:\n",
            "\t\t\tTrain Loss: 0.017989424536270754 - Train Accuracy: 0.609375\n",
            "\t\t\tVal Loss: 0.020090504549443722 - Val Accuracy: 0.55\n",
            "\n",
            "\tSTARTING EPOCH 9 - LR=[2]...\n",
            "\t\tTrain step - Step 300, Loss 0.016144467517733574\n",
            "\t\tRESULT EPOCH 9:\n",
            "\t\t\tTrain Loss: 0.016903319236423287 - Train Accuracy: 0.6450892857142857\n",
            "\t\t\tVal Loss: 0.021360694896429777 - Val Accuracy: 0.548\n",
            "\n",
            "\tSTARTING EPOCH 10 - LR=[2]...\n",
            "\t\tTrain step - Step 330, Loss 0.013403229415416718\n",
            "\t\tRESULT EPOCH 10:\n",
            "\t\t\tTrain Loss: 0.01580622922629118 - Train Accuracy: 0.6658482142857143\n",
            "\t\t\tVal Loss: 0.020146639551967382 - Val Accuracy: 0.598\n",
            "\n",
            "\tSTARTING EPOCH 11 - LR=[2]...\n",
            "\t\tTrain step - Step 360, Loss 0.014506308361887932\n",
            "\t\tRESULT EPOCH 11:\n",
            "\t\t\tTrain Loss: 0.015202588508171695 - Train Accuracy: 0.6814732142857143\n",
            "\t\t\tVal Loss: 0.018630762584507465 - Val Accuracy: 0.62\n",
            "\n",
            "\tSTARTING EPOCH 12 - LR=[2]...\n",
            "\t\tTrain step - Step 390, Loss 0.014894152991473675\n",
            "\t\tRESULT EPOCH 12:\n",
            "\t\t\tTrain Loss: 0.01486136567379747 - Train Accuracy: 0.6979910714285714\n",
            "\t\t\tVal Loss: 0.017849596217274666 - Val Accuracy: 0.64\n",
            "\n",
            "\tSTARTING EPOCH 13 - LR=[2]...\n",
            "\t\tTrain step - Step 420, Loss 0.012877542525529861\n",
            "\t\tTrain step - Step 450, Loss 0.016595548018813133\n",
            "\t\tRESULT EPOCH 13:\n",
            "\t\t\tTrain Loss: 0.013910126420004026 - Train Accuracy: 0.7069196428571428\n",
            "\t\t\tVal Loss: 0.017355946358293295 - Val Accuracy: 0.64\n",
            "\n",
            "\tSTARTING EPOCH 14 - LR=[2]...\n",
            "\t\tTrain step - Step 480, Loss 0.014020809903740883\n",
            "\t\tRESULT EPOCH 14:\n",
            "\t\t\tTrain Loss: 0.013388905195253237 - Train Accuracy: 0.7183035714285714\n",
            "\t\t\tVal Loss: 0.015536218415945768 - Val Accuracy: 0.7\n",
            "\n",
            "\tSTARTING EPOCH 15 - LR=[2]...\n",
            "\t\tTrain step - Step 510, Loss 0.010031483136117458\n",
            "\t\tRESULT EPOCH 15:\n",
            "\t\t\tTrain Loss: 0.012693691386708192 - Train Accuracy: 0.7350446428571429\n",
            "\t\t\tVal Loss: 0.015605200314894319 - Val Accuracy: 0.682\n",
            "\n",
            "\tSTARTING EPOCH 16 - LR=[2]...\n",
            "\t\tTrain step - Step 540, Loss 0.013355770148336887\n",
            "\t\tRESULT EPOCH 16:\n",
            "\t\t\tTrain Loss: 0.011960719898343086 - Train Accuracy: 0.7589285714285714\n",
            "\t\t\tVal Loss: 0.016443896340206265 - Val Accuracy: 0.662\n",
            "\n",
            "\tSTARTING EPOCH 17 - LR=[2]...\n",
            "\t\tTrain step - Step 570, Loss 0.012392171658575535\n",
            "\t\tRESULT EPOCH 17:\n",
            "\t\t\tTrain Loss: 0.011867673668478216 - Train Accuracy: 0.7560267857142857\n",
            "\t\t\tVal Loss: 0.01683460036292672 - Val Accuracy: 0.662\n",
            "\n",
            "\tSTARTING EPOCH 18 - LR=[2]...\n",
            "\t\tTrain step - Step 600, Loss 0.0110451215878129\n",
            "\t\tRESULT EPOCH 18:\n",
            "\t\t\tTrain Loss: 0.011231901416821139 - Train Accuracy: 0.7752232142857143\n",
            "\t\t\tVal Loss: 0.013632445828989148 - Val Accuracy: 0.718\n",
            "\n",
            "\tSTARTING EPOCH 19 - LR=[2]...\n",
            "\t\tTrain step - Step 630, Loss 0.011106177233159542\n",
            "\t\tTrain step - Step 660, Loss 0.01070567686110735\n",
            "\t\tRESULT EPOCH 19:\n",
            "\t\t\tTrain Loss: 0.010473124523247992 - Train Accuracy: 0.7872767857142857\n",
            "\t\t\tVal Loss: 0.013175811618566513 - Val Accuracy: 0.746\n",
            "\n",
            "\tSTARTING EPOCH 20 - LR=[2]...\n",
            "\t\tTrain step - Step 690, Loss 0.012019260786473751\n",
            "\t\tRESULT EPOCH 20:\n",
            "\t\t\tTrain Loss: 0.010583925380238465 - Train Accuracy: 0.7890625\n",
            "\t\t\tVal Loss: 0.018658001208677888 - Val Accuracy: 0.652\n",
            "\n",
            "\tSTARTING EPOCH 21 - LR=[2]...\n",
            "\t\tTrain step - Step 720, Loss 0.008668085560202599\n",
            "\t\tRESULT EPOCH 21:\n",
            "\t\t\tTrain Loss: 0.009925697983375618 - Train Accuracy: 0.8060267857142858\n",
            "\t\t\tVal Loss: 0.014866235200315714 - Val Accuracy: 0.686\n",
            "\n",
            "\tSTARTING EPOCH 22 - LR=[2]...\n",
            "\t\tTrain step - Step 750, Loss 0.011436340399086475\n",
            "\t\tRESULT EPOCH 22:\n",
            "\t\t\tTrain Loss: 0.010023544090134756 - Train Accuracy: 0.8013392857142857\n",
            "\t\t\tVal Loss: 0.014736535493284464 - Val Accuracy: 0.702\n",
            "\n",
            "\tSTARTING EPOCH 23 - LR=[2]...\n",
            "\t\tTrain step - Step 780, Loss 0.010829475708305836\n",
            "\t\tRESULT EPOCH 23:\n",
            "\t\t\tTrain Loss: 0.009657275290893656 - Train Accuracy: 0.8113839285714286\n",
            "\t\t\tVal Loss: 0.01382229058071971 - Val Accuracy: 0.732\n",
            "\n",
            "\tSTARTING EPOCH 24 - LR=[2]...\n",
            "\t\tTrain step - Step 810, Loss 0.011287848465144634\n",
            "\t\tRESULT EPOCH 24:\n",
            "\t\t\tTrain Loss: 0.009393802378326654 - Train Accuracy: 0.8087053571428572\n",
            "\t\t\tVal Loss: 0.013293738476932049 - Val Accuracy: 0.738\n",
            "\n",
            "\tSTARTING EPOCH 25 - LR=[2]...\n",
            "\t\tTrain step - Step 840, Loss 0.006625392474234104\n",
            "\t\tTrain step - Step 870, Loss 0.008010746911168098\n",
            "\t\tRESULT EPOCH 25:\n",
            "\t\t\tTrain Loss: 0.008552377524652651 - Train Accuracy: 0.8316964285714286\n",
            "\t\t\tVal Loss: 0.01337820990011096 - Val Accuracy: 0.75\n",
            "\n",
            "\tSTARTING EPOCH 26 - LR=[2]...\n",
            "\t\tTrain step - Step 900, Loss 0.008364391513168812\n",
            "\t\tRESULT EPOCH 26:\n",
            "\t\t\tTrain Loss: 0.008265645961676326 - Train Accuracy: 0.8395089285714286\n",
            "\t\t\tVal Loss: 0.013618760043755174 - Val Accuracy: 0.74\n",
            "\n",
            "\tSTARTING EPOCH 27 - LR=[2]...\n",
            "\t\tTrain step - Step 930, Loss 0.00783422589302063\n",
            "\t\tRESULT EPOCH 27:\n",
            "\t\t\tTrain Loss: 0.008792140973465784 - Train Accuracy: 0.828125\n",
            "\t\t\tVal Loss: 0.012905775336548686 - Val Accuracy: 0.742\n",
            "\n",
            "\tSTARTING EPOCH 28 - LR=[2]...\n",
            "\t\tTrain step - Step 960, Loss 0.007688756566494703\n",
            "\t\tRESULT EPOCH 28:\n",
            "\t\t\tTrain Loss: 0.007823962359023946 - Train Accuracy: 0.8502232142857142\n",
            "\t\t\tVal Loss: 0.012871969025582075 - Val Accuracy: 0.758\n",
            "\n",
            "\tSTARTING EPOCH 29 - LR=[2]...\n",
            "\t\tTrain step - Step 990, Loss 0.0073808846063911915\n",
            "\t\tRESULT EPOCH 29:\n",
            "\t\t\tTrain Loss: 0.007734142190643719 - Train Accuracy: 0.85\n",
            "\t\t\tVal Loss: 0.011965864337980747 - Val Accuracy: 0.774\n",
            "\n",
            "\tSTARTING EPOCH 30 - LR=[2]...\n",
            "\t\tTrain step - Step 1020, Loss 0.007053211331367493\n",
            "\t\tRESULT EPOCH 30:\n",
            "\t\t\tTrain Loss: 0.0075030804611742495 - Train Accuracy: 0.8542410714285714\n",
            "\t\t\tVal Loss: 0.011481506749987602 - Val Accuracy: 0.778\n",
            "\n",
            "\tSTARTING EPOCH 31 - LR=[2]...\n",
            "\t\tTrain step - Step 1050, Loss 0.0068459962494671345\n",
            "\t\tTrain step - Step 1080, Loss 0.009104346856474876\n",
            "\t\tRESULT EPOCH 31:\n",
            "\t\t\tTrain Loss: 0.007559029598321234 - Train Accuracy: 0.8582589285714286\n",
            "\t\t\tVal Loss: 0.017657931661233306 - Val Accuracy: 0.688\n",
            "\n",
            "\tSTARTING EPOCH 32 - LR=[2]...\n",
            "\t\tTrain step - Step 1110, Loss 0.006025393959134817\n",
            "\t\tRESULT EPOCH 32:\n",
            "\t\t\tTrain Loss: 0.007223228311964444 - Train Accuracy: 0.8555803571428572\n",
            "\t\t\tVal Loss: 0.013342018239200115 - Val Accuracy: 0.742\n",
            "\n",
            "\tSTARTING EPOCH 33 - LR=[2]...\n",
            "\t\tTrain step - Step 1140, Loss 0.0054090810008347034\n",
            "\t\tRESULT EPOCH 33:\n",
            "\t\t\tTrain Loss: 0.006890390414212431 - Train Accuracy: 0.8694196428571429\n",
            "\t\t\tVal Loss: 0.013020726619288325 - Val Accuracy: 0.746\n",
            "\n",
            "\tSTARTING EPOCH 34 - LR=[2]...\n",
            "\t\tTrain step - Step 1170, Loss 0.007204179652035236\n",
            "\t\tRESULT EPOCH 34:\n",
            "\t\t\tTrain Loss: 0.0066844063411865915 - Train Accuracy: 0.875\n",
            "\t\t\tVal Loss: 0.012698012171313167 - Val Accuracy: 0.75\n",
            "\n",
            "\tSTARTING EPOCH 35 - LR=[2]...\n",
            "\t\tTrain step - Step 1200, Loss 0.004765157122164965\n",
            "\t\tRESULT EPOCH 35:\n",
            "\t\t\tTrain Loss: 0.006303972298545497 - Train Accuracy: 0.8832589285714286\n",
            "\t\t\tVal Loss: 0.013039723271504045 - Val Accuracy: 0.76\n",
            "\n",
            "\tSTARTING EPOCH 36 - LR=[2]...\n",
            "\t\tTrain step - Step 1230, Loss 0.005432752426713705\n",
            "\t\tRESULT EPOCH 36:\n",
            "\t\t\tTrain Loss: 0.006812827355627503 - Train Accuracy: 0.8683035714285714\n",
            "\t\t\tVal Loss: 0.013573428150266409 - Val Accuracy: 0.76\n",
            "\n",
            "\tSTARTING EPOCH 37 - LR=[2]...\n",
            "\t\tTrain step - Step 1260, Loss 0.005575912073254585\n",
            "\t\tTrain step - Step 1290, Loss 0.005492771044373512\n",
            "\t\tRESULT EPOCH 37:\n",
            "\t\t\tTrain Loss: 0.006409305653401784 - Train Accuracy: 0.8752232142857143\n",
            "\t\t\tVal Loss: 0.018117792438715696 - Val Accuracy: 0.68\n",
            "\n",
            "\tSTARTING EPOCH 38 - LR=[2]...\n",
            "\t\tTrain step - Step 1320, Loss 0.006023228634148836\n",
            "\t\tRESULT EPOCH 38:\n",
            "\t\t\tTrain Loss: 0.0057874817534216815 - Train Accuracy: 0.8921875\n",
            "\t\t\tVal Loss: 0.013228599447757006 - Val Accuracy: 0.748\n",
            "\n",
            "\tSTARTING EPOCH 39 - LR=[2]...\n",
            "\t\tTrain step - Step 1350, Loss 0.006551000755280256\n",
            "\t\tRESULT EPOCH 39:\n",
            "\t\t\tTrain Loss: 0.005903350528595703 - Train Accuracy: 0.8897321428571429\n",
            "\t\t\tVal Loss: 0.015090225730091333 - Val Accuracy: 0.726\n",
            "\n",
            "\tSTARTING EPOCH 40 - LR=[2]...\n",
            "\t\tTrain step - Step 1380, Loss 0.0058760857209563255\n",
            "\t\tRESULT EPOCH 40:\n",
            "\t\t\tTrain Loss: 0.006341534680021661 - Train Accuracy: 0.8776785714285714\n",
            "\t\t\tVal Loss: 0.013365291291847825 - Val Accuracy: 0.756\n",
            "\n",
            "\tSTARTING EPOCH 41 - LR=[2]...\n",
            "\t\tTrain step - Step 1410, Loss 0.006561892107129097\n",
            "\t\tRESULT EPOCH 41:\n",
            "\t\t\tTrain Loss: 0.0055156446261597535 - Train Accuracy: 0.8979910714285714\n",
            "\t\t\tVal Loss: 0.011824927292764187 - Val Accuracy: 0.788\n",
            "\n",
            "\tSTARTING EPOCH 42 - LR=[2]...\n",
            "\t\tTrain step - Step 1440, Loss 0.0044604879803955555\n",
            "\t\tRESULT EPOCH 42:\n",
            "\t\t\tTrain Loss: 0.005249067176399487 - Train Accuracy: 0.9026785714285714\n",
            "\t\t\tVal Loss: 0.011734175961464643 - Val Accuracy: 0.808\n",
            "\n",
            "\tSTARTING EPOCH 43 - LR=[2]...\n",
            "\t\tTrain step - Step 1470, Loss 0.005514109041541815\n",
            "\t\tTrain step - Step 1500, Loss 0.005513377021998167\n",
            "\t\tRESULT EPOCH 43:\n",
            "\t\t\tTrain Loss: 0.0052330066915601495 - Train Accuracy: 0.9060267857142857\n",
            "\t\t\tVal Loss: 0.010552947176620364 - Val Accuracy: 0.8\n",
            "\n",
            "\tSTARTING EPOCH 44 - LR=[2]...\n",
            "\t\tTrain step - Step 1530, Loss 0.005565811414271593\n",
            "\t\tRESULT EPOCH 44:\n",
            "\t\t\tTrain Loss: 0.004857286751004202 - Train Accuracy: 0.9113839285714286\n",
            "\t\t\tVal Loss: 0.013179406058043242 - Val Accuracy: 0.77\n",
            "\n",
            "\tSTARTING EPOCH 45 - LR=[2]...\n",
            "\t\tTrain step - Step 1560, Loss 0.002530061872676015\n",
            "\t\tRESULT EPOCH 45:\n",
            "\t\t\tTrain Loss: 0.004719179649172085 - Train Accuracy: 0.9102678571428572\n",
            "\t\t\tVal Loss: 0.014234865782782435 - Val Accuracy: 0.738\n",
            "\n",
            "\tSTARTING EPOCH 46 - LR=[2]...\n",
            "\t\tTrain step - Step 1590, Loss 0.005095154512673616\n",
            "\t\tRESULT EPOCH 46:\n",
            "\t\t\tTrain Loss: 0.005160288871931178 - Train Accuracy: 0.9042410714285715\n",
            "\t\t\tVal Loss: 0.01505950279533863 - Val Accuracy: 0.752\n",
            "\n",
            "\tSTARTING EPOCH 47 - LR=[2]...\n",
            "\t\tTrain step - Step 1620, Loss 0.004666440188884735\n",
            "\t\tRESULT EPOCH 47:\n",
            "\t\t\tTrain Loss: 0.005044127475204213 - Train Accuracy: 0.9055803571428571\n",
            "\t\t\tVal Loss: 0.010828949743881822 - Val Accuracy: 0.804\n",
            "\n",
            "\tSTARTING EPOCH 48 - LR=[2]...\n",
            "\t\tTrain step - Step 1650, Loss 0.0035924166440963745\n",
            "\t\tRESULT EPOCH 48:\n",
            "\t\t\tTrain Loss: 0.004532985495669501 - Train Accuracy: 0.9183035714285714\n",
            "\t\t\tVal Loss: 0.012886301963590086 - Val Accuracy: 0.774\n",
            "\n",
            "\tSTARTING EPOCH 49 - LR=[2]...\n",
            "\t\tTrain step - Step 1680, Loss 0.006798447109758854\n",
            "\t\tTrain step - Step 1710, Loss 0.004972493276000023\n",
            "\t\tRESULT EPOCH 49:\n",
            "\t\t\tTrain Loss: 0.005015347113034555 - Train Accuracy: 0.9064732142857143\n",
            "\t\t\tVal Loss: 0.014566754223778844 - Val Accuracy: 0.774\n",
            "\n",
            "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1740, Loss 0.0026124559808522463\n",
            "\t\tRESULT EPOCH 50:\n",
            "\t\t\tTrain Loss: 0.0032894835208675693 - Train Accuracy: 0.9453125\n",
            "\t\t\tVal Loss: 0.00923304504249245 - Val Accuracy: 0.85\n",
            "\n",
            "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1770, Loss 0.001659488887526095\n",
            "\t\tRESULT EPOCH 51:\n",
            "\t\t\tTrain Loss: 0.0023827216953837445 - Train Accuracy: 0.9676339285714286\n",
            "\t\t\tVal Loss: 0.00872690009418875 - Val Accuracy: 0.84\n",
            "\n",
            "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1800, Loss 0.0015002017607912421\n",
            "\t\tRESULT EPOCH 52:\n",
            "\t\t\tTrain Loss: 0.0021252675248043876 - Train Accuracy: 0.9689732142857143\n",
            "\t\t\tVal Loss: 0.008942955289967358 - Val Accuracy: 0.844\n",
            "\n",
            "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1830, Loss 0.002466195495799184\n",
            "\t\tRESULT EPOCH 53:\n",
            "\t\t\tTrain Loss: 0.0019879252217443926 - Train Accuracy: 0.9691964285714286\n",
            "\t\t\tVal Loss: 0.008543591247871518 - Val Accuracy: 0.854\n",
            "\n",
            "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1860, Loss 0.002075477736070752\n",
            "\t\tRESULT EPOCH 54:\n",
            "\t\t\tTrain Loss: 0.001820851765972163 - Train Accuracy: 0.9734375\n",
            "\t\t\tVal Loss: 0.008917172672227025 - Val Accuracy: 0.856\n",
            "\n",
            "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1890, Loss 0.0016400604508817196\n",
            "\t\tTrain step - Step 1920, Loss 0.0014042319962754846\n",
            "\t\tRESULT EPOCH 55:\n",
            "\t\t\tTrain Loss: 0.0017006878258793482 - Train Accuracy: 0.9772321428571429\n",
            "\t\t\tVal Loss: 0.00868575053755194 - Val Accuracy: 0.844\n",
            "\n",
            "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1950, Loss 0.0019308071350678802\n",
            "\t\tRESULT EPOCH 56:\n",
            "\t\t\tTrain Loss: 0.0016607280471362174 - Train Accuracy: 0.9772321428571429\n",
            "\t\t\tVal Loss: 0.008923662127926946 - Val Accuracy: 0.85\n",
            "\n",
            "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
            "\t\tTrain step - Step 1980, Loss 0.0014250028179958463\n",
            "\t\tRESULT EPOCH 57:\n",
            "\t\t\tTrain Loss: 0.0014773729174131793 - Train Accuracy: 0.9828125\n",
            "\t\t\tVal Loss: 0.008891572942957282 - Val Accuracy: 0.852\n",
            "\n",
            "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2010, Loss 0.0007318493444472551\n",
            "\t\tRESULT EPOCH 58:\n",
            "\t\t\tTrain Loss: 0.0014907147918295648 - Train Accuracy: 0.9803571428571428\n",
            "\t\t\tVal Loss: 0.00865490606520325 - Val Accuracy: 0.856\n",
            "\n",
            "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2040, Loss 0.0022366230841726065\n",
            "\t\tRESULT EPOCH 59:\n",
            "\t\t\tTrain Loss: 0.0014337000802957585 - Train Accuracy: 0.9814732142857143\n",
            "\t\t\tVal Loss: 0.009650299209170043 - Val Accuracy: 0.84\n",
            "\n",
            "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2070, Loss 0.0015026971232146025\n",
            "\t\tRESULT EPOCH 60:\n",
            "\t\t\tTrain Loss: 0.0013270909399060267 - Train Accuracy: 0.9821428571428571\n",
            "\t\t\tVal Loss: 0.009041318553499877 - Val Accuracy: 0.85\n",
            "\n",
            "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2100, Loss 0.0009501241729594767\n",
            "\t\tTrain step - Step 2130, Loss 0.001078399596735835\n",
            "\t\tRESULT EPOCH 61:\n",
            "\t\t\tTrain Loss: 0.001360373298770615 - Train Accuracy: 0.9828125\n",
            "\t\t\tVal Loss: 0.008594100596383214 - Val Accuracy: 0.86\n",
            "\n",
            "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2160, Loss 0.0008339653722941875\n",
            "\t\tRESULT EPOCH 62:\n",
            "\t\t\tTrain Loss: 0.0011891192523762583 - Train Accuracy: 0.9877232142857143\n",
            "\t\t\tVal Loss: 0.008638937841169536 - Val Accuracy: 0.862\n",
            "\n",
            "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
            "\t\tTrain step - Step 2190, Loss 0.0011242406908422709\n",
            "\t\tRESULT EPOCH 63:\n",
            "\t\t\tTrain Loss: 0.0010967276424967817 - Train Accuracy: 0.9886160714285714\n",
            "\t\t\tVal Loss: 0.00883439858444035 - Val Accuracy: 0.848\n",
            "\n",
            "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2220, Loss 0.0005883927224203944\n",
            "\t\tRESULT EPOCH 64:\n",
            "\t\t\tTrain Loss: 0.0010014434087289763 - Train Accuracy: 0.9895089285714286\n",
            "\t\t\tVal Loss: 0.008816078654490411 - Val Accuracy: 0.866\n",
            "\n",
            "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2250, Loss 0.0007182654808275402\n",
            "\t\tRESULT EPOCH 65:\n",
            "\t\t\tTrain Loss: 0.0010201612653742943 - Train Accuracy: 0.9890625\n",
            "\t\t\tVal Loss: 0.008623614674434066 - Val Accuracy: 0.866\n",
            "\n",
            "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2280, Loss 0.0005700952606275678\n",
            "\t\tRESULT EPOCH 66:\n",
            "\t\t\tTrain Loss: 0.0009016951936895826 - Train Accuracy: 0.9921875\n",
            "\t\t\tVal Loss: 0.009655259316787124 - Val Accuracy: 0.848\n",
            "\n",
            "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2310, Loss 0.001203370513394475\n",
            "\t\tTrain step - Step 2340, Loss 0.0006432115333154798\n",
            "\t\tRESULT EPOCH 67:\n",
            "\t\t\tTrain Loss: 0.00096808853974965 - Train Accuracy: 0.9890625\n",
            "\t\t\tVal Loss: 0.008353503071703017 - Val Accuracy: 0.862\n",
            "\n",
            "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2370, Loss 0.0008720329497009516\n",
            "\t\tRESULT EPOCH 68:\n",
            "\t\t\tTrain Loss: 0.0009110861940176359 - Train Accuracy: 0.9928571428571429\n",
            "\t\t\tVal Loss: 0.008280190057121217 - Val Accuracy: 0.836\n",
            "\n",
            "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2400, Loss 0.0012333225458860397\n",
            "\t\tRESULT EPOCH 69:\n",
            "\t\t\tTrain Loss: 0.0009240649723713951 - Train Accuracy: 0.9926339285714286\n",
            "\t\t\tVal Loss: 0.009277896024286747 - Val Accuracy: 0.86\n",
            "\n",
            "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
            "\t\tTrain step - Step 2430, Loss 0.0009286944405175745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t\tRESULT EPOCH 70:\n",
            "\t\t\tTrain Loss: 0.0009109359675286604 - Train Accuracy: 0.9912946428571429\n",
            "\t\t\tVal Loss: 0.007920937961898744 - Val Accuracy: 0.872\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 12.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\tResults STAGE 1:\n",
            "\t\tTrain Mean Accuracy: 0.8305644132653062\n",
            "\t\tVal Mean Accuracy: 0.7312571428571428\n",
            "\t\tTest Accuracy: 0.848\n",
            "\n",
            "\t\t\n",
            "Total time: 6 min 7 sec\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}