{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "colab": {
   "name": "IL_fine_tuning.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "tvETQMX1ipNf",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1Df_YvI2mdf9SoeA1GZLecH_3_mthCWei\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab Account AI\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5-LoM_h1IXAi",
    "colab_type": "code",
    "outputId": "4a03e136-83d0-4473-c96c-f6f189866ddb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "# memory footprint support libraries/code\n",
    "\"\"\"!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\"\"\"\n",
    "\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isn’t guaranteed\n",
    "gpu = GPUs[0]\n",
    "print(gpu.name)"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Tesla P100-PCIE-16GB\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "wwN82ZV7ipNg",
    "colab_type": "text"
   },
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "RSnex0bmipNh",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "DATASET_ROOT = 'cifar-100-python'\n",
    "CODE_ROOT = 'libs'\n",
    "import os\n",
    "if not os.path.isdir(DATASET_ROOT):\n",
    "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
    "    !tar -xf 'cifar-100-python.tar.gz'  \n",
    "    !rm -rf 'cifar-100-python.tar.gz'\n",
    "\n",
    "if not os.path.isdir(CODE_ROOT):\n",
    "  !git clone https://lore-lml:29f601e814e0446c5b17a9f6c3684d1cbd316bcf@github.com/lore-lml/machine-learning2020-incremental_learning.git\n",
    "  !mv 'machine-learning2020-incremental_learning/libs' '.'\n",
    "  !rm -rf 'machine-learning2020-incremental_learning'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from torch.backends import cudnn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import libs.utils as utils\n",
    "from libs.utils import get_one_hot\n",
    "\n",
    "%matplotlib inline"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "7W9y67yoipNk",
    "colab_type": "text"
   },
   "source": [
    "**SET ARGUMENTS**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "r0hjWAP3ipNk",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "\n",
    "arguments = utils.get_arguments()\n",
    "\n",
    "DEVICE = arguments['DEVICE']\n",
    "NUM_CLASSES = arguments[\"NUM_CLASSES\"] \n",
    "\n",
    "BATCH_SIZE = arguments[\"BATCH_SIZE\"]        # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
    "                                            # the batch size, learning rate should change by the same factor to have comparable results\n",
    "\n",
    "LR = arguments[\"LR\"]                        # The initial Learning Rate\n",
    "MOMENTUM = arguments[\"MOMENTUM\"]            # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
    "WEIGHT_DECAY = arguments[\"WEIGHT_DECAY\"]    # Regularization, you can keep this at the default\n",
    "\n",
    "NUM_EPOCHS = arguments[\"NUM_EPOCHS\"]        # Total number of training epochs (iterations over dataset)\n",
    "GAMMA = arguments[\"GAMMA\"]                  # Multiplicative factor for learning rate step-down\n",
    "\n",
    "LOG_FREQUENCY = arguments[\"LOG_FREQUENCY\"]\n",
    "MILESTONES = arguments[\"MILESTONES\"]\n",
    "SEED = arguments[\"SEED\"]\n",
    "\n",
    "LOSS_TYPE = 'bce'\n",
    "\n",
    "TRAINING_TYPE = 'FT'\n",
    "#TRAINING_TYPE = 'JT'\n",
    "OUTPUT_PATH = f\"RUN1_{TRAINING_TYPE}\""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "SaT8eFDNipNm",
    "colab_type": "text"
   },
   "source": [
    "**Define Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "m-ydAGw4ipNm",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_transforms, eval_transforms = utils.get_train_eval_transforms()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "X7Naz_DdipNp",
    "colab_type": "text"
   },
   "source": [
    "**Prepare Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "G-Xct5sNipNp",
    "colab_type": "code",
    "outputId": "8b77b698-cc4e-4217-e814-7538f2c0c1e3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    }
   },
   "source": [
    "train_val_dataset = utils.get_cifar_with_seed(DATASET_ROOT, train_transforms, src='train', seed=SEED)\n",
    "test_dataset = utils.get_cifar_with_seed(DATASET_ROOT, eval_transforms, src='test', seed=SEED)\n",
    "\n",
    "print(f\"Size Training Set: {len(train_val_dataset)}\")\n",
    "print(f\"Size Test Set: {len(test_dataset)}\")"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Size Training Set: 50000\n",
      "Size Test Set: 10000\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "xZDP5yXBipNt",
    "colab_type": "text"
   },
   "source": [
    "**Train, Test, Validation functions**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "secPALBtipNt",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def train_batch(net, train_loader, criterion, optimizer, current_step, device=DEVICE):\n",
    "    net.train()\n",
    "    cumulative_loss =.0\n",
    "    running_corrects = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        if LOSS_TYPE == 'bce':\n",
    "            labels_enc = get_one_hot(labels, NUM_CLASSES, DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
    "        \n",
    "        loss = criterion(outputs, labels_enc) if LOSS_TYPE == 'bce'\\\n",
    "                                              else criterion(outputs, labels)\n",
    "        cumulative_loss += loss.item()\n",
    "        \n",
    "        if current_step != 0 and current_step % LOG_FREQUENCY == 0:\n",
    "                print('\\t\\tTrain step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        current_step += 1\n",
    "\n",
    "    return cumulative_loss / len(train_loader), running_corrects, current_step\n",
    "\n",
    "def validate(net, val_loader, criterion, optimizer, device=DEVICE):\n",
    "    net.eval()\n",
    "    cumulative_loss =.0\n",
    "    running_corrects = 0\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        if LOSS_TYPE == 'bce':\n",
    "            labels_enc = get_one_hot(labels, NUM_CLASSES, DEVICE)\n",
    "        \n",
    "\n",
    "        outputs = net(images)\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
    "        \n",
    "        loss = criterion(outputs, labels_enc) if LOSS_TYPE == 'bce'\\\n",
    "                                              else criterion(outputs, labels)\n",
    "        cumulative_loss += loss.item()\n",
    "\n",
    "\n",
    "    return cumulative_loss / len(val_loader), running_corrects\n",
    "\n",
    "def test(net, test_loader, device=DEVICE):\n",
    "    \n",
    "    # confusion matrix\n",
    "    y_true = []\n",
    "    y_preds = []\n",
    "\n",
    "    running_corrects = 0\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        net.eval()\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
    "\n",
    "        # confusion matrix\n",
    "        y_true.extend(labels.data.tolist())\n",
    "        y_preds.extend(preds.tolist())\n",
    "\n",
    "   \n",
    "    return running_corrects, y_true, y_preds\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "s5SroLpaipNw",
    "colab_type": "text"
   },
   "source": [
    "**FINE TUNING FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "clnGi_eLipNw",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def fine_tuning(train_val_dataset, test_dataset, max_epoch=NUM_EPOCHS, file_path=OUTPUT_PATH, device=DEVICE):\n",
    "    import math, time\n",
    "    incremental_test = []\n",
    "    train_mean_stage_accuracies = []\n",
    "    val_mean_stage_accuracies = []\n",
    "    test_stage_accuracies = []\n",
    "    cudnn.benchmark\n",
    "    net = utils.get_resnet(32).to(device)\n",
    "    criterion = utils.get_criterion(LOSS_TYPE)\n",
    "    start_time = time.time()\n",
    "    for stage in range(10):\n",
    "        optimizer, scheduler = utils.get_otpmizer_scheduler(net.parameters(), LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA)\n",
    "        print(f\"STARTING FINE TUNING STAGE {stage+1}...\")\n",
    "        # Get indices\n",
    "        # 4000 training, 1000 validation\n",
    "        train_idx, val_idx, test_idx = utils.get_kth_batch(train_val_dataset, test_dataset, stage,\n",
    "                                                                 seed=SEED, train_size=.9, get='indices')\n",
    "        \n",
    "        # Make test set incremental\n",
    "        incremental_test.extend(test_idx)\n",
    "        train_set, val_set, test_set = Subset(train_val_dataset, train_idx),\\\n",
    "                                       Subset(train_val_dataset, val_idx),\\\n",
    "                                       Subset(test_dataset, incremental_test)\n",
    "\n",
    "        # Build data loaders\n",
    "        curr_train_loader = utils.get_train_loader(train_set,batch_size=BATCH_SIZE)\n",
    "        curr_val_loader = utils.get_eval_loader(val_set, batch_size=BATCH_SIZE)\n",
    "        curr_test_loader = utils.get_eval_loader(test_set, batch_size=BATCH_SIZE)\n",
    "\n",
    "        # Init results\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        min_val_loss = -1\n",
    "        current_step = 0\n",
    "        tolerance = 10\n",
    "        for epoch in range(max_epoch):\n",
    "            print(f\"\\tSTARTING EPOCH {epoch+1} - LR={scheduler.get_last_lr()}...\")\n",
    "            curr_result = train_batch(net, curr_train_loader, criterion, optimizer, current_step, device)\n",
    "            curr_train_loss = curr_result[0]\n",
    "            curr_train_accuracy = curr_result[1] / float(BATCH_SIZE * len(curr_train_loader))\n",
    "            current_step = curr_result[2]\n",
    "            \n",
    "            train_losses.append(curr_train_loss)\n",
    "            train_accuracies.append(curr_train_accuracy)\n",
    "            scheduler.step()\n",
    "            \n",
    "            curr_val_loss, val_corrects = validate(net, curr_val_loader, criterion, optimizer, device)\n",
    "            val_losses.append(curr_val_loss)\n",
    "            curr_val_accuracy = val_corrects / float(len(val_set))\n",
    "            val_accuracies.append(curr_val_accuracy)\n",
    "            \n",
    "            print(f\"\\t\\tRESULT EPOCH {epoch+1}:\")\n",
    "            print(f\"\\t\\t\\tTrain Loss: {curr_train_loss} - Train Accuracy: {curr_train_accuracy}\")\n",
    "            print(f\"\\t\\t\\tVal Loss: {curr_val_loss} - Val Accuracy: {curr_val_accuracy}\\n\")\n",
    "            \n",
    "            if math.isnan(curr_val_loss):\n",
    "                tolerance -= 1\n",
    "            else:\n",
    "                tolerance = 10\n",
    "            \n",
    "            if tolerance == 0:\n",
    "                print(f\"STAGE {stage+1} -> EARLY STOPPING\\n\")\n",
    "                break\n",
    "            \n",
    "            if min_val_loss == -1 or min_val_loss > curr_val_loss:\n",
    "                min_val_loss = curr_val_loss\n",
    "                torch.save(net, f\"{file_path}_best_model_finetuning.pth\")\n",
    "        \n",
    "        net = torch.load(f\"{file_path}_best_model_finetuning.pth\").to(device)\n",
    "        corrects, y_true, y_preds = test(net, curr_test_loader, device)\n",
    "        epoch_test_accuracy = corrects / float(len(test_set))\n",
    "        test_stage_accuracies.append(epoch_test_accuracy)\n",
    "        train_mean_stage_accuracies.append(np.mean(train_accuracies))\n",
    "        val_mean_stage_accuracies.append(np.mean(val_accuracies))\n",
    "        \n",
    "        print(f\"\\n\\tResults STAGE {stage+1}:\")\n",
    "        print(f\"\\t\\tTrain Mean Accuracy: {train_mean_stage_accuracies[stage]}\")\n",
    "        print(f\"\\t\\tVal Mean Accuracy: {val_mean_stage_accuracies[stage]}\")\n",
    "        print(f\"\\t\\tTest Accuracy: {test_stage_accuracies[stage]}\\n\")\n",
    "\n",
    "\n",
    "    total_time = int(time.time() - start_time)\n",
    "    min = int(total_time / 60)\n",
    "    sec = total_time % 60\n",
    "    print(f\"\\nTotal time: {min} min {sec} sec\\n\")\n",
    "        \n",
    "    return train_mean_stage_accuracies,\\\n",
    "           val_mean_stage_accuracies,\\\n",
    "           test_stage_accuracies,\\\n",
    "           y_true, y_preds"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sLnI2Dqx6I-",
    "colab_type": "text"
   },
   "source": [
    "**JOINT TRAINING FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "44iaChR_yM34",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def joint_training(train_val_dataset, test_dataset, max_epoch=NUM_EPOCHS, file_path=OUTPUT_PATH, device=DEVICE):\n",
    "    import math, time\n",
    "    incremental_train = []\n",
    "    incremental_val = []\n",
    "    incremental_test = []\n",
    "    train_mean_stage_accuracies = []\n",
    "    val_mean_stage_accuracies = []\n",
    "    test_stage_accuracies = []\n",
    "    cudnn.benchmark\n",
    "    net = utils.get_resnet(32).to(device)\n",
    "    criterion = utils.get_criterion(LOSS_TYPE)\n",
    "    start_time = time.time()\n",
    "    for stage in range(10):\n",
    "        optimizer, scheduler = utils.get_otpmizer_scheduler(net.parameters(), LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA)\n",
    "        print(f\"STARTING JOINT TRAINING STAGE {stage+1}...\")\n",
    "        # Get indices\n",
    "        # 4000 training, 1000 validation\n",
    "        train_idx, val_idx, test_idx = utils.get_kth_batch(train_val_dataset, test_dataset, stage,\n",
    "                                                                 seed=SEED, train_size=.9, get='indices')\n",
    "        \n",
    "        # Make test set incremental\n",
    "        incremental_train.extend(train_idx)\n",
    "        incremental_val.extend(val_idx)\n",
    "        incremental_test.extend(test_idx)\n",
    "        train_set, val_set, test_set = Subset(train_val_dataset, incremental_train),\\\n",
    "                                       Subset(train_val_dataset, incremental_val),\\\n",
    "                                       Subset(test_dataset, incremental_test)\n",
    "\n",
    "\n",
    "        # Build data loaders\n",
    "        curr_train_loader = utils.get_train_loader(train_set,batch_size=BATCH_SIZE)\n",
    "        curr_val_loader = utils.get_eval_loader(val_set, batch_size=BATCH_SIZE)\n",
    "        curr_test_loader = utils.get_eval_loader(test_set, batch_size=BATCH_SIZE)\n",
    "\n",
    "        # Init results\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        min_val_loss = -1\n",
    "        current_step = 0\n",
    "        tolerance = 10\n",
    "        for epoch in range(max_epoch):\n",
    "            print(f\"\\tSTARTING EPOCH {epoch+1} - LR={scheduler.get_last_lr()}...\")\n",
    "            curr_result = train_batch(net, curr_train_loader, criterion, optimizer, current_step, device)\n",
    "            curr_train_loss = curr_result[0]\n",
    "            curr_train_accuracy = curr_result[1] / float(BATCH_SIZE * len(curr_train_loader))\n",
    "            current_step = curr_result[2]\n",
    "            \n",
    "            train_losses.append(curr_train_loss)\n",
    "            train_accuracies.append(curr_train_accuracy)\n",
    "            scheduler.step()\n",
    "            \n",
    "            curr_val_loss, val_corrects = validate(net, curr_val_loader, criterion, optimizer, device)\n",
    "            val_losses.append(curr_val_loss)\n",
    "            curr_val_accuracy = val_corrects / float(len(val_set))\n",
    "            val_accuracies.append(curr_val_accuracy)\n",
    "            \n",
    "            print(f\"\\t\\tRESULT EPOCH {epoch+1}:\")\n",
    "            print(f\"\\t\\t\\tTrain Loss: {curr_train_loss} - Train Accuracy: {curr_train_accuracy}\")\n",
    "            print(f\"\\t\\t\\tVal Loss: {curr_val_loss} - Val Accuracy: {curr_val_accuracy}\\n\")\n",
    "            \n",
    "            if math.isnan(curr_val_loss):\n",
    "                tolerance -= 1\n",
    "            else:\n",
    "                tolerance = 10\n",
    "            \n",
    "            if tolerance == 0:\n",
    "                print(f\"STAGE {stage+1} -> EARLY STOPPING\\n\")\n",
    "                break\n",
    "            \n",
    "            if min_val_loss == -1 or min_val_loss > curr_val_loss:\n",
    "                min_val_loss = curr_val_loss\n",
    "                torch.save(net, f\"{file_path}_best_model_finetuning.pth\")\n",
    "        \n",
    "        net = torch.load(f\"{file_path}_best_model_finetuning.pth\").to(device)\n",
    "        corrects, y_true, y_preds = test(net, curr_test_loader, device)\n",
    "        epoch_test_accuracy = corrects / float(len(test_set))\n",
    "        test_stage_accuracies.append(epoch_test_accuracy)\n",
    "        train_mean_stage_accuracies.append(np.mean(train_accuracies))\n",
    "        val_mean_stage_accuracies.append(np.mean(val_accuracies))\n",
    "        \n",
    "        print(f\"\\n\\tResults STAGE {stage+1}:\")\n",
    "        print(f\"\\t\\tTrain Mean Accuracy: {train_mean_stage_accuracies[stage]}\")\n",
    "        print(f\"\\t\\tVal Mean Accuracy: {val_mean_stage_accuracies[stage]}\")\n",
    "        print(f\"\\t\\tTest Accuracy: {test_stage_accuracies[stage]}\\n\")\n",
    "\n",
    "\n",
    "    total_time = int(time.time() - start_time)\n",
    "    min = int(total_time / 60)\n",
    "    sec = total_time % 60\n",
    "    print(f\"\\nJOINT TRAININGTotal time: {min} min {sec} sec\\n\")\n",
    "        \n",
    "    return train_mean_stage_accuracies,\\\n",
    "           val_mean_stage_accuracies,\\\n",
    "           test_stage_accuracies,\\\n",
    "           y_true, y_preds"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "bvaYg8SiipNy",
    "colab_type": "text"
   },
   "source": [
    "**FINE TUNING / JOINT TRAINING START**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "i_ejvvl4ipNy",
    "colab_type": "code",
    "outputId": "091cab80-0573-44dc-8bb7-eff16f761328",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "train_accuracies,\\\n",
    "val_accuracies,\\\n",
    "test_accuracies,\\\n",
    "y_true, y_preds = fine_tuning(train_val_dataset, test_dataset, NUM_EPOCHS) if TRAINING_TYPE == 'FT' else joint_training(train_val_dataset, test_dataset, NUM_EPOCHS)"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "STARTING FINE TUNING STAGE 1...\n",
      "\tSTARTING EPOCH 1 - LR=[2]...\n",
      "\t\tTrain step - Step 30, Loss 0.030451931059360504\n",
      "\t\tRESULT EPOCH 1:\n",
      "\t\t\tTrain Loss: 0.06618214478450161 - Train Accuracy: 0.16205357142857144\n",
      "\t\t\tVal Loss: 0.029952332843095064 - Val Accuracy: 0.256\n",
      "\n",
      "\tSTARTING EPOCH 2 - LR=[2]...\n",
      "\t\tTrain step - Step 60, Loss 0.024708060547709465\n",
      "\t\tRESULT EPOCH 2:\n",
      "\t\t\tTrain Loss: 0.026528981806976454 - Train Accuracy: 0.37008928571428573\n",
      "\t\t\tVal Loss: 0.026106462348252535 - Val Accuracy: 0.4\n",
      "\n",
      "\tSTARTING EPOCH 3 - LR=[2]...\n",
      "\t\tTrain step - Step 90, Loss 0.024521300569176674\n",
      "\t\tRESULT EPOCH 3:\n",
      "\t\t\tTrain Loss: 0.02417141044778483 - Train Accuracy: 0.434375\n",
      "\t\t\tVal Loss: 0.0261314962990582 - Val Accuracy: 0.404\n",
      "\n",
      "\tSTARTING EPOCH 4 - LR=[2]...\n",
      "\t\tTrain step - Step 120, Loss 0.023590432479977608\n",
      "\t\tRESULT EPOCH 4:\n",
      "\t\t\tTrain Loss: 0.022576336349759783 - Train Accuracy: 0.47611607142857143\n",
      "\t\t\tVal Loss: 0.023719959892332554 - Val Accuracy: 0.462\n",
      "\n",
      "\tSTARTING EPOCH 5 - LR=[2]...\n",
      "\t\tTrain step - Step 150, Loss 0.018895534798502922\n",
      "\t\tRESULT EPOCH 5:\n",
      "\t\t\tTrain Loss: 0.02116776066167014 - Train Accuracy: 0.5160714285714286\n",
      "\t\t\tVal Loss: 0.02178945764899254 - Val Accuracy: 0.524\n",
      "\n",
      "\tSTARTING EPOCH 6 - LR=[2]...\n",
      "\t\tTrain step - Step 180, Loss 0.02009119652211666\n",
      "\t\tRESULT EPOCH 6:\n",
      "\t\t\tTrain Loss: 0.02015806899539062 - Train Accuracy: 0.5428571428571428\n",
      "\t\t\tVal Loss: 0.021954796742647886 - Val Accuracy: 0.484\n",
      "\n",
      "\tSTARTING EPOCH 7 - LR=[2]...\n",
      "\t\tTrain step - Step 210, Loss 0.017695855349302292\n",
      "\t\tTrain step - Step 240, Loss 0.01812528260052204\n",
      "\t\tRESULT EPOCH 7:\n",
      "\t\t\tTrain Loss: 0.018969900320683207 - Train Accuracy: 0.5792410714285714\n",
      "\t\t\tVal Loss: 0.02332538040354848 - Val Accuracy: 0.516\n",
      "\n",
      "\tSTARTING EPOCH 8 - LR=[2]...\n",
      "\t\tTrain step - Step 270, Loss 0.020100584253668785\n",
      "\t\tRESULT EPOCH 8:\n",
      "\t\t\tTrain Loss: 0.017814375247274125 - Train Accuracy: 0.6080357142857142\n",
      "\t\t\tVal Loss: 0.01827117009088397 - Val Accuracy: 0.61\n",
      "\n",
      "\tSTARTING EPOCH 9 - LR=[2]...\n",
      "\t\tTrain step - Step 300, Loss 0.01523087453097105\n",
      "\t\tRESULT EPOCH 9:\n",
      "\t\t\tTrain Loss: 0.01695569436997175 - Train Accuracy: 0.6377232142857143\n",
      "\t\t\tVal Loss: 0.01799879618920386 - Val Accuracy: 0.602\n",
      "\n",
      "\tSTARTING EPOCH 10 - LR=[2]...\n",
      "\t\tTrain step - Step 330, Loss 0.018589938059449196\n",
      "\t\tRESULT EPOCH 10:\n",
      "\t\t\tTrain Loss: 0.016208855674735137 - Train Accuracy: 0.6618303571428571\n",
      "\t\t\tVal Loss: 0.018596110632643104 - Val Accuracy: 0.63\n",
      "\n",
      "\tSTARTING EPOCH 11 - LR=[2]...\n",
      "\t\tTrain step - Step 360, Loss 0.01460285671055317\n",
      "\t\tRESULT EPOCH 11:\n",
      "\t\t\tTrain Loss: 0.015199777031583445 - Train Accuracy: 0.6832589285714286\n",
      "\t\t\tVal Loss: 0.017366274958476424 - Val Accuracy: 0.642\n",
      "\n",
      "\tSTARTING EPOCH 12 - LR=[2]...\n",
      "\t\tTrain step - Step 390, Loss 0.015634674578905106\n",
      "\t\tRESULT EPOCH 12:\n",
      "\t\t\tTrain Loss: 0.014658622284020697 - Train Accuracy: 0.6964285714285714\n",
      "\t\t\tVal Loss: 0.01716859918087721 - Val Accuracy: 0.62\n",
      "\n",
      "\tSTARTING EPOCH 13 - LR=[2]...\n",
      "\t\tTrain step - Step 420, Loss 0.012257605791091919\n",
      "\t\tTrain step - Step 450, Loss 0.013153311796486378\n",
      "\t\tRESULT EPOCH 13:\n",
      "\t\t\tTrain Loss: 0.013445136642881802 - Train Accuracy: 0.7247767857142857\n",
      "\t\t\tVal Loss: 0.017394511960446835 - Val Accuracy: 0.622\n",
      "\n",
      "\tSTARTING EPOCH 14 - LR=[2]...\n",
      "\t\tTrain step - Step 480, Loss 0.011378838680684566\n",
      "\t\tRESULT EPOCH 14:\n",
      "\t\t\tTrain Loss: 0.012696109898388385 - Train Accuracy: 0.7446428571428572\n",
      "\t\t\tVal Loss: 0.016481714555993676 - Val Accuracy: 0.67\n",
      "\n",
      "\tSTARTING EPOCH 15 - LR=[2]...\n",
      "\t\tTrain step - Step 510, Loss 0.011062593199312687\n",
      "\t\tRESULT EPOCH 15:\n",
      "\t\t\tTrain Loss: 0.01228531255785908 - Train Accuracy: 0.7540178571428572\n",
      "\t\t\tVal Loss: 0.016187070170417428 - Val Accuracy: 0.668\n",
      "\n",
      "\tSTARTING EPOCH 16 - LR=[2]...\n",
      "\t\tTrain step - Step 540, Loss 0.012133008800446987\n",
      "\t\tRESULT EPOCH 16:\n",
      "\t\t\tTrain Loss: 0.011778504853802068 - Train Accuracy: 0.7642857142857142\n",
      "\t\t\tVal Loss: 0.019661368569359183 - Val Accuracy: 0.634\n",
      "\n",
      "\tSTARTING EPOCH 17 - LR=[2]...\n",
      "\t\tTrain step - Step 570, Loss 0.012812219560146332\n",
      "\t\tRESULT EPOCH 17:\n",
      "\t\t\tTrain Loss: 0.011432849136846406 - Train Accuracy: 0.7703125\n",
      "\t\t\tVal Loss: 0.014990004943683743 - Val Accuracy: 0.666\n",
      "\n",
      "\tSTARTING EPOCH 18 - LR=[2]...\n",
      "\t\tTrain step - Step 600, Loss 0.012914387509226799\n",
      "\t\tRESULT EPOCH 18:\n",
      "\t\t\tTrain Loss: 0.011034684894340379 - Train Accuracy: 0.7763392857142857\n",
      "\t\t\tVal Loss: 0.0172991412691772 - Val Accuracy: 0.662\n",
      "\n",
      "\tSTARTING EPOCH 19 - LR=[2]...\n",
      "\t\tTrain step - Step 630, Loss 0.009855976328253746\n",
      "\t\tTrain step - Step 660, Loss 0.008845794014632702\n",
      "\t\tRESULT EPOCH 19:\n",
      "\t\t\tTrain Loss: 0.010560766634132182 - Train Accuracy: 0.7886160714285714\n",
      "\t\t\tVal Loss: 0.0151289370842278 - Val Accuracy: 0.688\n",
      "\n",
      "\tSTARTING EPOCH 20 - LR=[2]...\n",
      "\t\tTrain step - Step 690, Loss 0.012758689932525158\n",
      "\t\tRESULT EPOCH 20:\n",
      "\t\t\tTrain Loss: 0.010267177876085044 - Train Accuracy: 0.7926339285714286\n",
      "\t\t\tVal Loss: 0.015051647322252393 - Val Accuracy: 0.69\n",
      "\n",
      "\tSTARTING EPOCH 21 - LR=[2]...\n",
      "\t\tTrain step - Step 720, Loss 0.008875647559762001\n",
      "\t\tRESULT EPOCH 21:\n",
      "\t\t\tTrain Loss: 0.009819433359163148 - Train Accuracy: 0.8046875\n",
      "\t\t\tVal Loss: 0.015623959945514798 - Val Accuracy: 0.676\n",
      "\n",
      "\tSTARTING EPOCH 22 - LR=[2]...\n",
      "\t\tTrain step - Step 750, Loss 0.01005568914115429\n",
      "\t\tRESULT EPOCH 22:\n",
      "\t\t\tTrain Loss: 0.009403795083718641 - Train Accuracy: 0.8167410714285714\n",
      "\t\t\tVal Loss: 0.01488583954051137 - Val Accuracy: 0.714\n",
      "\n",
      "\tSTARTING EPOCH 23 - LR=[2]...\n",
      "\t\tTrain step - Step 780, Loss 0.007478054612874985\n",
      "\t\tRESULT EPOCH 23:\n",
      "\t\t\tTrain Loss: 0.008897917039160217 - Train Accuracy: 0.8261160714285715\n",
      "\t\t\tVal Loss: 0.015035913325846195 - Val Accuracy: 0.706\n",
      "\n",
      "\tSTARTING EPOCH 24 - LR=[2]...\n",
      "\t\tTrain step - Step 810, Loss 0.006415386218577623\n",
      "\t\tRESULT EPOCH 24:\n",
      "\t\t\tTrain Loss: 0.008813677355647087 - Train Accuracy: 0.8274553571428571\n",
      "\t\t\tVal Loss: 0.015672764740884304 - Val Accuracy: 0.694\n",
      "\n",
      "\tSTARTING EPOCH 25 - LR=[2]...\n",
      "\t\tTrain step - Step 840, Loss 0.005332836415618658\n",
      "\t\tTrain step - Step 870, Loss 0.01030852273106575\n",
      "\t\tRESULT EPOCH 25:\n",
      "\t\t\tTrain Loss: 0.008576790576002427 - Train Accuracy: 0.8303571428571429\n",
      "\t\t\tVal Loss: 0.013397397240623832 - Val Accuracy: 0.728\n",
      "\n",
      "\tSTARTING EPOCH 26 - LR=[2]...\n",
      "\t\tTrain step - Step 900, Loss 0.0065254634246230125\n",
      "\t\tRESULT EPOCH 26:\n",
      "\t\t\tTrain Loss: 0.008188821042754821 - Train Accuracy: 0.8412946428571428\n",
      "\t\t\tVal Loss: 0.013900776160880923 - Val Accuracy: 0.724\n",
      "\n",
      "\tSTARTING EPOCH 27 - LR=[2]...\n",
      "\t\tTrain step - Step 930, Loss 0.005301938392221928\n",
      "\t\tRESULT EPOCH 27:\n",
      "\t\t\tTrain Loss: 0.00793011992105416 - Train Accuracy: 0.8417410714285715\n",
      "\t\t\tVal Loss: 0.016256781993433833 - Val Accuracy: 0.7\n",
      "\n",
      "\tSTARTING EPOCH 28 - LR=[2]...\n",
      "\t\tTrain step - Step 960, Loss 0.009395827539265156\n",
      "\t\tRESULT EPOCH 28:\n",
      "\t\t\tTrain Loss: 0.007954362207757575 - Train Accuracy: 0.8421875\n",
      "\t\t\tVal Loss: 0.01881006476469338 - Val Accuracy: 0.694\n",
      "\n",
      "\tSTARTING EPOCH 29 - LR=[2]...\n",
      "\t\tTrain step - Step 990, Loss 0.006487741135060787\n",
      "\t\tRESULT EPOCH 29:\n",
      "\t\t\tTrain Loss: 0.007560631752546345 - Train Accuracy: 0.8529017857142858\n",
      "\t\t\tVal Loss: 0.012570863589644432 - Val Accuracy: 0.774\n",
      "\n",
      "\tSTARTING EPOCH 30 - LR=[2]...\n",
      "\t\tTrain step - Step 1020, Loss 0.008270442485809326\n",
      "\t\tRESULT EPOCH 30:\n",
      "\t\t\tTrain Loss: 0.007367463369986841 - Train Accuracy: 0.8549107142857143\n",
      "\t\t\tVal Loss: 0.015275014331564307 - Val Accuracy: 0.72\n",
      "\n",
      "\tSTARTING EPOCH 31 - LR=[2]...\n",
      "\t\tTrain step - Step 1050, Loss 0.00793436262756586\n",
      "\t\tTrain step - Step 1080, Loss 0.007040484342724085\n",
      "\t\tRESULT EPOCH 31:\n",
      "\t\t\tTrain Loss: 0.006781743134238891 - Train Accuracy: 0.8720982142857143\n",
      "\t\t\tVal Loss: 0.012350776931270957 - Val Accuracy: 0.778\n",
      "\n",
      "\tSTARTING EPOCH 32 - LR=[2]...\n",
      "\t\tTrain step - Step 1110, Loss 0.005351904314011335\n",
      "\t\tRESULT EPOCH 32:\n",
      "\t\t\tTrain Loss: 0.006688239824559007 - Train Accuracy: 0.8790178571428572\n",
      "\t\t\tVal Loss: 0.013532247394323349 - Val Accuracy: 0.76\n",
      "\n",
      "\tSTARTING EPOCH 33 - LR=[2]...\n",
      "\t\tTrain step - Step 1140, Loss 0.006622812710702419\n",
      "\t\tRESULT EPOCH 33:\n",
      "\t\t\tTrain Loss: 0.0066361244767904285 - Train Accuracy: 0.8714285714285714\n",
      "\t\t\tVal Loss: 0.012725664069876075 - Val Accuracy: 0.758\n",
      "\n",
      "\tSTARTING EPOCH 34 - LR=[2]...\n",
      "\t\tTrain step - Step 1170, Loss 0.0066862935200333595\n",
      "\t\tRESULT EPOCH 34:\n",
      "\t\t\tTrain Loss: 0.006360771227627992 - Train Accuracy: 0.8861607142857143\n",
      "\t\t\tVal Loss: 0.01198456366546452 - Val Accuracy: 0.776\n",
      "\n",
      "\tSTARTING EPOCH 35 - LR=[2]...\n",
      "\t\tTrain step - Step 1200, Loss 0.006046044174581766\n",
      "\t\tRESULT EPOCH 35:\n",
      "\t\t\tTrain Loss: 0.005883817926847509 - Train Accuracy: 0.8897321428571429\n",
      "\t\t\tVal Loss: 0.012156722601503134 - Val Accuracy: 0.744\n",
      "\n",
      "\tSTARTING EPOCH 36 - LR=[2]...\n",
      "\t\tTrain step - Step 1230, Loss 0.007209612987935543\n",
      "\t\tRESULT EPOCH 36:\n",
      "\t\t\tTrain Loss: 0.006030524748244456 - Train Accuracy: 0.8870535714285714\n",
      "\t\t\tVal Loss: 0.014174731215462089 - Val Accuracy: 0.74\n",
      "\n",
      "\tSTARTING EPOCH 37 - LR=[2]...\n",
      "\t\tTrain step - Step 1260, Loss 0.005131002981215715\n",
      "\t\tTrain step - Step 1290, Loss 0.007014294620603323\n",
      "\t\tRESULT EPOCH 37:\n",
      "\t\t\tTrain Loss: 0.006143478969378131 - Train Accuracy: 0.884375\n",
      "\t\t\tVal Loss: 0.013044719584286213 - Val Accuracy: 0.78\n",
      "\n",
      "\tSTARTING EPOCH 38 - LR=[2]...\n",
      "\t\tTrain step - Step 1320, Loss 0.005043587647378445\n",
      "\t\tRESULT EPOCH 38:\n",
      "\t\t\tTrain Loss: 0.005380178555580122 - Train Accuracy: 0.8970982142857142\n",
      "\t\t\tVal Loss: 0.011889793910086155 - Val Accuracy: 0.784\n",
      "\n",
      "\tSTARTING EPOCH 39 - LR=[2]...\n",
      "\t\tTrain step - Step 1350, Loss 0.004081489983946085\n",
      "\t\tRESULT EPOCH 39:\n",
      "\t\t\tTrain Loss: 0.004919941590300628 - Train Accuracy: 0.9100446428571428\n",
      "\t\t\tVal Loss: 0.012899782974272966 - Val Accuracy: 0.772\n",
      "\n",
      "\tSTARTING EPOCH 40 - LR=[2]...\n",
      "\t\tTrain step - Step 1380, Loss 0.007782571017742157\n",
      "\t\tRESULT EPOCH 40:\n",
      "\t\t\tTrain Loss: 0.0053017439054591315 - Train Accuracy: 0.896875\n",
      "\t\t\tVal Loss: 0.012724620988592505 - Val Accuracy: 0.764\n",
      "\n",
      "\tSTARTING EPOCH 41 - LR=[2]...\n",
      "\t\tTrain step - Step 1410, Loss 0.006505277473479509\n",
      "\t\tRESULT EPOCH 41:\n",
      "\t\t\tTrain Loss: 0.005436985893175006 - Train Accuracy: 0.8970982142857142\n",
      "\t\t\tVal Loss: 0.021595117636024952 - Val Accuracy: 0.716\n",
      "\n",
      "\tSTARTING EPOCH 42 - LR=[2]...\n",
      "\t\tTrain step - Step 1440, Loss 0.003507302375510335\n",
      "\t\tRESULT EPOCH 42:\n",
      "\t\t\tTrain Loss: 0.005251027064930115 - Train Accuracy: 0.8982142857142857\n",
      "\t\t\tVal Loss: 0.01526390085928142 - Val Accuracy: 0.728\n",
      "\n",
      "\tSTARTING EPOCH 43 - LR=[2]...\n",
      "\t\tTrain step - Step 1470, Loss 0.0051464722491800785\n",
      "\t\tTrain step - Step 1500, Loss 0.005812081042677164\n",
      "\t\tRESULT EPOCH 43:\n",
      "\t\t\tTrain Loss: 0.0051069919751690965 - Train Accuracy: 0.9051339285714286\n",
      "\t\t\tVal Loss: 0.012906193733215332 - Val Accuracy: 0.778\n",
      "\n",
      "\tSTARTING EPOCH 44 - LR=[2]...\n",
      "\t\tTrain step - Step 1530, Loss 0.004042787943035364\n",
      "\t\tRESULT EPOCH 44:\n",
      "\t\t\tTrain Loss: 0.004798840199198041 - Train Accuracy: 0.9125\n",
      "\t\t\tVal Loss: 0.013090027729049325 - Val Accuracy: 0.764\n",
      "\n",
      "\tSTARTING EPOCH 45 - LR=[2]...\n",
      "\t\tTrain step - Step 1560, Loss 0.004201153758913279\n",
      "\t\tRESULT EPOCH 45:\n",
      "\t\t\tTrain Loss: 0.004942513470138822 - Train Accuracy: 0.9087053571428572\n",
      "\t\t\tVal Loss: 0.01282924460247159 - Val Accuracy: 0.786\n",
      "\n",
      "\tSTARTING EPOCH 46 - LR=[2]...\n",
      "\t\tTrain step - Step 1590, Loss 0.005809237714856863\n",
      "\t\tRESULT EPOCH 46:\n",
      "\t\t\tTrain Loss: 0.0046616853081754275 - Train Accuracy: 0.9133928571428571\n",
      "\t\t\tVal Loss: 0.013107543112710118 - Val Accuracy: 0.776\n",
      "\n",
      "\tSTARTING EPOCH 47 - LR=[2]...\n",
      "\t\tTrain step - Step 1620, Loss 0.003692845581099391\n",
      "\t\tRESULT EPOCH 47:\n",
      "\t\t\tTrain Loss: 0.00471464594426964 - Train Accuracy: 0.9116071428571428\n",
      "\t\t\tVal Loss: 0.012953149620443583 - Val Accuracy: 0.758\n",
      "\n",
      "\tSTARTING EPOCH 48 - LR=[2]...\n",
      "\t\tTrain step - Step 1650, Loss 0.0033301946241408587\n",
      "\t\tRESULT EPOCH 48:\n",
      "\t\t\tTrain Loss: 0.004782583903787391 - Train Accuracy: 0.9102678571428572\n",
      "\t\t\tVal Loss: 0.01715388661250472 - Val Accuracy: 0.722\n",
      "\n",
      "\tSTARTING EPOCH 49 - LR=[2]...\n",
      "\t\tTrain step - Step 1680, Loss 0.0030900011770427227\n",
      "\t\tTrain step - Step 1710, Loss 0.0066612171940505505\n",
      "\t\tRESULT EPOCH 49:\n",
      "\t\t\tTrain Loss: 0.004194831582052367 - Train Accuracy: 0.9227678571428571\n",
      "\t\t\tVal Loss: 0.012699567014351487 - Val Accuracy: 0.796\n",
      "\n",
      "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1740, Loss 0.0024751981254667044\n",
      "\t\tRESULT EPOCH 50:\n",
      "\t\t\tTrain Loss: 0.002942809751922531 - Train Accuracy: 0.9515625\n",
      "\t\t\tVal Loss: 0.009115579072386026 - Val Accuracy: 0.832\n",
      "\n",
      "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1770, Loss 0.0013714296510443091\n",
      "\t\tRESULT EPOCH 51:\n",
      "\t\t\tTrain Loss: 0.002225382938714964 - Train Accuracy: 0.9660714285714286\n",
      "\t\t\tVal Loss: 0.00858713046181947 - Val Accuracy: 0.85\n",
      "\n",
      "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1800, Loss 0.0012687083799391985\n",
      "\t\tRESULT EPOCH 52:\n",
      "\t\t\tTrain Loss: 0.001961839826045824 - Train Accuracy: 0.971875\n",
      "\t\t\tVal Loss: 0.008684106753207743 - Val Accuracy: 0.842\n",
      "\n",
      "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1830, Loss 0.0023820935748517513\n",
      "\t\tRESULT EPOCH 53:\n",
      "\t\t\tTrain Loss: 0.0018164722265542619 - Train Accuracy: 0.9745535714285715\n",
      "\t\t\tVal Loss: 0.008542879018932581 - Val Accuracy: 0.85\n",
      "\n",
      "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1860, Loss 0.0012572711566463113\n",
      "\t\tRESULT EPOCH 54:\n",
      "\t\t\tTrain Loss: 0.0016259247536904045 - Train Accuracy: 0.9787946428571429\n",
      "\t\t\tVal Loss: 0.008783504250459373 - Val Accuracy: 0.852\n",
      "\n",
      "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1890, Loss 0.001043004565872252\n",
      "\t\tTrain step - Step 1920, Loss 0.002445997903123498\n",
      "\t\tRESULT EPOCH 55:\n",
      "\t\t\tTrain Loss: 0.0015312576350489898 - Train Accuracy: 0.9799107142857143\n",
      "\t\t\tVal Loss: 0.008916314225643873 - Val Accuracy: 0.848\n",
      "\n",
      "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1950, Loss 0.00212916755117476\n",
      "\t\tRESULT EPOCH 56:\n",
      "\t\t\tTrain Loss: 0.0014872194866516761 - Train Accuracy: 0.9796875\n",
      "\t\t\tVal Loss: 0.009899426018819213 - Val Accuracy: 0.836\n",
      "\n",
      "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1980, Loss 0.0013240787666290998\n",
      "\t\tRESULT EPOCH 57:\n",
      "\t\t\tTrain Loss: 0.0015372040082833596 - Train Accuracy: 0.9794642857142857\n",
      "\t\t\tVal Loss: 0.010171781992539763 - Val Accuracy: 0.846\n",
      "\n",
      "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2010, Loss 0.0005789610440842807\n",
      "\t\tRESULT EPOCH 58:\n",
      "\t\t\tTrain Loss: 0.0014584213162639312 - Train Accuracy: 0.9808035714285714\n",
      "\t\t\tVal Loss: 0.009687757468782365 - Val Accuracy: 0.83\n",
      "\n",
      "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2040, Loss 0.0009019838180392981\n",
      "\t\tRESULT EPOCH 59:\n",
      "\t\t\tTrain Loss: 0.0013473780742580337 - Train Accuracy: 0.9837053571428571\n",
      "\t\t\tVal Loss: 0.009710296988487244 - Val Accuracy: 0.84\n",
      "\n",
      "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2070, Loss 0.0015295440098270774\n",
      "\t\tRESULT EPOCH 60:\n",
      "\t\t\tTrain Loss: 0.001267483174368473 - Train Accuracy: 0.9866071428571429\n",
      "\t\t\tVal Loss: 0.009589700028300285 - Val Accuracy: 0.842\n",
      "\n",
      "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2100, Loss 0.0015370991313830018\n",
      "\t\tTrain step - Step 2130, Loss 0.0007575209019705653\n",
      "\t\tRESULT EPOCH 61:\n",
      "\t\t\tTrain Loss: 0.0012837870395742356 - Train Accuracy: 0.9839285714285714\n",
      "\t\t\tVal Loss: 0.010066366055980325 - Val Accuracy: 0.836\n",
      "\n",
      "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2160, Loss 0.0006197277107276022\n",
      "\t\tRESULT EPOCH 62:\n",
      "\t\t\tTrain Loss: 0.0011778974780879382 - Train Accuracy: 0.9850446428571429\n",
      "\t\t\tVal Loss: 0.009735168423503637 - Val Accuracy: 0.852\n",
      "\n",
      "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2190, Loss 0.001183074084110558\n",
      "\t\tRESULT EPOCH 63:\n",
      "\t\t\tTrain Loss: 0.0010710274002381733 - Train Accuracy: 0.9872767857142857\n",
      "\t\t\tVal Loss: 0.009412659797817469 - Val Accuracy: 0.85\n",
      "\n",
      "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2220, Loss 0.0007213028147816658\n",
      "\t\tRESULT EPOCH 64:\n",
      "\t\t\tTrain Loss: 0.0009949968088351722 - Train Accuracy: 0.9901785714285715\n",
      "\t\t\tVal Loss: 0.009847556706517935 - Val Accuracy: 0.844\n",
      "\n",
      "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2250, Loss 0.0019196937792003155\n",
      "\t\tRESULT EPOCH 65:\n",
      "\t\t\tTrain Loss: 0.0010637089019707804 - Train Accuracy: 0.9895089285714286\n",
      "\t\t\tVal Loss: 0.009136488777585328 - Val Accuracy: 0.836\n",
      "\n",
      "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2280, Loss 0.0007214245270006359\n",
      "\t\tRESULT EPOCH 66:\n",
      "\t\t\tTrain Loss: 0.0009664903536239373 - Train Accuracy: 0.9899553571428571\n",
      "\t\t\tVal Loss: 0.008634962840005755 - Val Accuracy: 0.866\n",
      "\n",
      "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2310, Loss 0.0010412790579721332\n",
      "\t\tTrain step - Step 2340, Loss 0.0008876893552951515\n",
      "\t\tRESULT EPOCH 67:\n",
      "\t\t\tTrain Loss: 0.0009678674462650504 - Train Accuracy: 0.9897321428571428\n",
      "\t\t\tVal Loss: 0.008972726296633482 - Val Accuracy: 0.848\n",
      "\n",
      "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2370, Loss 0.0005416995263658464\n",
      "\t\tRESULT EPOCH 68:\n",
      "\t\t\tTrain Loss: 0.0009547088744251855 - Train Accuracy: 0.9888392857142857\n",
      "\t\t\tVal Loss: 0.009576498530805111 - Val Accuracy: 0.85\n",
      "\n",
      "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2400, Loss 0.0011041149264201522\n",
      "\t\tRESULT EPOCH 69:\n",
      "\t\t\tTrain Loss: 0.0009269213553385011 - Train Accuracy: 0.9912946428571429\n",
      "\t\t\tVal Loss: 0.010446240659803152 - Val Accuracy: 0.852\n",
      "\n",
      "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2430, Loss 0.0007619270472787321\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/8 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tRESULT EPOCH 70:\n",
      "\t\t\tTrain Loss: 0.0009036533650942147 - Train Accuracy: 0.9901785714285715\n",
      "\t\t\tVal Loss: 0.009442933602258563 - Val Accuracy: 0.848\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 18.61it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "\tResults STAGE 1:\n",
      "\t\tTrain Mean Accuracy: 0.8356377551020409\n",
      "\t\tVal Mean Accuracy: 0.7258571428571428\n",
      "\t\tTest Accuracy: 0.844\n",
      "\n",
      "STARTING FINE TUNING STAGE 2...\n",
      "\tSTARTING EPOCH 1 - LR=[2]...\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tTrain step - Step 30, Loss 0.02408362366259098\n",
      "\t\tRESULT EPOCH 1:\n",
      "\t\t\tTrain Loss: 0.05120790797684874 - Train Accuracy: 0.2654017857142857\n",
      "\t\t\tVal Loss: 0.02846005279570818 - Val Accuracy: 0.418\n",
      "\n",
      "\tSTARTING EPOCH 2 - LR=[2]...\n",
      "\t\tTrain step - Step 60, Loss 0.017756454646587372\n",
      "\t\tRESULT EPOCH 2:\n",
      "\t\t\tTrain Loss: 0.01954804134688207 - Train Accuracy: 0.5665178571428572\n",
      "\t\t\tVal Loss: 0.018061558715999126 - Val Accuracy: 0.594\n",
      "\n",
      "\tSTARTING EPOCH 3 - LR=[2]...\n",
      "\t\tTrain step - Step 90, Loss 0.015072966925799847\n",
      "\t\tRESULT EPOCH 3:\n",
      "\t\t\tTrain Loss: 0.01616181071315493 - Train Accuracy: 0.6482142857142857\n",
      "\t\t\tVal Loss: 0.016610012156888843 - Val Accuracy: 0.638\n",
      "\n",
      "\tSTARTING EPOCH 4 - LR=[2]...\n",
      "\t\tTrain step - Step 120, Loss 0.014214439317584038\n",
      "\t\tRESULT EPOCH 4:\n",
      "\t\t\tTrain Loss: 0.014084012300840446 - Train Accuracy: 0.709375\n",
      "\t\t\tVal Loss: 0.013639807235449553 - Val Accuracy: 0.718\n",
      "\n",
      "\tSTARTING EPOCH 5 - LR=[2]...\n",
      "\t\tTrain step - Step 150, Loss 0.014701482839882374\n",
      "\t\tRESULT EPOCH 5:\n",
      "\t\t\tTrain Loss: 0.012454793974757194 - Train Accuracy: 0.746875\n",
      "\t\t\tVal Loss: 0.015397857408970594 - Val Accuracy: 0.698\n",
      "\n",
      "\tSTARTING EPOCH 6 - LR=[2]...\n",
      "\t\tTrain step - Step 180, Loss 0.011195138096809387\n",
      "\t\tRESULT EPOCH 6:\n",
      "\t\t\tTrain Loss: 0.011876176377492291 - Train Accuracy: 0.7620535714285714\n",
      "\t\t\tVal Loss: 0.013538180151954293 - Val Accuracy: 0.748\n",
      "\n",
      "\tSTARTING EPOCH 7 - LR=[2]...\n",
      "\t\tTrain step - Step 210, Loss 0.009267414920032024\n",
      "\t\tTrain step - Step 240, Loss 0.011824213899672031\n",
      "\t\tRESULT EPOCH 7:\n",
      "\t\t\tTrain Loss: 0.010304585391921656 - Train Accuracy: 0.7984375\n",
      "\t\t\tVal Loss: 0.0134076161775738 - Val Accuracy: 0.742\n",
      "\n",
      "\tSTARTING EPOCH 8 - LR=[2]...\n",
      "\t\tTrain step - Step 270, Loss 0.010515171103179455\n",
      "\t\tRESULT EPOCH 8:\n",
      "\t\t\tTrain Loss: 0.009500454618994679 - Train Accuracy: 0.8167410714285714\n",
      "\t\t\tVal Loss: 0.013225210597738624 - Val Accuracy: 0.744\n",
      "\n",
      "\tSTARTING EPOCH 9 - LR=[2]...\n",
      "\t\tTrain step - Step 300, Loss 0.007675368804484606\n",
      "\t\tRESULT EPOCH 9:\n",
      "\t\t\tTrain Loss: 0.009188260617000716 - Train Accuracy: 0.8243303571428572\n",
      "\t\t\tVal Loss: 0.01335848681628704 - Val Accuracy: 0.748\n",
      "\n",
      "\tSTARTING EPOCH 10 - LR=[2]...\n",
      "\t\tTrain step - Step 330, Loss 0.009615696966648102\n",
      "\t\tRESULT EPOCH 10:\n",
      "\t\t\tTrain Loss: 0.00879956872335502 - Train Accuracy: 0.8325892857142857\n",
      "\t\t\tVal Loss: 0.011127432808279991 - Val Accuracy: 0.782\n",
      "\n",
      "\tSTARTING EPOCH 11 - LR=[2]...\n",
      "\t\tTrain step - Step 360, Loss 0.007200950291007757\n",
      "\t\tRESULT EPOCH 11:\n",
      "\t\t\tTrain Loss: 0.008145037253520318 - Train Accuracy: 0.846875\n",
      "\t\t\tVal Loss: 0.01302206702530384 - Val Accuracy: 0.758\n",
      "\n",
      "\tSTARTING EPOCH 12 - LR=[2]...\n",
      "\t\tTrain step - Step 390, Loss 0.008273210376501083\n",
      "\t\tRESULT EPOCH 12:\n",
      "\t\t\tTrain Loss: 0.007927069440484047 - Train Accuracy: 0.85\n",
      "\t\t\tVal Loss: 0.012122158193960786 - Val Accuracy: 0.764\n",
      "\n",
      "\tSTARTING EPOCH 13 - LR=[2]...\n",
      "\t\tTrain step - Step 420, Loss 0.007669561542570591\n",
      "\t\tTrain step - Step 450, Loss 0.007650717161595821\n",
      "\t\tRESULT EPOCH 13:\n",
      "\t\t\tTrain Loss: 0.007119609056306737 - Train Accuracy: 0.8709821428571428\n",
      "\t\t\tVal Loss: 0.010931657394394279 - Val Accuracy: 0.786\n",
      "\n",
      "\tSTARTING EPOCH 14 - LR=[2]...\n",
      "\t\tTrain step - Step 480, Loss 0.008014003746211529\n",
      "\t\tRESULT EPOCH 14:\n",
      "\t\t\tTrain Loss: 0.0068867392571909086 - Train Accuracy: 0.8678571428571429\n",
      "\t\t\tVal Loss: 0.010692436713725328 - Val Accuracy: 0.782\n",
      "\n",
      "\tSTARTING EPOCH 15 - LR=[2]...\n",
      "\t\tTrain step - Step 510, Loss 0.008525797165930271\n",
      "\t\tRESULT EPOCH 15:\n",
      "\t\t\tTrain Loss: 0.0068097068662089965 - Train Accuracy: 0.8736607142857142\n",
      "\t\t\tVal Loss: 0.012495305389165878 - Val Accuracy: 0.762\n",
      "\n",
      "\tSTARTING EPOCH 16 - LR=[2]...\n",
      "\t\tTrain step - Step 540, Loss 0.005935183260589838\n",
      "\t\tRESULT EPOCH 16:\n",
      "\t\t\tTrain Loss: 0.006068019129868064 - Train Accuracy: 0.8866071428571428\n",
      "\t\t\tVal Loss: 0.010193227441050112 - Val Accuracy: 0.818\n",
      "\n",
      "\tSTARTING EPOCH 17 - LR=[2]...\n",
      "\t\tTrain step - Step 570, Loss 0.005954327527433634\n",
      "\t\tRESULT EPOCH 17:\n",
      "\t\t\tTrain Loss: 0.006241305944110666 - Train Accuracy: 0.8848214285714285\n",
      "\t\t\tVal Loss: 0.00976980000268668 - Val Accuracy: 0.806\n",
      "\n",
      "\tSTARTING EPOCH 18 - LR=[2]...\n",
      "\t\tTrain step - Step 600, Loss 0.00647898530587554\n",
      "\t\tRESULT EPOCH 18:\n",
      "\t\t\tTrain Loss: 0.0061556752771139145 - Train Accuracy: 0.8879464285714286\n",
      "\t\t\tVal Loss: 0.010740582016296685 - Val Accuracy: 0.778\n",
      "\n",
      "\tSTARTING EPOCH 19 - LR=[2]...\n",
      "\t\tTrain step - Step 630, Loss 0.004665064625442028\n",
      "\t\tTrain step - Step 660, Loss 0.0054819416254758835\n",
      "\t\tRESULT EPOCH 19:\n",
      "\t\t\tTrain Loss: 0.005701928412807839 - Train Accuracy: 0.8917410714285714\n",
      "\t\t\tVal Loss: 0.011993139050900936 - Val Accuracy: 0.776\n",
      "\n",
      "\tSTARTING EPOCH 20 - LR=[2]...\n",
      "\t\tTrain step - Step 690, Loss 0.004709349945187569\n",
      "\t\tRESULT EPOCH 20:\n",
      "\t\t\tTrain Loss: 0.005500907018514616 - Train Accuracy: 0.9006696428571429\n",
      "\t\t\tVal Loss: 0.013195399544201791 - Val Accuracy: 0.766\n",
      "\n",
      "\tSTARTING EPOCH 21 - LR=[2]...\n",
      "\t\tTrain step - Step 720, Loss 0.005250199697911739\n",
      "\t\tRESULT EPOCH 21:\n",
      "\t\t\tTrain Loss: 0.005550605411242161 - Train Accuracy: 0.8970982142857142\n",
      "\t\t\tVal Loss: 0.011728639830835164 - Val Accuracy: 0.782\n",
      "\n",
      "\tSTARTING EPOCH 22 - LR=[2]...\n",
      "\t\tTrain step - Step 750, Loss 0.0054775686003267765\n",
      "\t\tRESULT EPOCH 22:\n",
      "\t\t\tTrain Loss: 0.004889263904520443 - Train Accuracy: 0.9180803571428572\n",
      "\t\t\tVal Loss: 0.010035716812126338 - Val Accuracy: 0.83\n",
      "\n",
      "\tSTARTING EPOCH 23 - LR=[2]...\n",
      "\t\tTrain step - Step 780, Loss 0.004334780387580395\n",
      "\t\tRESULT EPOCH 23:\n",
      "\t\t\tTrain Loss: 0.004863450719442751 - Train Accuracy: 0.9100446428571428\n",
      "\t\t\tVal Loss: 0.010370466276071966 - Val Accuracy: 0.814\n",
      "\n",
      "\tSTARTING EPOCH 24 - LR=[2]...\n",
      "\t\tTrain step - Step 810, Loss 0.0030115728732198477\n",
      "\t\tRESULT EPOCH 24:\n",
      "\t\t\tTrain Loss: 0.004692128453669803 - Train Accuracy: 0.9171875\n",
      "\t\t\tVal Loss: 0.012348039890639484 - Val Accuracy: 0.776\n",
      "\n",
      "\tSTARTING EPOCH 25 - LR=[2]...\n",
      "\t\tTrain step - Step 840, Loss 0.004140826407819986\n",
      "\t\tTrain step - Step 870, Loss 0.005747061688452959\n",
      "\t\tRESULT EPOCH 25:\n",
      "\t\t\tTrain Loss: 0.004953668426190104 - Train Accuracy: 0.9129464285714286\n",
      "\t\t\tVal Loss: 0.010565663920715451 - Val Accuracy: 0.806\n",
      "\n",
      "\tSTARTING EPOCH 26 - LR=[2]...\n",
      "\t\tTrain step - Step 900, Loss 0.003882850054651499\n",
      "\t\tRESULT EPOCH 26:\n",
      "\t\t\tTrain Loss: 0.005116205589313592 - Train Accuracy: 0.9040178571428571\n",
      "\t\t\tVal Loss: 0.012157236575149 - Val Accuracy: 0.81\n",
      "\n",
      "\tSTARTING EPOCH 27 - LR=[2]...\n",
      "\t\tTrain step - Step 930, Loss 0.005541305523365736\n",
      "\t\tRESULT EPOCH 27:\n",
      "\t\t\tTrain Loss: 0.004529750579968095 - Train Accuracy: 0.9169642857142857\n",
      "\t\t\tVal Loss: 0.010420998325571418 - Val Accuracy: 0.806\n",
      "\n",
      "\tSTARTING EPOCH 28 - LR=[2]...\n",
      "\t\tTrain step - Step 960, Loss 0.00336684868671\n",
      "\t\tRESULT EPOCH 28:\n",
      "\t\t\tTrain Loss: 0.004116620981533613 - Train Accuracy: 0.9292410714285714\n",
      "\t\t\tVal Loss: 0.010808907565660775 - Val Accuracy: 0.806\n",
      "\n",
      "\tSTARTING EPOCH 29 - LR=[2]...\n",
      "\t\tTrain step - Step 990, Loss 0.0032068588770926\n",
      "\t\tRESULT EPOCH 29:\n",
      "\t\t\tTrain Loss: 0.004118745354935527 - Train Accuracy: 0.9254464285714286\n",
      "\t\t\tVal Loss: 0.00968477560672909 - Val Accuracy: 0.806\n",
      "\n",
      "\tSTARTING EPOCH 30 - LR=[2]...\n",
      "\t\tTrain step - Step 1020, Loss 0.0043832119554281235\n",
      "\t\tRESULT EPOCH 30:\n",
      "\t\t\tTrain Loss: 0.004145049776083657 - Train Accuracy: 0.9214285714285714\n",
      "\t\t\tVal Loss: 0.010774896596558392 - Val Accuracy: 0.8\n",
      "\n",
      "\tSTARTING EPOCH 31 - LR=[2]...\n",
      "\t\tTrain step - Step 1050, Loss 0.0027775478083640337\n",
      "\t\tTrain step - Step 1080, Loss 0.0032469278667122126\n",
      "\t\tRESULT EPOCH 31:\n",
      "\t\t\tTrain Loss: 0.0039694877175082055 - Train Accuracy: 0.9252232142857143\n",
      "\t\t\tVal Loss: 0.012648731877561659 - Val Accuracy: 0.784\n",
      "\n",
      "\tSTARTING EPOCH 32 - LR=[2]...\n",
      "\t\tTrain step - Step 1110, Loss 0.0037601590156555176\n",
      "\t\tRESULT EPOCH 32:\n",
      "\t\t\tTrain Loss: 0.003993662130752845 - Train Accuracy: 0.9232142857142858\n",
      "\t\t\tVal Loss: 0.013014334253966808 - Val Accuracy: 0.784\n",
      "\n",
      "\tSTARTING EPOCH 33 - LR=[2]...\n",
      "\t\tTrain step - Step 1140, Loss 0.004576403647661209\n",
      "\t\tRESULT EPOCH 33:\n",
      "\t\t\tTrain Loss: 0.0042027552146464585 - Train Accuracy: 0.928125\n",
      "\t\t\tVal Loss: 0.010667566326446831 - Val Accuracy: 0.808\n",
      "\n",
      "\tSTARTING EPOCH 34 - LR=[2]...\n",
      "\t\tTrain step - Step 1170, Loss 0.005471964832395315\n",
      "\t\tRESULT EPOCH 34:\n",
      "\t\t\tTrain Loss: 0.003995712819908346 - Train Accuracy: 0.9254464285714286\n",
      "\t\t\tVal Loss: 0.008404853055253625 - Val Accuracy: 0.838\n",
      "\n",
      "\tSTARTING EPOCH 35 - LR=[2]...\n",
      "\t\tTrain step - Step 1200, Loss 0.0025584411341696978\n",
      "\t\tRESULT EPOCH 35:\n",
      "\t\t\tTrain Loss: 0.003312570748052427 - Train Accuracy: 0.9404017857142857\n",
      "\t\t\tVal Loss: 0.009545685723423958 - Val Accuracy: 0.82\n",
      "\n",
      "\tSTARTING EPOCH 36 - LR=[2]...\n",
      "\t\tTrain step - Step 1230, Loss 0.0021746428683400154\n",
      "\t\tRESULT EPOCH 36:\n",
      "\t\t\tTrain Loss: 0.003292057619962309 - Train Accuracy: 0.9453125\n",
      "\t\t\tVal Loss: 0.008879221160896122 - Val Accuracy: 0.848\n",
      "\n",
      "\tSTARTING EPOCH 37 - LR=[2]...\n",
      "\t\tTrain step - Step 1260, Loss 0.002421373501420021\n",
      "\t\tTrain step - Step 1290, Loss 0.004889425355941057\n",
      "\t\tRESULT EPOCH 37:\n",
      "\t\t\tTrain Loss: 0.003341280382924846 - Train Accuracy: 0.9430803571428571\n",
      "\t\t\tVal Loss: 0.010830956744030118 - Val Accuracy: 0.818\n",
      "\n",
      "\tSTARTING EPOCH 38 - LR=[2]...\n",
      "\t\tTrain step - Step 1320, Loss 0.003416722873225808\n",
      "\t\tRESULT EPOCH 38:\n",
      "\t\t\tTrain Loss: 0.002991648603762899 - Train Accuracy: 0.9479910714285714\n",
      "\t\t\tVal Loss: 0.010447640204802155 - Val Accuracy: 0.822\n",
      "\n",
      "\tSTARTING EPOCH 39 - LR=[2]...\n",
      "\t\tTrain step - Step 1350, Loss 0.003220665268599987\n",
      "\t\tRESULT EPOCH 39:\n",
      "\t\t\tTrain Loss: 0.00347040886990726 - Train Accuracy: 0.9424107142857143\n",
      "\t\t\tVal Loss: 0.011432421626523137 - Val Accuracy: 0.81\n",
      "\n",
      "\tSTARTING EPOCH 40 - LR=[2]...\n",
      "\t\tTrain step - Step 1380, Loss 0.0038598317187279463\n",
      "\t\tRESULT EPOCH 40:\n",
      "\t\t\tTrain Loss: 0.0033108889923564025 - Train Accuracy: 0.9410714285714286\n",
      "\t\t\tVal Loss: 0.010675373487174511 - Val Accuracy: 0.834\n",
      "\n",
      "\tSTARTING EPOCH 41 - LR=[2]...\n",
      "\t\tTrain step - Step 1410, Loss 0.00175286375451833\n",
      "\t\tRESULT EPOCH 41:\n",
      "\t\t\tTrain Loss: 0.0031446778514821615 - Train Accuracy: 0.9446428571428571\n",
      "\t\t\tVal Loss: 0.012217962997965515 - Val Accuracy: 0.8\n",
      "\n",
      "\tSTARTING EPOCH 42 - LR=[2]...\n",
      "\t\tTrain step - Step 1440, Loss 0.00482315244153142\n",
      "\t\tRESULT EPOCH 42:\n",
      "\t\t\tTrain Loss: 0.0034946944398273317 - Train Accuracy: 0.9401785714285714\n",
      "\t\t\tVal Loss: 0.014590459875762463 - Val Accuracy: 0.786\n",
      "\n",
      "\tSTARTING EPOCH 43 - LR=[2]...\n",
      "\t\tTrain step - Step 1470, Loss 0.0037650007288903\n",
      "\t\tTrain step - Step 1500, Loss 0.0013285290915519\n",
      "\t\tRESULT EPOCH 43:\n",
      "\t\t\tTrain Loss: 0.003249415442613619 - Train Accuracy: 0.9428571428571428\n",
      "\t\t\tVal Loss: 0.018732276977971196 - Val Accuracy: 0.712\n",
      "\n",
      "\tSTARTING EPOCH 44 - LR=[2]...\n",
      "\t\tTrain step - Step 1530, Loss 0.00199239794164896\n",
      "\t\tRESULT EPOCH 44:\n",
      "\t\t\tTrain Loss: 0.003255791845731437 - Train Accuracy: 0.9470982142857143\n",
      "\t\t\tVal Loss: 0.008833309984765947 - Val Accuracy: 0.846\n",
      "\n",
      "\tSTARTING EPOCH 45 - LR=[2]...\n",
      "\t\tTrain step - Step 1560, Loss 0.0050998255610466\n",
      "\t\tRESULT EPOCH 45:\n",
      "\t\t\tTrain Loss: 0.002571367715219302 - Train Accuracy: 0.9587053571428571\n",
      "\t\t\tVal Loss: 0.010897337342612445 - Val Accuracy: 0.806\n",
      "\n",
      "\tSTARTING EPOCH 46 - LR=[2]...\n",
      "\t\tTrain step - Step 1590, Loss 0.0030425649601966143\n",
      "\t\tRESULT EPOCH 46:\n",
      "\t\t\tTrain Loss: 0.0030082975314663987 - Train Accuracy: 0.9486607142857143\n",
      "\t\t\tVal Loss: 0.010397562524303794 - Val Accuracy: 0.828\n",
      "\n",
      "\tSTARTING EPOCH 47 - LR=[2]...\n",
      "\t\tTrain step - Step 1620, Loss 0.0028599840588867664\n",
      "\t\tRESULT EPOCH 47:\n",
      "\t\t\tTrain Loss: 0.003109304776548275 - Train Accuracy: 0.9441964285714286\n",
      "\t\t\tVal Loss: 0.013142199954017997 - Val Accuracy: 0.788\n",
      "\n",
      "\tSTARTING EPOCH 48 - LR=[2]...\n",
      "\t\tTrain step - Step 1650, Loss 0.001903541968204081\n",
      "\t\tRESULT EPOCH 48:\n",
      "\t\t\tTrain Loss: 0.0029866520614762393 - Train Accuracy: 0.9462053571428571\n",
      "\t\t\tVal Loss: 0.012234116322360933 - Val Accuracy: 0.828\n",
      "\n",
      "\tSTARTING EPOCH 49 - LR=[2]...\n",
      "\t\tTrain step - Step 1680, Loss 0.002682594582438469\n",
      "\t\tTrain step - Step 1710, Loss 0.0038825131487101316\n",
      "\t\tRESULT EPOCH 49:\n",
      "\t\t\tTrain Loss: 0.0024258871961917194 - Train Accuracy: 0.9573660714285714\n",
      "\t\t\tVal Loss: 0.009137849556282163 - Val Accuracy: 0.84\n",
      "\n",
      "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1740, Loss 0.0017039661761373281\n",
      "\t\tRESULT EPOCH 50:\n",
      "\t\t\tTrain Loss: 0.0016929172761073069 - Train Accuracy: 0.9738839285714286\n",
      "\t\t\tVal Loss: 0.007890924694947898 - Val Accuracy: 0.866\n",
      "\n",
      "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1770, Loss 0.000966736814007163\n",
      "\t\tRESULT EPOCH 51:\n",
      "\t\t\tTrain Loss: 0.0010403377985182618 - Train Accuracy: 0.9892857142857143\n",
      "\t\t\tVal Loss: 0.007598636671900749 - Val Accuracy: 0.876\n",
      "\n",
      "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1800, Loss 0.0007232226780615747\n",
      "\t\tRESULT EPOCH 52:\n",
      "\t\t\tTrain Loss: 0.0009424762135105474 - Train Accuracy: 0.9892857142857143\n",
      "\t\t\tVal Loss: 0.007132569560781121 - Val Accuracy: 0.882\n",
      "\n",
      "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1830, Loss 0.0012690996518358588\n",
      "\t\tRESULT EPOCH 53:\n",
      "\t\t\tTrain Loss: 0.0008597467086344426 - Train Accuracy: 0.9928571428571429\n",
      "\t\t\tVal Loss: 0.006535565364174545 - Val Accuracy: 0.87\n",
      "\n",
      "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1860, Loss 0.0008239775779657066\n",
      "\t\tRESULT EPOCH 54:\n",
      "\t\t\tTrain Loss: 0.0008042352897713759 - Train Accuracy: 0.9901785714285715\n",
      "\t\t\tVal Loss: 0.007227880181744695 - Val Accuracy: 0.884\n",
      "\n",
      "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1890, Loss 0.0010581340175122023\n",
      "\t\tTrain step - Step 1920, Loss 0.0008298758184537292\n",
      "\t\tRESULT EPOCH 55:\n",
      "\t\t\tTrain Loss: 0.000743651355151087 - Train Accuracy: 0.9928571428571429\n",
      "\t\t\tVal Loss: 0.006539001245982945 - Val Accuracy: 0.888\n",
      "\n",
      "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1950, Loss 0.0011362357763573527\n",
      "\t\tRESULT EPOCH 56:\n",
      "\t\t\tTrain Loss: 0.000682478365654658 - Train Accuracy: 0.9948660714285714\n",
      "\t\t\tVal Loss: 0.006481764139607549 - Val Accuracy: 0.886\n",
      "\n",
      "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1980, Loss 0.0007784253684803843\n",
      "\t\tRESULT EPOCH 57:\n",
      "\t\t\tTrain Loss: 0.0006480743842465537 - Train Accuracy: 0.9948660714285714\n",
      "\t\t\tVal Loss: 0.007745115668512881 - Val Accuracy: 0.87\n",
      "\n",
      "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2010, Loss 0.0003632469743024558\n",
      "\t\tRESULT EPOCH 58:\n",
      "\t\t\tTrain Loss: 0.0005916165770031512 - Train Accuracy: 0.9941964285714285\n",
      "\t\t\tVal Loss: 0.007111265673302114 - Val Accuracy: 0.876\n",
      "\n",
      "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2040, Loss 0.0004402223858051002\n",
      "\t\tRESULT EPOCH 59:\n",
      "\t\t\tTrain Loss: 0.0005299431949554543 - Train Accuracy: 0.9982142857142857\n",
      "\t\t\tVal Loss: 0.007440127665176988 - Val Accuracy: 0.88\n",
      "\n",
      "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2070, Loss 0.00041352942935191095\n",
      "\t\tRESULT EPOCH 60:\n",
      "\t\t\tTrain Loss: 0.0006467548772759203 - Train Accuracy: 0.9953125\n",
      "\t\t\tVal Loss: 0.006636720150709152 - Val Accuracy: 0.892\n",
      "\n",
      "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2100, Loss 0.00034855908597819507\n",
      "\t\tTrain step - Step 2130, Loss 0.0005884895217604935\n",
      "\t\tRESULT EPOCH 61:\n",
      "\t\t\tTrain Loss: 0.0005188173206988722 - Train Accuracy: 0.9959821428571428\n",
      "\t\t\tVal Loss: 0.006996736396104097 - Val Accuracy: 0.878\n",
      "\n",
      "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2160, Loss 0.000487088953377679\n",
      "\t\tRESULT EPOCH 62:\n",
      "\t\t\tTrain Loss: 0.0005349109265288072 - Train Accuracy: 0.9944196428571429\n",
      "\t\t\tVal Loss: 0.006904659268911928 - Val Accuracy: 0.89\n",
      "\n",
      "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2190, Loss 0.0003512435359880328\n",
      "\t\tRESULT EPOCH 63:\n",
      "\t\t\tTrain Loss: 0.0005578075053303369 - Train Accuracy: 0.9953125\n",
      "\t\t\tVal Loss: 0.007808850263245404 - Val Accuracy: 0.872\n",
      "\n",
      "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2220, Loss 0.0007471807184629142\n",
      "\t\tRESULT EPOCH 64:\n",
      "\t\t\tTrain Loss: 0.0004575332273296746 - Train Accuracy: 0.9966517857142857\n",
      "\t\t\tVal Loss: 0.006037188111804426 - Val Accuracy: 0.906\n",
      "\n",
      "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2250, Loss 0.0003349296166561544\n",
      "\t\tRESULT EPOCH 65:\n",
      "\t\t\tTrain Loss: 0.0004960221458791889 - Train Accuracy: 0.9959821428571428\n",
      "\t\t\tVal Loss: 0.006532394210807979 - Val Accuracy: 0.892\n",
      "\n",
      "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2280, Loss 0.00033636504667811096\n",
      "\t\tRESULT EPOCH 66:\n",
      "\t\t\tTrain Loss: 0.0004469528657084863 - Train Accuracy: 0.9973214285714286\n",
      "\t\t\tVal Loss: 0.0074102445505559444 - Val Accuracy: 0.878\n",
      "\n",
      "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2310, Loss 0.00034578610211610794\n",
      "\t\tTrain step - Step 2340, Loss 0.0008946807938627899\n",
      "\t\tRESULT EPOCH 67:\n",
      "\t\t\tTrain Loss: 0.0004180287094121533 - Train Accuracy: 0.9975446428571428\n",
      "\t\t\tVal Loss: 0.0071747563779354095 - Val Accuracy: 0.882\n",
      "\n",
      "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2370, Loss 0.0004768974322360009\n",
      "\t\tRESULT EPOCH 68:\n",
      "\t\t\tTrain Loss: 0.00040610885688303303 - Train Accuracy: 0.9975446428571428\n",
      "\t\t\tVal Loss: 0.00644025590736419 - Val Accuracy: 0.9\n",
      "\n",
      "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2400, Loss 0.00033936763065867126\n",
      "\t\tRESULT EPOCH 69:\n",
      "\t\t\tTrain Loss: 0.00043027123236762625 - Train Accuracy: 0.9975446428571428\n",
      "\t\t\tVal Loss: 0.007335577916819602 - Val Accuracy: 0.874\n",
      "\n",
      "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2430, Loss 0.0003795263764914125\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/16 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tRESULT EPOCH 70:\n",
      "\t\t\tTrain Loss: 0.0004723007549598281 - Train Accuracy: 0.9966517857142857\n",
      "\t\t\tVal Loss: 0.006955679622478783 - Val Accuracy: 0.888\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 23.74it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "\tResults STAGE 2:\n",
      "\t\tTrain Mean Accuracy: 0.9092442602040817\n",
      "\t\tVal Mean Accuracy: 0.8084571428571429\n",
      "\t\tTest Accuracy: 0.4445\n",
      "\n",
      "STARTING FINE TUNING STAGE 3...\n",
      "\tSTARTING EPOCH 1 - LR=[2]...\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tTrain step - Step 30, Loss 0.02483607456088066\n",
      "\t\tRESULT EPOCH 1:\n",
      "\t\t\tTrain Loss: 0.04612839339034898 - Train Accuracy: 0.29799107142857145\n",
      "\t\t\tVal Loss: 0.02413871674798429 - Val Accuracy: 0.452\n",
      "\n",
      "\tSTARTING EPOCH 2 - LR=[2]...\n",
      "\t\tTrain step - Step 60, Loss 0.018011828884482384\n",
      "\t\tRESULT EPOCH 2:\n",
      "\t\t\tTrain Loss: 0.020433028042316437 - Train Accuracy: 0.54375\n",
      "\t\t\tVal Loss: 0.019535336643457413 - Val Accuracy: 0.542\n",
      "\n",
      "\tSTARTING EPOCH 3 - LR=[2]...\n",
      "\t\tTrain step - Step 90, Loss 0.019475217908620834\n",
      "\t\tRESULT EPOCH 3:\n",
      "\t\t\tTrain Loss: 0.017773776767509325 - Train Accuracy: 0.615625\n",
      "\t\t\tVal Loss: 0.018685102928429842 - Val Accuracy: 0.58\n",
      "\n",
      "\tSTARTING EPOCH 4 - LR=[2]...\n",
      "\t\tTrain step - Step 120, Loss 0.015047849155962467\n",
      "\t\tRESULT EPOCH 4:\n",
      "\t\t\tTrain Loss: 0.015541555147085872 - Train Accuracy: 0.6674107142857143\n",
      "\t\t\tVal Loss: 0.016246644780039787 - Val Accuracy: 0.646\n",
      "\n",
      "\tSTARTING EPOCH 5 - LR=[2]...\n",
      "\t\tTrain step - Step 150, Loss 0.01668132096529007\n",
      "\t\tRESULT EPOCH 5:\n",
      "\t\t\tTrain Loss: 0.013902385905385017 - Train Accuracy: 0.7071428571428572\n",
      "\t\t\tVal Loss: 0.016435444820672274 - Val Accuracy: 0.64\n",
      "\n",
      "\tSTARTING EPOCH 6 - LR=[2]...\n",
      "\t\tTrain step - Step 180, Loss 0.013401956297457218\n",
      "\t\tRESULT EPOCH 6:\n",
      "\t\t\tTrain Loss: 0.012674174271523952 - Train Accuracy: 0.7430803571428571\n",
      "\t\t\tVal Loss: 0.014692823286168277 - Val Accuracy: 0.698\n",
      "\n",
      "\tSTARTING EPOCH 7 - LR=[2]...\n",
      "\t\tTrain step - Step 210, Loss 0.012282509356737137\n",
      "\t\tTrain step - Step 240, Loss 0.01554370392113924\n",
      "\t\tRESULT EPOCH 7:\n",
      "\t\t\tTrain Loss: 0.011972374814961637 - Train Accuracy: 0.7571428571428571\n",
      "\t\t\tVal Loss: 0.018578731454908848 - Val Accuracy: 0.616\n",
      "\n",
      "\tSTARTING EPOCH 8 - LR=[2]...\n",
      "\t\tTrain step - Step 270, Loss 0.009841601364314556\n",
      "\t\tRESULT EPOCH 8:\n",
      "\t\t\tTrain Loss: 0.011215876548417977 - Train Accuracy: 0.7761160714285714\n",
      "\t\t\tVal Loss: 0.015926165273413062 - Val Accuracy: 0.672\n",
      "\n",
      "\tSTARTING EPOCH 9 - LR=[2]...\n",
      "\t\tTrain step - Step 300, Loss 0.007314339745789766\n",
      "\t\tRESULT EPOCH 9:\n",
      "\t\t\tTrain Loss: 0.010020543994115932 - Train Accuracy: 0.80625\n",
      "\t\t\tVal Loss: 0.014706251677125692 - Val Accuracy: 0.69\n",
      "\n",
      "\tSTARTING EPOCH 10 - LR=[2]...\n",
      "\t\tTrain step - Step 330, Loss 0.013248474337160587\n",
      "\t\tRESULT EPOCH 10:\n",
      "\t\t\tTrain Loss: 0.00974899356120399 - Train Accuracy: 0.8116071428571429\n",
      "\t\t\tVal Loss: 0.016668199095875025 - Val Accuracy: 0.668\n",
      "\n",
      "\tSTARTING EPOCH 11 - LR=[2]...\n",
      "\t\tTrain step - Step 360, Loss 0.009820651262998581\n",
      "\t\tRESULT EPOCH 11:\n",
      "\t\t\tTrain Loss: 0.009477924555540085 - Train Accuracy: 0.8066964285714285\n",
      "\t\t\tVal Loss: 0.020500288112089038 - Val Accuracy: 0.626\n",
      "\n",
      "\tSTARTING EPOCH 12 - LR=[2]...\n",
      "\t\tTrain step - Step 390, Loss 0.009029547683894634\n",
      "\t\tRESULT EPOCH 12:\n",
      "\t\t\tTrain Loss: 0.008597089616315706 - Train Accuracy: 0.8330357142857143\n",
      "\t\t\tVal Loss: 0.01680510345613584 - Val Accuracy: 0.666\n",
      "\n",
      "\tSTARTING EPOCH 13 - LR=[2]...\n",
      "\t\tTrain step - Step 420, Loss 0.009498266503214836\n",
      "\t\tTrain step - Step 450, Loss 0.0057178279384970665\n",
      "\t\tRESULT EPOCH 13:\n",
      "\t\t\tTrain Loss: 0.008679692287530218 - Train Accuracy: 0.8245535714285714\n",
      "\t\t\tVal Loss: 0.013448575045913458 - Val Accuracy: 0.708\n",
      "\n",
      "\tSTARTING EPOCH 14 - LR=[2]...\n",
      "\t\tTrain step - Step 480, Loss 0.008024157024919987\n",
      "\t\tRESULT EPOCH 14:\n",
      "\t\t\tTrain Loss: 0.008009117362754685 - Train Accuracy: 0.8457589285714285\n",
      "\t\t\tVal Loss: 0.013786469586193562 - Val Accuracy: 0.72\n",
      "\n",
      "\tSTARTING EPOCH 15 - LR=[2]...\n",
      "\t\tTrain step - Step 510, Loss 0.007292113266885281\n",
      "\t\tRESULT EPOCH 15:\n",
      "\t\t\tTrain Loss: 0.007830513947244202 - Train Accuracy: 0.8553571428571428\n",
      "\t\t\tVal Loss: 0.013958836905658245 - Val Accuracy: 0.714\n",
      "\n",
      "\tSTARTING EPOCH 16 - LR=[2]...\n",
      "\t\tTrain step - Step 540, Loss 0.007771411910653114\n",
      "\t\tRESULT EPOCH 16:\n",
      "\t\t\tTrain Loss: 0.0076475635303982666 - Train Accuracy: 0.8529017857142858\n",
      "\t\t\tVal Loss: 0.013449925230816007 - Val Accuracy: 0.716\n",
      "\n",
      "\tSTARTING EPOCH 17 - LR=[2]...\n",
      "\t\tTrain step - Step 570, Loss 0.006114286836236715\n",
      "\t\tRESULT EPOCH 17:\n",
      "\t\t\tTrain Loss: 0.007091399095952511 - Train Accuracy: 0.8625\n",
      "\t\t\tVal Loss: 0.015858135768212378 - Val Accuracy: 0.686\n",
      "\n",
      "\tSTARTING EPOCH 18 - LR=[2]...\n",
      "\t\tTrain step - Step 600, Loss 0.005403958261013031\n",
      "\t\tRESULT EPOCH 18:\n",
      "\t\t\tTrain Loss: 0.007087382607694183 - Train Accuracy: 0.8662946428571429\n",
      "\t\t\tVal Loss: 0.012930501368828118 - Val Accuracy: 0.732\n",
      "\n",
      "\tSTARTING EPOCH 19 - LR=[2]...\n",
      "\t\tTrain step - Step 630, Loss 0.005916795693337917\n",
      "\t\tTrain step - Step 660, Loss 0.008333246223628521\n",
      "\t\tRESULT EPOCH 19:\n",
      "\t\t\tTrain Loss: 0.00641090509348682 - Train Accuracy: 0.8747767857142857\n",
      "\t\t\tVal Loss: 0.012913252459838986 - Val Accuracy: 0.754\n",
      "\n",
      "\tSTARTING EPOCH 20 - LR=[2]...\n",
      "\t\tTrain step - Step 690, Loss 0.0071150860749185085\n",
      "\t\tRESULT EPOCH 20:\n",
      "\t\t\tTrain Loss: 0.006631449916000877 - Train Accuracy: 0.8785714285714286\n",
      "\t\t\tVal Loss: 0.016893760534003377 - Val Accuracy: 0.678\n",
      "\n",
      "\tSTARTING EPOCH 21 - LR=[2]...\n",
      "\t\tTrain step - Step 720, Loss 0.005870593711733818\n",
      "\t\tRESULT EPOCH 21:\n",
      "\t\t\tTrain Loss: 0.006498055639011519 - Train Accuracy: 0.8736607142857142\n",
      "\t\t\tVal Loss: 0.015024881809949875 - Val Accuracy: 0.712\n",
      "\n",
      "\tSTARTING EPOCH 22 - LR=[2]...\n",
      "\t\tTrain step - Step 750, Loss 0.005562803708016872\n",
      "\t\tRESULT EPOCH 22:\n",
      "\t\t\tTrain Loss: 0.005968137338225331 - Train Accuracy: 0.890625\n",
      "\t\t\tVal Loss: 0.014721913496032357 - Val Accuracy: 0.728\n",
      "\n",
      "\tSTARTING EPOCH 23 - LR=[2]...\n",
      "\t\tTrain step - Step 780, Loss 0.006539621390402317\n",
      "\t\tRESULT EPOCH 23:\n",
      "\t\t\tTrain Loss: 0.006080664428217071 - Train Accuracy: 0.8848214285714285\n",
      "\t\t\tVal Loss: 0.01476845785509795 - Val Accuracy: 0.712\n",
      "\n",
      "\tSTARTING EPOCH 24 - LR=[2]...\n",
      "\t\tTrain step - Step 810, Loss 0.005911513231694698\n",
      "\t\tRESULT EPOCH 24:\n",
      "\t\t\tTrain Loss: 0.005406715288492185 - Train Accuracy: 0.8964285714285715\n",
      "\t\t\tVal Loss: 0.014253977220505476 - Val Accuracy: 0.754\n",
      "\n",
      "\tSTARTING EPOCH 25 - LR=[2]...\n",
      "\t\tTrain step - Step 840, Loss 0.005513764452189207\n",
      "\t\tTrain step - Step 870, Loss 0.005669523496180773\n",
      "\t\tRESULT EPOCH 25:\n",
      "\t\t\tTrain Loss: 0.005550147360190749 - Train Accuracy: 0.8953125\n",
      "\t\t\tVal Loss: 0.014650925761088729 - Val Accuracy: 0.75\n",
      "\n",
      "\tSTARTING EPOCH 26 - LR=[2]...\n",
      "\t\tTrain step - Step 900, Loss 0.00497973058372736\n",
      "\t\tRESULT EPOCH 26:\n",
      "\t\t\tTrain Loss: 0.0052023477519729305 - Train Accuracy: 0.9046875\n",
      "\t\t\tVal Loss: 0.013931214693002403 - Val Accuracy: 0.742\n",
      "\n",
      "\tSTARTING EPOCH 27 - LR=[2]...\n",
      "\t\tTrain step - Step 930, Loss 0.004889796953648329\n",
      "\t\tRESULT EPOCH 27:\n",
      "\t\t\tTrain Loss: 0.005631339091009328 - Train Accuracy: 0.8986607142857143\n",
      "\t\t\tVal Loss: 0.022177621140144765 - Val Accuracy: 0.65\n",
      "\n",
      "\tSTARTING EPOCH 28 - LR=[2]...\n",
      "\t\tTrain step - Step 960, Loss 0.005376090761274099\n",
      "\t\tRESULT EPOCH 28:\n",
      "\t\t\tTrain Loss: 0.00548336529172957 - Train Accuracy: 0.9020089285714286\n",
      "\t\t\tVal Loss: 0.015227721771225333 - Val Accuracy: 0.714\n",
      "\n",
      "\tSTARTING EPOCH 29 - LR=[2]...\n",
      "\t\tTrain step - Step 990, Loss 0.004467318300157785\n",
      "\t\tRESULT EPOCH 29:\n",
      "\t\t\tTrain Loss: 0.005556980547096048 - Train Accuracy: 0.8946428571428572\n",
      "\t\t\tVal Loss: 0.018620619317516685 - Val Accuracy: 0.674\n",
      "\n",
      "\tSTARTING EPOCH 30 - LR=[2]...\n",
      "\t\tTrain step - Step 1020, Loss 0.00550040602684021\n",
      "\t\tRESULT EPOCH 30:\n",
      "\t\t\tTrain Loss: 0.005361435455935342 - Train Accuracy: 0.9\n",
      "\t\t\tVal Loss: 0.014811473316513002 - Val Accuracy: 0.74\n",
      "\n",
      "\tSTARTING EPOCH 31 - LR=[2]...\n",
      "\t\tTrain step - Step 1050, Loss 0.003926038276404142\n",
      "\t\tTrain step - Step 1080, Loss 0.005756055004894733\n",
      "\t\tRESULT EPOCH 31:\n",
      "\t\t\tTrain Loss: 0.004696171344923121 - Train Accuracy: 0.9136160714285714\n",
      "\t\t\tVal Loss: 0.016016917186789215 - Val Accuracy: 0.718\n",
      "\n",
      "\tSTARTING EPOCH 32 - LR=[2]...\n",
      "\t\tTrain step - Step 1110, Loss 0.0038990401662886143\n",
      "\t\tRESULT EPOCH 32:\n",
      "\t\t\tTrain Loss: 0.00444443342941148 - Train Accuracy: 0.9191964285714286\n",
      "\t\t\tVal Loss: 0.020301983458921313 - Val Accuracy: 0.658\n",
      "\n",
      "\tSTARTING EPOCH 33 - LR=[2]...\n",
      "\t\tTrain step - Step 1140, Loss 0.0036433162167668343\n",
      "\t\tRESULT EPOCH 33:\n",
      "\t\t\tTrain Loss: 0.0044840103214872735 - Train Accuracy: 0.9203125\n",
      "\t\t\tVal Loss: 0.014285346143878996 - Val Accuracy: 0.736\n",
      "\n",
      "\tSTARTING EPOCH 34 - LR=[2]...\n",
      "\t\tTrain step - Step 1170, Loss 0.008374931290745735\n",
      "\t\tRESULT EPOCH 34:\n",
      "\t\t\tTrain Loss: 0.004828661640307733 - Train Accuracy: 0.9087053571428572\n",
      "\t\t\tVal Loss: 0.014683354762382805 - Val Accuracy: 0.734\n",
      "\n",
      "\tSTARTING EPOCH 35 - LR=[2]...\n",
      "\t\tTrain step - Step 1200, Loss 0.004603130277246237\n",
      "\t\tRESULT EPOCH 35:\n",
      "\t\t\tTrain Loss: 0.004800373921170831 - Train Accuracy: 0.9169642857142857\n",
      "\t\t\tVal Loss: 0.013866982189938426 - Val Accuracy: 0.75\n",
      "\n",
      "\tSTARTING EPOCH 36 - LR=[2]...\n",
      "\t\tTrain step - Step 1230, Loss 0.004211155232042074\n",
      "\t\tRESULT EPOCH 36:\n",
      "\t\t\tTrain Loss: 0.00408174516633153 - Train Accuracy: 0.9263392857142857\n",
      "\t\t\tVal Loss: 0.013708862010389566 - Val Accuracy: 0.76\n",
      "\n",
      "\tSTARTING EPOCH 37 - LR=[2]...\n",
      "\t\tTrain step - Step 1260, Loss 0.00301360827870667\n",
      "\t\tTrain step - Step 1290, Loss 0.00418771430850029\n",
      "\t\tRESULT EPOCH 37:\n",
      "\t\t\tTrain Loss: 0.004101889001737748 - Train Accuracy: 0.9290178571428571\n",
      "\t\t\tVal Loss: 0.01297733816318214 - Val Accuracy: 0.77\n",
      "\n",
      "\tSTARTING EPOCH 38 - LR=[2]...\n",
      "\t\tTrain step - Step 1320, Loss 0.004413173068314791\n",
      "\t\tRESULT EPOCH 38:\n",
      "\t\t\tTrain Loss: 0.00400635634349393 - Train Accuracy: 0.9323660714285714\n",
      "\t\t\tVal Loss: 0.011598505428992212 - Val Accuracy: 0.77\n",
      "\n",
      "\tSTARTING EPOCH 39 - LR=[2]...\n",
      "\t\tTrain step - Step 1350, Loss 0.0026656242553144693\n",
      "\t\tRESULT EPOCH 39:\n",
      "\t\t\tTrain Loss: 0.004061043388875468 - Train Accuracy: 0.9247767857142857\n",
      "\t\t\tVal Loss: 0.015308506088331342 - Val Accuracy: 0.728\n",
      "\n",
      "\tSTARTING EPOCH 40 - LR=[2]...\n",
      "\t\tTrain step - Step 1380, Loss 0.0024876119568943977\n",
      "\t\tRESULT EPOCH 40:\n",
      "\t\t\tTrain Loss: 0.0036007549979590945 - Train Accuracy: 0.9392857142857143\n",
      "\t\t\tVal Loss: 0.015741934650577605 - Val Accuracy: 0.734\n",
      "\n",
      "\tSTARTING EPOCH 41 - LR=[2]...\n",
      "\t\tTrain step - Step 1410, Loss 0.003916472662240267\n",
      "\t\tRESULT EPOCH 41:\n",
      "\t\t\tTrain Loss: 0.0036986602270709617 - Train Accuracy: 0.9332589285714286\n",
      "\t\t\tVal Loss: 0.016094507300294936 - Val Accuracy: 0.732\n",
      "\n",
      "\tSTARTING EPOCH 42 - LR=[2]...\n",
      "\t\tTrain step - Step 1440, Loss 0.004365327302366495\n",
      "\t\tRESULT EPOCH 42:\n",
      "\t\t\tTrain Loss: 0.0037336631544998716 - Train Accuracy: 0.9334821428571428\n",
      "\t\t\tVal Loss: 0.015742224408313632 - Val Accuracy: 0.736\n",
      "\n",
      "\tSTARTING EPOCH 43 - LR=[2]...\n",
      "\t\tTrain step - Step 1470, Loss 0.002222684910520911\n",
      "\t\tTrain step - Step 1500, Loss 0.00554734468460083\n",
      "\t\tRESULT EPOCH 43:\n",
      "\t\t\tTrain Loss: 0.0036643741419538855 - Train Accuracy: 0.9330357142857143\n",
      "\t\t\tVal Loss: 0.014708603033795953 - Val Accuracy: 0.732\n",
      "\n",
      "\tSTARTING EPOCH 44 - LR=[2]...\n",
      "\t\tTrain step - Step 1530, Loss 0.0034817045088857412\n",
      "\t\tRESULT EPOCH 44:\n",
      "\t\t\tTrain Loss: 0.0039192766949002235 - Train Accuracy: 0.9290178571428571\n",
      "\t\t\tVal Loss: 0.016907531768083572 - Val Accuracy: 0.734\n",
      "\n",
      "\tSTARTING EPOCH 45 - LR=[2]...\n",
      "\t\tTrain step - Step 1560, Loss 0.0031878494191914797\n",
      "\t\tRESULT EPOCH 45:\n",
      "\t\t\tTrain Loss: 0.0033063531686951006 - Train Accuracy: 0.9397321428571429\n",
      "\t\t\tVal Loss: 0.014052760903723538 - Val Accuracy: 0.76\n",
      "\n",
      "\tSTARTING EPOCH 46 - LR=[2]...\n",
      "\t\tTrain step - Step 1590, Loss 0.0028667140286415815\n",
      "\t\tRESULT EPOCH 46:\n",
      "\t\t\tTrain Loss: 0.003146230775330748 - Train Accuracy: 0.9464285714285714\n",
      "\t\t\tVal Loss: 0.012121988227590919 - Val Accuracy: 0.798\n",
      "\n",
      "\tSTARTING EPOCH 47 - LR=[2]...\n",
      "\t\tTrain step - Step 1620, Loss 0.0015116633148863912\n",
      "\t\tRESULT EPOCH 47:\n",
      "\t\t\tTrain Loss: 0.0032615283570651497 - Train Accuracy: 0.9448660714285714\n",
      "\t\t\tVal Loss: 0.016595967579632998 - Val Accuracy: 0.732\n",
      "\n",
      "\tSTARTING EPOCH 48 - LR=[2]...\n",
      "\t\tTrain step - Step 1650, Loss 0.0017021911917254329\n",
      "\t\tRESULT EPOCH 48:\n",
      "\t\t\tTrain Loss: 0.0038786057748698764 - Train Accuracy: 0.9287946428571429\n",
      "\t\t\tVal Loss: 0.02770972205325961 - Val Accuracy: 0.61\n",
      "\n",
      "\tSTARTING EPOCH 49 - LR=[2]...\n",
      "\t\tTrain step - Step 1680, Loss 0.004147189669311047\n",
      "\t\tTrain step - Step 1710, Loss 0.0026360058691352606\n",
      "\t\tRESULT EPOCH 49:\n",
      "\t\t\tTrain Loss: 0.0037138764347348896 - Train Accuracy: 0.9352678571428571\n",
      "\t\t\tVal Loss: 0.01380648068152368 - Val Accuracy: 0.764\n",
      "\n",
      "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1740, Loss 0.0016435643192380667\n",
      "\t\tRESULT EPOCH 50:\n",
      "\t\t\tTrain Loss: 0.002260125435090491 - Train Accuracy: 0.9642857142857143\n",
      "\t\t\tVal Loss: 0.011301770224235952 - Val Accuracy: 0.796\n",
      "\n",
      "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1770, Loss 0.001491443021222949\n",
      "\t\tRESULT EPOCH 51:\n",
      "\t\t\tTrain Loss: 0.0014280924573540688 - Train Accuracy: 0.9823660714285715\n",
      "\t\t\tVal Loss: 0.011233812663704157 - Val Accuracy: 0.786\n",
      "\n",
      "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1800, Loss 0.0015034195967018604\n",
      "\t\tRESULT EPOCH 52:\n",
      "\t\t\tTrain Loss: 0.0010843430812071478 - Train Accuracy: 0.9881696428571428\n",
      "\t\t\tVal Loss: 0.011091172113083303 - Val Accuracy: 0.8\n",
      "\n",
      "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1830, Loss 0.0008406908018514514\n",
      "\t\tRESULT EPOCH 53:\n",
      "\t\t\tTrain Loss: 0.001148370688315481 - Train Accuracy: 0.9870535714285714\n",
      "\t\t\tVal Loss: 0.009925538790412247 - Val Accuracy: 0.82\n",
      "\n",
      "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1860, Loss 0.0008694170392118394\n",
      "\t\tRESULT EPOCH 54:\n",
      "\t\t\tTrain Loss: 0.001005693039457713 - Train Accuracy: 0.9877232142857143\n",
      "\t\t\tVal Loss: 0.010613263817504048 - Val Accuracy: 0.806\n",
      "\n",
      "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1890, Loss 0.0009470299701206386\n",
      "\t\tTrain step - Step 1920, Loss 0.0004417163727339357\n",
      "\t\tRESULT EPOCH 55:\n",
      "\t\t\tTrain Loss: 0.0009781296780732062 - Train Accuracy: 0.9890625\n",
      "\t\t\tVal Loss: 0.010769130662083626 - Val Accuracy: 0.794\n",
      "\n",
      "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1950, Loss 0.0007003338541835546\n",
      "\t\tRESULT EPOCH 56:\n",
      "\t\t\tTrain Loss: 0.0008470290315537049 - Train Accuracy: 0.9930803571428571\n",
      "\t\t\tVal Loss: 0.010325585724785924 - Val Accuracy: 0.824\n",
      "\n",
      "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1980, Loss 0.0007910183048807085\n",
      "\t\tRESULT EPOCH 57:\n",
      "\t\t\tTrain Loss: 0.0007041025424509176 - Train Accuracy: 0.9935267857142858\n",
      "\t\t\tVal Loss: 0.010817037022206932 - Val Accuracy: 0.828\n",
      "\n",
      "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2010, Loss 0.0005294332513585687\n",
      "\t\tRESULT EPOCH 58:\n",
      "\t\t\tTrain Loss: 0.0007239745904891086 - Train Accuracy: 0.9948660714285714\n",
      "\t\t\tVal Loss: 0.011344675323925912 - Val Accuracy: 0.816\n",
      "\n",
      "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2040, Loss 0.0009875645628198981\n",
      "\t\tRESULT EPOCH 59:\n",
      "\t\t\tTrain Loss: 0.0007039360922395384 - Train Accuracy: 0.9933035714285714\n",
      "\t\t\tVal Loss: 0.011548871756531298 - Val Accuracy: 0.804\n",
      "\n",
      "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2070, Loss 0.0005935549270361662\n",
      "\t\tRESULT EPOCH 60:\n",
      "\t\t\tTrain Loss: 0.0006649499484670481 - Train Accuracy: 0.9941964285714285\n",
      "\t\t\tVal Loss: 0.011179775348864496 - Val Accuracy: 0.808\n",
      "\n",
      "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2100, Loss 0.0005524075822904706\n",
      "\t\tTrain step - Step 2130, Loss 0.0004704903403762728\n",
      "\t\tRESULT EPOCH 61:\n",
      "\t\t\tTrain Loss: 0.0005874827337850417 - Train Accuracy: 0.9953125\n",
      "\t\t\tVal Loss: 0.0116872179787606 - Val Accuracy: 0.81\n",
      "\n",
      "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2160, Loss 0.00042124598985537887\n",
      "\t\tRESULT EPOCH 62:\n",
      "\t\t\tTrain Loss: 0.0005887545441510156 - Train Accuracy: 0.9950892857142857\n",
      "\t\t\tVal Loss: 0.010351753095164895 - Val Accuracy: 0.828\n",
      "\n",
      "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2190, Loss 0.00042061135172843933\n",
      "\t\tRESULT EPOCH 63:\n",
      "\t\t\tTrain Loss: 0.0005147118969554348 - Train Accuracy: 0.9962053571428572\n",
      "\t\t\tVal Loss: 0.011526397662237287 - Val Accuracy: 0.806\n",
      "\n",
      "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2220, Loss 0.000431899941759184\n",
      "\t\tRESULT EPOCH 64:\n",
      "\t\t\tTrain Loss: 0.0005728501103086664 - Train Accuracy: 0.9935267857142858\n",
      "\t\t\tVal Loss: 0.011130525963380933 - Val Accuracy: 0.824\n",
      "\n",
      "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2250, Loss 0.00033836689544841647\n",
      "\t\tRESULT EPOCH 65:\n",
      "\t\t\tTrain Loss: 0.0005781171203125268 - Train Accuracy: 0.9955357142857143\n",
      "\t\t\tVal Loss: 0.010794218513183296 - Val Accuracy: 0.822\n",
      "\n",
      "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2280, Loss 0.00039487110916525126\n",
      "\t\tRESULT EPOCH 66:\n",
      "\t\t\tTrain Loss: 0.0004930548228523028 - Train Accuracy: 0.9959821428571428\n",
      "\t\t\tVal Loss: 0.011342720361426473 - Val Accuracy: 0.814\n",
      "\n",
      "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2310, Loss 0.0005261351470835507\n",
      "\t\tTrain step - Step 2340, Loss 0.0002503837167751044\n",
      "\t\tRESULT EPOCH 67:\n",
      "\t\t\tTrain Loss: 0.0004700197297747114 - Train Accuracy: 0.9964285714285714\n",
      "\t\t\tVal Loss: 0.01073948061093688 - Val Accuracy: 0.814\n",
      "\n",
      "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2370, Loss 0.0007746940827928483\n",
      "\t\tRESULT EPOCH 68:\n",
      "\t\t\tTrain Loss: 0.0005288054634417806 - Train Accuracy: 0.9948660714285714\n",
      "\t\t\tVal Loss: 0.010392937751021236 - Val Accuracy: 0.836\n",
      "\n",
      "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2400, Loss 0.0005402297247201204\n",
      "\t\tRESULT EPOCH 69:\n",
      "\t\t\tTrain Loss: 0.0004518676574142384 - Train Accuracy: 0.9966517857142857\n",
      "\t\t\tVal Loss: 0.010728450841270387 - Val Accuracy: 0.826\n",
      "\n",
      "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2430, Loss 0.00022509897826239467\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/24 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tRESULT EPOCH 70:\n",
      "\t\t\tTrain Loss: 0.0005269105242665059 - Train Accuracy: 0.9950892857142857\n",
      "\t\t\tVal Loss: 0.011205499293282628 - Val Accuracy: 0.816\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 25.28it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "\tResults STAGE 3:\n",
      "\t\tTrain Mean Accuracy: 0.8949170918367347\n",
      "\t\tVal Mean Accuracy: 0.7344857142857144\n",
      "\t\tTest Accuracy: 0.278\n",
      "\n",
      "STARTING FINE TUNING STAGE 4...\n",
      "\tSTARTING EPOCH 1 - LR=[2]...\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tTrain step - Step 30, Loss 0.02472294308245182\n",
      "\t\tRESULT EPOCH 1:\n",
      "\t\t\tTrain Loss: 0.04409422012312072 - Train Accuracy: 0.28080357142857143\n",
      "\t\t\tVal Loss: 0.023984130937606096 - Val Accuracy: 0.45\n",
      "\n",
      "\tSTARTING EPOCH 2 - LR=[2]...\n",
      "\t\tTrain step - Step 60, Loss 0.01692338101565838\n",
      "\t\tRESULT EPOCH 2:\n",
      "\t\t\tTrain Loss: 0.01858893582331283 - Train Accuracy: 0.590625\n",
      "\t\t\tVal Loss: 0.016566341277211905 - Val Accuracy: 0.61\n",
      "\n",
      "\tSTARTING EPOCH 3 - LR=[2]...\n",
      "\t\tTrain step - Step 90, Loss 0.014043237082660198\n",
      "\t\tRESULT EPOCH 3:\n",
      "\t\t\tTrain Loss: 0.014921134018472263 - Train Accuracy: 0.6720982142857143\n",
      "\t\t\tVal Loss: 0.01463011116720736 - Val Accuracy: 0.676\n",
      "\n",
      "\tSTARTING EPOCH 4 - LR=[2]...\n",
      "\t\tTrain step - Step 120, Loss 0.011516362428665161\n",
      "\t\tRESULT EPOCH 4:\n",
      "\t\t\tTrain Loss: 0.012929796241223812 - Train Accuracy: 0.7252232142857142\n",
      "\t\t\tVal Loss: 0.015494880499318242 - Val Accuracy: 0.672\n",
      "\n",
      "\tSTARTING EPOCH 5 - LR=[2]...\n",
      "\t\tTrain step - Step 150, Loss 0.012377106584608555\n",
      "\t\tRESULT EPOCH 5:\n",
      "\t\t\tTrain Loss: 0.011693450090076243 - Train Accuracy: 0.7551339285714286\n",
      "\t\t\tVal Loss: 0.013170176767744124 - Val Accuracy: 0.738\n",
      "\n",
      "\tSTARTING EPOCH 6 - LR=[2]...\n",
      "\t\tTrain step - Step 180, Loss 0.01183702889829874\n",
      "\t\tRESULT EPOCH 6:\n",
      "\t\t\tTrain Loss: 0.01075068549918277 - Train Accuracy: 0.784375\n",
      "\t\t\tVal Loss: 0.01623915508389473 - Val Accuracy: 0.662\n",
      "\n",
      "\tSTARTING EPOCH 7 - LR=[2]...\n",
      "\t\tTrain step - Step 210, Loss 0.0071162208914756775\n",
      "\t\tTrain step - Step 240, Loss 0.01038014143705368\n",
      "\t\tRESULT EPOCH 7:\n",
      "\t\t\tTrain Loss: 0.009454466761755091 - Train Accuracy: 0.8120535714285714\n",
      "\t\t\tVal Loss: 0.014733234769664705 - Val Accuracy: 0.724\n",
      "\n",
      "\tSTARTING EPOCH 8 - LR=[2]...\n",
      "\t\tTrain step - Step 270, Loss 0.008080944418907166\n",
      "\t\tRESULT EPOCH 8:\n",
      "\t\t\tTrain Loss: 0.009322907323283808 - Train Accuracy: 0.8200892857142857\n",
      "\t\t\tVal Loss: 0.010959890787489712 - Val Accuracy: 0.766\n",
      "\n",
      "\tSTARTING EPOCH 9 - LR=[2]...\n",
      "\t\tTrain step - Step 300, Loss 0.009555218741297722\n",
      "\t\tRESULT EPOCH 9:\n",
      "\t\t\tTrain Loss: 0.008401302926774537 - Train Accuracy: 0.8395089285714286\n",
      "\t\t\tVal Loss: 0.012837058049626648 - Val Accuracy: 0.75\n",
      "\n",
      "\tSTARTING EPOCH 10 - LR=[2]...\n",
      "\t\tTrain step - Step 330, Loss 0.007857627235352993\n",
      "\t\tRESULT EPOCH 10:\n",
      "\t\t\tTrain Loss: 0.008185925161732095 - Train Accuracy: 0.8428571428571429\n",
      "\t\t\tVal Loss: 0.017595450393855572 - Val Accuracy: 0.69\n",
      "\n",
      "\tSTARTING EPOCH 11 - LR=[2]...\n",
      "\t\tTrain step - Step 360, Loss 0.007357493508607149\n",
      "\t\tRESULT EPOCH 11:\n",
      "\t\t\tTrain Loss: 0.0074489331405077665 - Train Accuracy: 0.8589285714285714\n",
      "\t\t\tVal Loss: 0.011756551917642355 - Val Accuracy: 0.778\n",
      "\n",
      "\tSTARTING EPOCH 12 - LR=[2]...\n",
      "\t\tTrain step - Step 390, Loss 0.007286227308213711\n",
      "\t\tRESULT EPOCH 12:\n",
      "\t\t\tTrain Loss: 0.007365680605705295 - Train Accuracy: 0.8620535714285714\n",
      "\t\t\tVal Loss: 0.013305723667144775 - Val Accuracy: 0.736\n",
      "\n",
      "\tSTARTING EPOCH 13 - LR=[2]...\n",
      "\t\tTrain step - Step 420, Loss 0.006041291169822216\n",
      "\t\tTrain step - Step 450, Loss 0.00806939322501421\n",
      "\t\tRESULT EPOCH 13:\n",
      "\t\t\tTrain Loss: 0.006983216745512826 - Train Accuracy: 0.8683035714285714\n",
      "\t\t\tVal Loss: 0.009439061861485243 - Val Accuracy: 0.798\n",
      "\n",
      "\tSTARTING EPOCH 14 - LR=[2]...\n",
      "\t\tTrain step - Step 480, Loss 0.005904031451791525\n",
      "\t\tRESULT EPOCH 14:\n",
      "\t\t\tTrain Loss: 0.006157773799662079 - Train Accuracy: 0.8877232142857143\n",
      "\t\t\tVal Loss: 0.012337782885879278 - Val Accuracy: 0.774\n",
      "\n",
      "\tSTARTING EPOCH 15 - LR=[2]...\n",
      "\t\tTrain step - Step 510, Loss 0.0071469820104539394\n",
      "\t\tRESULT EPOCH 15:\n",
      "\t\t\tTrain Loss: 0.006006499772359218 - Train Accuracy: 0.8841517857142858\n",
      "\t\t\tVal Loss: 0.01172349276021123 - Val Accuracy: 0.784\n",
      "\n",
      "\tSTARTING EPOCH 16 - LR=[2]...\n",
      "\t\tTrain step - Step 540, Loss 0.006141044199466705\n",
      "\t\tRESULT EPOCH 16:\n",
      "\t\t\tTrain Loss: 0.006103032434891377 - Train Accuracy: 0.8879464285714286\n",
      "\t\t\tVal Loss: 0.012366733164526522 - Val Accuracy: 0.758\n",
      "\n",
      "\tSTARTING EPOCH 17 - LR=[2]...\n",
      "\t\tTrain step - Step 570, Loss 0.007906923070549965\n",
      "\t\tRESULT EPOCH 17:\n",
      "\t\t\tTrain Loss: 0.005964852896119867 - Train Accuracy: 0.8917410714285714\n",
      "\t\t\tVal Loss: 0.014641197631135583 - Val Accuracy: 0.748\n",
      "\n",
      "\tSTARTING EPOCH 18 - LR=[2]...\n",
      "\t\tTrain step - Step 600, Loss 0.005942975636571646\n",
      "\t\tRESULT EPOCH 18:\n",
      "\t\t\tTrain Loss: 0.005402426787519029 - Train Accuracy: 0.903125\n",
      "\t\t\tVal Loss: 0.013807703973725438 - Val Accuracy: 0.776\n",
      "\n",
      "\tSTARTING EPOCH 19 - LR=[2]...\n",
      "\t\tTrain step - Step 630, Loss 0.00434800423681736\n",
      "\t\tTrain step - Step 660, Loss 0.0059776040725409985\n",
      "\t\tRESULT EPOCH 19:\n",
      "\t\t\tTrain Loss: 0.005296458064445428 - Train Accuracy: 0.9051339285714286\n",
      "\t\t\tVal Loss: 0.010465066879987717 - Val Accuracy: 0.816\n",
      "\n",
      "\tSTARTING EPOCH 20 - LR=[2]...\n",
      "\t\tTrain step - Step 690, Loss 0.007848352193832397\n",
      "\t\tRESULT EPOCH 20:\n",
      "\t\t\tTrain Loss: 0.00554897607570248 - Train Accuracy: 0.8984375\n",
      "\t\t\tVal Loss: 0.01497497851960361 - Val Accuracy: 0.75\n",
      "\n",
      "\tSTARTING EPOCH 21 - LR=[2]...\n",
      "\t\tTrain step - Step 720, Loss 0.005914730951189995\n",
      "\t\tRESULT EPOCH 21:\n",
      "\t\t\tTrain Loss: 0.005119532878909793 - Train Accuracy: 0.9037946428571428\n",
      "\t\t\tVal Loss: 0.013034410076215863 - Val Accuracy: 0.76\n",
      "\n",
      "\tSTARTING EPOCH 22 - LR=[2]...\n",
      "\t\tTrain step - Step 750, Loss 0.004357496276497841\n",
      "\t\tRESULT EPOCH 22:\n",
      "\t\t\tTrain Loss: 0.005149360167394791 - Train Accuracy: 0.9026785714285714\n",
      "\t\t\tVal Loss: 0.01131447497755289 - Val Accuracy: 0.79\n",
      "\n",
      "\tSTARTING EPOCH 23 - LR=[2]...\n",
      "\t\tTrain step - Step 780, Loss 0.005317343398928642\n",
      "\t\tRESULT EPOCH 23:\n",
      "\t\t\tTrain Loss: 0.00489969361972596 - Train Accuracy: 0.9104910714285714\n",
      "\t\t\tVal Loss: 0.011591506423428655 - Val Accuracy: 0.778\n",
      "\n",
      "\tSTARTING EPOCH 24 - LR=[2]...\n",
      "\t\tTrain step - Step 810, Loss 0.0038817173335701227\n",
      "\t\tRESULT EPOCH 24:\n",
      "\t\t\tTrain Loss: 0.004665294349459666 - Train Accuracy: 0.9160714285714285\n",
      "\t\t\tVal Loss: 0.01136239361949265 - Val Accuracy: 0.794\n",
      "\n",
      "\tSTARTING EPOCH 25 - LR=[2]...\n",
      "\t\tTrain step - Step 840, Loss 0.004245864227414131\n",
      "\t\tTrain step - Step 870, Loss 0.0036865132860839367\n",
      "\t\tRESULT EPOCH 25:\n",
      "\t\t\tTrain Loss: 0.004512765710907323 - Train Accuracy: 0.9176339285714286\n",
      "\t\t\tVal Loss: 0.013994294567964971 - Val Accuracy: 0.784\n",
      "\n",
      "\tSTARTING EPOCH 26 - LR=[2]...\n",
      "\t\tTrain step - Step 900, Loss 0.00533424224704504\n",
      "\t\tRESULT EPOCH 26:\n",
      "\t\t\tTrain Loss: 0.004331429409129279 - Train Accuracy: 0.9158482142857143\n",
      "\t\t\tVal Loss: 0.010756934178061783 - Val Accuracy: 0.808\n",
      "\n",
      "\tSTARTING EPOCH 27 - LR=[2]...\n",
      "\t\tTrain step - Step 930, Loss 0.00461049797013402\n",
      "\t\tRESULT EPOCH 27:\n",
      "\t\t\tTrain Loss: 0.003957399379994188 - Train Accuracy: 0.9305803571428571\n",
      "\t\t\tVal Loss: 0.01208532985765487 - Val Accuracy: 0.798\n",
      "\n",
      "\tSTARTING EPOCH 28 - LR=[2]...\n",
      "\t\tTrain step - Step 960, Loss 0.003864638740196824\n",
      "\t\tRESULT EPOCH 28:\n",
      "\t\t\tTrain Loss: 0.003858835848846606 - Train Accuracy: 0.9283482142857142\n",
      "\t\t\tVal Loss: 0.01659047231078148 - Val Accuracy: 0.708\n",
      "\n",
      "\tSTARTING EPOCH 29 - LR=[2]...\n",
      "\t\tTrain step - Step 990, Loss 0.0033089923672378063\n",
      "\t\tRESULT EPOCH 29:\n",
      "\t\t\tTrain Loss: 0.004349925036409071 - Train Accuracy: 0.9229910714285714\n",
      "\t\t\tVal Loss: 0.012092083226889372 - Val Accuracy: 0.776\n",
      "\n",
      "\tSTARTING EPOCH 30 - LR=[2]...\n",
      "\t\tTrain step - Step 1020, Loss 0.005668707191944122\n",
      "\t\tRESULT EPOCH 30:\n",
      "\t\t\tTrain Loss: 0.004416114517620632 - Train Accuracy: 0.9207589285714286\n",
      "\t\t\tVal Loss: 0.01439139386638999 - Val Accuracy: 0.752\n",
      "\n",
      "\tSTARTING EPOCH 31 - LR=[2]...\n",
      "\t\tTrain step - Step 1050, Loss 0.0037350147031247616\n",
      "\t\tTrain step - Step 1080, Loss 0.0031422751490026712\n",
      "\t\tRESULT EPOCH 31:\n",
      "\t\t\tTrain Loss: 0.003844280308112502 - Train Accuracy: 0.9330357142857143\n",
      "\t\t\tVal Loss: 0.012819629395380616 - Val Accuracy: 0.762\n",
      "\n",
      "\tSTARTING EPOCH 32 - LR=[2]...\n",
      "\t\tTrain step - Step 1110, Loss 0.005955317057669163\n",
      "\t\tRESULT EPOCH 32:\n",
      "\t\t\tTrain Loss: 0.0036010755359062127 - Train Accuracy: 0.9368303571428571\n",
      "\t\t\tVal Loss: 0.015600287355482578 - Val Accuracy: 0.734\n",
      "\n",
      "\tSTARTING EPOCH 33 - LR=[2]...\n",
      "\t\tTrain step - Step 1140, Loss 0.004606408998370171\n",
      "\t\tRESULT EPOCH 33:\n",
      "\t\t\tTrain Loss: 0.0036958675399156554 - Train Accuracy: 0.93125\n",
      "\t\t\tVal Loss: 0.014381390530616045 - Val Accuracy: 0.78\n",
      "\n",
      "\tSTARTING EPOCH 34 - LR=[2]...\n",
      "\t\tTrain step - Step 1170, Loss 0.002699296921491623\n",
      "\t\tRESULT EPOCH 34:\n",
      "\t\t\tTrain Loss: 0.004042703006416559 - Train Accuracy: 0.928125\n",
      "\t\t\tVal Loss: 0.013185348419938236 - Val Accuracy: 0.79\n",
      "\n",
      "\tSTARTING EPOCH 35 - LR=[2]...\n",
      "\t\tTrain step - Step 1200, Loss 0.0030924577731639147\n",
      "\t\tRESULT EPOCH 35:\n",
      "\t\t\tTrain Loss: 0.0035724776996565715 - Train Accuracy: 0.9368303571428571\n",
      "\t\t\tVal Loss: 0.015593080315738916 - Val Accuracy: 0.766\n",
      "\n",
      "\tSTARTING EPOCH 36 - LR=[2]...\n",
      "\t\tTrain step - Step 1230, Loss 0.0037296339869499207\n",
      "\t\tRESULT EPOCH 36:\n",
      "\t\t\tTrain Loss: 0.0035048746769981726 - Train Accuracy: 0.9316964285714285\n",
      "\t\t\tVal Loss: 0.013525532907806337 - Val Accuracy: 0.776\n",
      "\n",
      "\tSTARTING EPOCH 37 - LR=[2]...\n",
      "\t\tTrain step - Step 1260, Loss 0.001492775627411902\n",
      "\t\tTrain step - Step 1290, Loss 0.003015619469806552\n",
      "\t\tRESULT EPOCH 37:\n",
      "\t\t\tTrain Loss: 0.0029643205293853367 - Train Accuracy: 0.9479910714285714\n",
      "\t\t\tVal Loss: 0.012705809785984457 - Val Accuracy: 0.778\n",
      "\n",
      "\tSTARTING EPOCH 38 - LR=[2]...\n",
      "\t\tTrain step - Step 1320, Loss 0.0018411610508337617\n",
      "\t\tRESULT EPOCH 38:\n",
      "\t\t\tTrain Loss: 0.003056580407012786 - Train Accuracy: 0.9491071428571428\n",
      "\t\t\tVal Loss: 0.015007005305960774 - Val Accuracy: 0.778\n",
      "\n",
      "\tSTARTING EPOCH 39 - LR=[2]...\n",
      "\t\tTrain step - Step 1350, Loss 0.0036246587987989187\n",
      "\t\tRESULT EPOCH 39:\n",
      "\t\t\tTrain Loss: 0.003445775274719511 - Train Accuracy: 0.9372767857142857\n",
      "\t\t\tVal Loss: 0.011669791536405683 - Val Accuracy: 0.8\n",
      "\n",
      "\tSTARTING EPOCH 40 - LR=[2]...\n",
      "\t\tTrain step - Step 1380, Loss 0.0050116246566176414\n",
      "\t\tRESULT EPOCH 40:\n",
      "\t\t\tTrain Loss: 0.003181381503652249 - Train Accuracy: 0.9430803571428571\n",
      "\t\t\tVal Loss: 0.012756775598973036 - Val Accuracy: 0.778\n",
      "\n",
      "\tSTARTING EPOCH 41 - LR=[2]...\n",
      "\t\tTrain step - Step 1410, Loss 0.003949086181819439\n",
      "\t\tRESULT EPOCH 41:\n",
      "\t\t\tTrain Loss: 0.0031730771364111986 - Train Accuracy: 0.94375\n",
      "\t\t\tVal Loss: 0.0162794659845531 - Val Accuracy: 0.758\n",
      "\n",
      "\tSTARTING EPOCH 42 - LR=[2]...\n",
      "\t\tTrain step - Step 1440, Loss 0.0031623521354049444\n",
      "\t\tRESULT EPOCH 42:\n",
      "\t\t\tTrain Loss: 0.0030516258806788494 - Train Accuracy: 0.9455357142857143\n",
      "\t\t\tVal Loss: 0.016005474142730236 - Val Accuracy: 0.766\n",
      "\n",
      "\tSTARTING EPOCH 43 - LR=[2]...\n",
      "\t\tTrain step - Step 1470, Loss 0.005320234689861536\n",
      "\t\tTrain step - Step 1500, Loss 0.005279354751110077\n",
      "\t\tRESULT EPOCH 43:\n",
      "\t\t\tTrain Loss: 0.0036118468469274897 - Train Accuracy: 0.9316964285714285\n",
      "\t\t\tVal Loss: 0.012209725216962397 - Val Accuracy: 0.808\n",
      "\n",
      "\tSTARTING EPOCH 44 - LR=[2]...\n",
      "\t\tTrain step - Step 1530, Loss 0.0031586019322276115\n",
      "\t\tRESULT EPOCH 44:\n",
      "\t\t\tTrain Loss: 0.0030721169131408843 - Train Accuracy: 0.9506696428571428\n",
      "\t\t\tVal Loss: 0.013588311849161983 - Val Accuracy: 0.764\n",
      "\n",
      "\tSTARTING EPOCH 45 - LR=[2]...\n",
      "\t\tTrain step - Step 1560, Loss 0.0017958333482965827\n",
      "\t\tRESULT EPOCH 45:\n",
      "\t\t\tTrain Loss: 0.0028596666076087527 - Train Accuracy: 0.9522321428571429\n",
      "\t\t\tVal Loss: 0.014146459521725774 - Val Accuracy: 0.76\n",
      "\n",
      "\tSTARTING EPOCH 46 - LR=[2]...\n",
      "\t\tTrain step - Step 1590, Loss 0.002062475075945258\n",
      "\t\tRESULT EPOCH 46:\n",
      "\t\t\tTrain Loss: 0.002624011063016951 - Train Accuracy: 0.9549107142857143\n",
      "\t\t\tVal Loss: 0.011319668148644269 - Val Accuracy: 0.8\n",
      "\n",
      "\tSTARTING EPOCH 47 - LR=[2]...\n",
      "\t\tTrain step - Step 1620, Loss 0.0015312773175537586\n",
      "\t\tRESULT EPOCH 47:\n",
      "\t\t\tTrain Loss: 0.0021485890594444106 - Train Accuracy: 0.9671875\n",
      "\t\t\tVal Loss: 0.01609606167767197 - Val Accuracy: 0.778\n",
      "\n",
      "\tSTARTING EPOCH 48 - LR=[2]...\n",
      "\t\tTrain step - Step 1650, Loss 0.0011407654965296388\n",
      "\t\tRESULT EPOCH 48:\n",
      "\t\t\tTrain Loss: 0.0024198097276634405 - Train Accuracy: 0.9591517857142857\n",
      "\t\t\tVal Loss: 0.013227065792307258 - Val Accuracy: 0.798\n",
      "\n",
      "\tSTARTING EPOCH 49 - LR=[2]...\n",
      "\t\tTrain step - Step 1680, Loss 0.0028167765121906996\n",
      "\t\tTrain step - Step 1710, Loss 0.003963686525821686\n",
      "\t\tRESULT EPOCH 49:\n",
      "\t\t\tTrain Loss: 0.00351817729949419 - Train Accuracy: 0.9379464285714286\n",
      "\t\t\tVal Loss: 0.0206816119607538 - Val Accuracy: 0.714\n",
      "\n",
      "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1740, Loss 0.0019251119811087847\n",
      "\t\tRESULT EPOCH 50:\n",
      "\t\t\tTrain Loss: 0.0022851428549204556 - Train Accuracy: 0.9616071428571429\n",
      "\t\t\tVal Loss: 0.00926829205127433 - Val Accuracy: 0.852\n",
      "\n",
      "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1770, Loss 0.0005995638784952462\n",
      "\t\tRESULT EPOCH 51:\n",
      "\t\t\tTrain Loss: 0.0012566808112231748 - Train Accuracy: 0.9839285714285714\n",
      "\t\t\tVal Loss: 0.008729455061256886 - Val Accuracy: 0.848\n",
      "\n",
      "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1800, Loss 0.001318119466304779\n",
      "\t\tRESULT EPOCH 52:\n",
      "\t\t\tTrain Loss: 0.0009463430515357427 - Train Accuracy: 0.9883928571428572\n",
      "\t\t\tVal Loss: 0.009093053638935089 - Val Accuracy: 0.854\n",
      "\n",
      "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1830, Loss 0.0005235528224147856\n",
      "\t\tRESULT EPOCH 53:\n",
      "\t\t\tTrain Loss: 0.0008587098106675382 - Train Accuracy: 0.9901785714285715\n",
      "\t\t\tVal Loss: 0.009537491598166525 - Val Accuracy: 0.866\n",
      "\n",
      "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1860, Loss 0.0008960465784184635\n",
      "\t\tRESULT EPOCH 54:\n",
      "\t\t\tTrain Loss: 0.0007281284870779408 - Train Accuracy: 0.9941964285714285\n",
      "\t\t\tVal Loss: 0.00923768529901281 - Val Accuracy: 0.86\n",
      "\n",
      "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1890, Loss 0.0004165954305790365\n",
      "\t\tTrain step - Step 1920, Loss 0.0007666325545869768\n",
      "\t\tRESULT EPOCH 55:\n",
      "\t\t\tTrain Loss: 0.0006535556857540671 - Train Accuracy: 0.99375\n",
      "\t\t\tVal Loss: 0.009906317747663707 - Val Accuracy: 0.842\n",
      "\n",
      "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1950, Loss 0.00035366282099857926\n",
      "\t\tRESULT EPOCH 56:\n",
      "\t\t\tTrain Loss: 0.0006401938926761172 - Train Accuracy: 0.9953125\n",
      "\t\t\tVal Loss: 0.008923887799028307 - Val Accuracy: 0.862\n",
      "\n",
      "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1980, Loss 0.0003036918642465025\n",
      "\t\tRESULT EPOCH 57:\n",
      "\t\t\tTrain Loss: 0.0005720506289175578 - Train Accuracy: 0.9970982142857143\n",
      "\t\t\tVal Loss: 0.009841550840064883 - Val Accuracy: 0.846\n",
      "\n",
      "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2010, Loss 0.00047386757796630263\n",
      "\t\tRESULT EPOCH 58:\n",
      "\t\t\tTrain Loss: 0.0005440279891315316 - Train Accuracy: 0.9950892857142857\n",
      "\t\t\tVal Loss: 0.008871080994140357 - Val Accuracy: 0.858\n",
      "\n",
      "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2040, Loss 0.0008315290906466544\n",
      "\t\tRESULT EPOCH 59:\n",
      "\t\t\tTrain Loss: 0.0004933108883311174 - Train Accuracy: 0.9959821428571428\n",
      "\t\t\tVal Loss: 0.009618332493118942 - Val Accuracy: 0.868\n",
      "\n",
      "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2070, Loss 0.0002497460227459669\n",
      "\t\tRESULT EPOCH 60:\n",
      "\t\t\tTrain Loss: 0.00044720405837454433 - Train Accuracy: 0.9979910714285715\n",
      "\t\t\tVal Loss: 0.008767748950049281 - Val Accuracy: 0.856\n",
      "\n",
      "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2100, Loss 0.0004354384436737746\n",
      "\t\tTrain step - Step 2130, Loss 0.0005134009988978505\n",
      "\t\tRESULT EPOCH 61:\n",
      "\t\t\tTrain Loss: 0.0005169300383256216 - Train Accuracy: 0.9950892857142857\n",
      "\t\t\tVal Loss: 0.009144748211838305 - Val Accuracy: 0.854\n",
      "\n",
      "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2160, Loss 0.00025079853367060423\n",
      "\t\tRESULT EPOCH 62:\n",
      "\t\t\tTrain Loss: 0.0003847680545212435 - Train Accuracy: 0.9988839285714286\n",
      "\t\t\tVal Loss: 0.008725021732971072 - Val Accuracy: 0.866\n",
      "\n",
      "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2190, Loss 0.00018928460485767573\n",
      "\t\tRESULT EPOCH 63:\n",
      "\t\t\tTrain Loss: 0.0004408556635358504 - Train Accuracy: 0.9964285714285714\n",
      "\t\t\tVal Loss: 0.009213343961164355 - Val Accuracy: 0.852\n",
      "\n",
      "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2220, Loss 0.00020537263480946422\n",
      "\t\tRESULT EPOCH 64:\n",
      "\t\t\tTrain Loss: 0.0003886491496814415 - Train Accuracy: 0.9979910714285715\n",
      "\t\t\tVal Loss: 0.009683123498689383 - Val Accuracy: 0.846\n",
      "\n",
      "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2250, Loss 0.0005345399840734899\n",
      "\t\tRESULT EPOCH 65:\n",
      "\t\t\tTrain Loss: 0.000380067087826319 - Train Accuracy: 0.9975446428571428\n",
      "\t\t\tVal Loss: 0.00911991106113419 - Val Accuracy: 0.858\n",
      "\n",
      "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2280, Loss 0.0003047881764359772\n",
      "\t\tRESULT EPOCH 66:\n",
      "\t\t\tTrain Loss: 0.0003330171428387985 - Train Accuracy: 0.9979910714285715\n",
      "\t\t\tVal Loss: 0.009439867571927607 - Val Accuracy: 0.858\n",
      "\n",
      "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2310, Loss 0.00032020153594203293\n",
      "\t\tTrain step - Step 2340, Loss 0.0005072341882623732\n",
      "\t\tRESULT EPOCH 67:\n",
      "\t\t\tTrain Loss: 0.00039196213723958605 - Train Accuracy: 0.9977678571428571\n",
      "\t\t\tVal Loss: 0.009448075317777693 - Val Accuracy: 0.86\n",
      "\n",
      "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2370, Loss 0.00029851426370441914\n",
      "\t\tRESULT EPOCH 68:\n",
      "\t\t\tTrain Loss: 0.0003749900347819286 - Train Accuracy: 0.9979910714285715\n",
      "\t\t\tVal Loss: 0.009770092263352126 - Val Accuracy: 0.846\n",
      "\n",
      "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2400, Loss 0.0005284406361170113\n",
      "\t\tRESULT EPOCH 69:\n",
      "\t\t\tTrain Loss: 0.00035502601739218723 - Train Accuracy: 0.9986607142857142\n",
      "\t\t\tVal Loss: 0.00923390919342637 - Val Accuracy: 0.862\n",
      "\n",
      "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2430, Loss 0.00017313851276412606\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/32 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tRESULT EPOCH 70:\n",
      "\t\t\tTrain Loss: 0.00033905442396644505 - Train Accuracy: 0.9984375\n",
      "\t\t\tVal Loss: 0.010067650640849024 - Val Accuracy: 0.846\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:01<00:00, 27.32it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "\tResults STAGE 4:\n",
      "\t\tTrain Mean Accuracy: 0.9132589285714285\n",
      "\t\tVal Mean Accuracy: 0.7835999999999999\n",
      "\t\tTest Accuracy: 0.21625\n",
      "\n",
      "STARTING FINE TUNING STAGE 5...\n",
      "\tSTARTING EPOCH 1 - LR=[2]...\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tTrain step - Step 30, Loss 0.02981744520366192\n",
      "\t\tRESULT EPOCH 1:\n",
      "\t\t\tTrain Loss: 0.04697032773068973 - Train Accuracy: 0.21004464285714286\n",
      "\t\t\tVal Loss: 0.025912169832736254 - Val Accuracy: 0.404\n",
      "\n",
      "\tSTARTING EPOCH 2 - LR=[2]...\n",
      "\t\tTrain step - Step 60, Loss 0.017925309017300606\n",
      "\t\tRESULT EPOCH 2:\n",
      "\t\t\tTrain Loss: 0.021137095295957156 - Train Accuracy: 0.5477678571428571\n",
      "\t\t\tVal Loss: 0.018643865827471018 - Val Accuracy: 0.59\n",
      "\n",
      "\tSTARTING EPOCH 3 - LR=[2]...\n",
      "\t\tTrain step - Step 90, Loss 0.014519629068672657\n",
      "\t\tRESULT EPOCH 3:\n",
      "\t\t\tTrain Loss: 0.015960099627929075 - Train Accuracy: 0.6578125\n",
      "\t\t\tVal Loss: 0.015523319831117988 - Val Accuracy: 0.676\n",
      "\n",
      "\tSTARTING EPOCH 4 - LR=[2]...\n",
      "\t\tTrain step - Step 120, Loss 0.012859795242547989\n",
      "\t\tRESULT EPOCH 4:\n",
      "\t\t\tTrain Loss: 0.012672626280358859 - Train Accuracy: 0.7397321428571428\n",
      "\t\t\tVal Loss: 0.017004351364448667 - Val Accuracy: 0.64\n",
      "\n",
      "\tSTARTING EPOCH 5 - LR=[2]...\n",
      "\t\tTrain step - Step 150, Loss 0.012047229334712029\n",
      "\t\tRESULT EPOCH 5:\n",
      "\t\t\tTrain Loss: 0.011466805982802595 - Train Accuracy: 0.7611607142857143\n",
      "\t\t\tVal Loss: 0.015730155631899834 - Val Accuracy: 0.67\n",
      "\n",
      "\tSTARTING EPOCH 6 - LR=[2]...\n",
      "\t\tTrain step - Step 180, Loss 0.008760279044508934\n",
      "\t\tRESULT EPOCH 6:\n",
      "\t\t\tTrain Loss: 0.010255302382366998 - Train Accuracy: 0.8024553571428571\n",
      "\t\t\tVal Loss: 0.013989833183586597 - Val Accuracy: 0.73\n",
      "\n",
      "\tSTARTING EPOCH 7 - LR=[2]...\n",
      "\t\tTrain step - Step 210, Loss 0.009600467048585415\n",
      "\t\tTrain step - Step 240, Loss 0.011002912186086178\n",
      "\t\tRESULT EPOCH 7:\n",
      "\t\t\tTrain Loss: 0.009509277702974422 - Train Accuracy: 0.8129464285714286\n",
      "\t\t\tVal Loss: 0.014345623087137938 - Val Accuracy: 0.742\n",
      "\n",
      "\tSTARTING EPOCH 8 - LR=[2]...\n",
      "\t\tTrain step - Step 270, Loss 0.008614116348326206\n",
      "\t\tRESULT EPOCH 8:\n",
      "\t\t\tTrain Loss: 0.008606997744313309 - Train Accuracy: 0.8354910714285714\n",
      "\t\t\tVal Loss: 0.016410836717113853 - Val Accuracy: 0.692\n",
      "\n",
      "\tSTARTING EPOCH 9 - LR=[2]...\n",
      "\t\tTrain step - Step 300, Loss 0.0056655858643352985\n",
      "\t\tRESULT EPOCH 9:\n",
      "\t\t\tTrain Loss: 0.008153662045619318 - Train Accuracy: 0.8424107142857142\n",
      "\t\t\tVal Loss: 0.013312131515704095 - Val Accuracy: 0.756\n",
      "\n",
      "\tSTARTING EPOCH 10 - LR=[2]...\n",
      "\t\tTrain step - Step 330, Loss 0.008739053271710873\n",
      "\t\tRESULT EPOCH 10:\n",
      "\t\t\tTrain Loss: 0.0071481054914849145 - Train Accuracy: 0.8678571428571429\n",
      "\t\t\tVal Loss: 0.01251120725646615 - Val Accuracy: 0.766\n",
      "\n",
      "\tSTARTING EPOCH 11 - LR=[2]...\n",
      "\t\tTrain step - Step 360, Loss 0.006907476577907801\n",
      "\t\tRESULT EPOCH 11:\n",
      "\t\t\tTrain Loss: 0.007046797299491508 - Train Accuracy: 0.8665178571428571\n",
      "\t\t\tVal Loss: 0.01842017937451601 - Val Accuracy: 0.654\n",
      "\n",
      "\tSTARTING EPOCH 12 - LR=[2]...\n",
      "\t\tTrain step - Step 390, Loss 0.008195092901587486\n",
      "\t\tRESULT EPOCH 12:\n",
      "\t\t\tTrain Loss: 0.006585517951420376 - Train Accuracy: 0.8792410714285714\n",
      "\t\t\tVal Loss: 0.012360740918666124 - Val Accuracy: 0.788\n",
      "\n",
      "\tSTARTING EPOCH 13 - LR=[2]...\n",
      "\t\tTrain step - Step 420, Loss 0.007087539415806532\n",
      "\t\tTrain step - Step 450, Loss 0.006993731018155813\n",
      "\t\tRESULT EPOCH 13:\n",
      "\t\t\tTrain Loss: 0.0062818668516618865 - Train Accuracy: 0.8828125\n",
      "\t\t\tVal Loss: 0.015637593809515238 - Val Accuracy: 0.704\n",
      "\n",
      "\tSTARTING EPOCH 14 - LR=[2]...\n",
      "\t\tTrain step - Step 480, Loss 0.00429227389395237\n",
      "\t\tRESULT EPOCH 14:\n",
      "\t\t\tTrain Loss: 0.006561935134232044 - Train Accuracy: 0.8767857142857143\n",
      "\t\t\tVal Loss: 0.013813614146783948 - Val Accuracy: 0.762\n",
      "\n",
      "\tSTARTING EPOCH 15 - LR=[2]...\n",
      "\t\tTrain step - Step 510, Loss 0.008241654373705387\n",
      "\t\tRESULT EPOCH 15:\n",
      "\t\t\tTrain Loss: 0.005564597362120237 - Train Accuracy: 0.896875\n",
      "\t\t\tVal Loss: 0.01891070487909019 - Val Accuracy: 0.69\n",
      "\n",
      "\tSTARTING EPOCH 16 - LR=[2]...\n",
      "\t\tTrain step - Step 540, Loss 0.007378594484180212\n",
      "\t\tRESULT EPOCH 16:\n",
      "\t\t\tTrain Loss: 0.005587530934384891 - Train Accuracy: 0.9013392857142857\n",
      "\t\t\tVal Loss: 0.013531932840123773 - Val Accuracy: 0.756\n",
      "\n",
      "\tSTARTING EPOCH 17 - LR=[2]...\n",
      "\t\tTrain step - Step 570, Loss 0.004973625298589468\n",
      "\t\tRESULT EPOCH 17:\n",
      "\t\t\tTrain Loss: 0.005166916017021452 - Train Accuracy: 0.9084821428571429\n",
      "\t\t\tVal Loss: 0.010336901468690485 - Val Accuracy: 0.796\n",
      "\n",
      "\tSTARTING EPOCH 18 - LR=[2]...\n",
      "\t\tTrain step - Step 600, Loss 0.005530283786356449\n",
      "\t\tRESULT EPOCH 18:\n",
      "\t\t\tTrain Loss: 0.005086203664541244 - Train Accuracy: 0.9060267857142857\n",
      "\t\t\tVal Loss: 0.01142467325553298 - Val Accuracy: 0.83\n",
      "\n",
      "\tSTARTING EPOCH 19 - LR=[2]...\n",
      "\t\tTrain step - Step 630, Loss 0.006229296792298555\n",
      "\t\tTrain step - Step 660, Loss 0.004369806963950396\n",
      "\t\tRESULT EPOCH 19:\n",
      "\t\t\tTrain Loss: 0.004827454965561628 - Train Accuracy: 0.9151785714285714\n",
      "\t\t\tVal Loss: 0.018139475025236607 - Val Accuracy: 0.684\n",
      "\n",
      "\tSTARTING EPOCH 20 - LR=[2]...\n",
      "\t\tTrain step - Step 690, Loss 0.0039177704602479935\n",
      "\t\tRESULT EPOCH 20:\n",
      "\t\t\tTrain Loss: 0.004547576380095311 - Train Accuracy: 0.9247767857142857\n",
      "\t\t\tVal Loss: 0.012628018972463906 - Val Accuracy: 0.764\n",
      "\n",
      "\tSTARTING EPOCH 21 - LR=[2]...\n",
      "\t\tTrain step - Step 720, Loss 0.005473756231367588\n",
      "\t\tRESULT EPOCH 21:\n",
      "\t\t\tTrain Loss: 0.004728779822055783 - Train Accuracy: 0.9113839285714286\n",
      "\t\t\tVal Loss: 0.014238107251003385 - Val Accuracy: 0.764\n",
      "\n",
      "\tSTARTING EPOCH 22 - LR=[2]...\n",
      "\t\tTrain step - Step 750, Loss 0.007016374729573727\n",
      "\t\tRESULT EPOCH 22:\n",
      "\t\t\tTrain Loss: 0.005068506985636694 - Train Accuracy: 0.9100446428571428\n",
      "\t\t\tVal Loss: 0.010411291266791523 - Val Accuracy: 0.824\n",
      "\n",
      "\tSTARTING EPOCH 23 - LR=[2]...\n",
      "\t\tTrain step - Step 780, Loss 0.003184063360095024\n",
      "\t\tRESULT EPOCH 23:\n",
      "\t\t\tTrain Loss: 0.004232691620875682 - Train Accuracy: 0.9254464285714286\n",
      "\t\t\tVal Loss: 0.012068104115314782 - Val Accuracy: 0.81\n",
      "\n",
      "\tSTARTING EPOCH 24 - LR=[2]...\n",
      "\t\tTrain step - Step 810, Loss 0.0035432176664471626\n",
      "\t\tRESULT EPOCH 24:\n",
      "\t\t\tTrain Loss: 0.004002255527302623 - Train Accuracy: 0.9299107142857143\n",
      "\t\t\tVal Loss: 0.015154977794736624 - Val Accuracy: 0.752\n",
      "\n",
      "\tSTARTING EPOCH 25 - LR=[2]...\n",
      "\t\tTrain step - Step 840, Loss 0.0042395154014229774\n",
      "\t\tTrain step - Step 870, Loss 0.005166142247617245\n",
      "\t\tRESULT EPOCH 25:\n",
      "\t\t\tTrain Loss: 0.0039317856010581765 - Train Accuracy: 0.9308035714285714\n",
      "\t\t\tVal Loss: 0.014032179722562432 - Val Accuracy: 0.786\n",
      "\n",
      "\tSTARTING EPOCH 26 - LR=[2]...\n",
      "\t\tTrain step - Step 900, Loss 0.0034003739710897207\n",
      "\t\tRESULT EPOCH 26:\n",
      "\t\t\tTrain Loss: 0.003482575195708445 - Train Accuracy: 0.9390625\n",
      "\t\t\tVal Loss: 0.013632738962769508 - Val Accuracy: 0.762\n",
      "\n",
      "\tSTARTING EPOCH 27 - LR=[2]...\n",
      "\t\tTrain step - Step 930, Loss 0.005689967889338732\n",
      "\t\tRESULT EPOCH 27:\n",
      "\t\t\tTrain Loss: 0.004340273594217641 - Train Accuracy: 0.9238839285714285\n",
      "\t\t\tVal Loss: 0.01974390004761517 - Val Accuracy: 0.678\n",
      "\n",
      "\tSTARTING EPOCH 28 - LR=[2]...\n",
      "\t\tTrain step - Step 960, Loss 0.0022338617127388716\n",
      "\t\tRESULT EPOCH 28:\n",
      "\t\t\tTrain Loss: 0.0041283575751419575 - Train Accuracy: 0.9299107142857143\n",
      "\t\t\tVal Loss: 0.010260096518322825 - Val Accuracy: 0.828\n",
      "\n",
      "\tSTARTING EPOCH 29 - LR=[2]...\n",
      "\t\tTrain step - Step 990, Loss 0.0027216593734920025\n",
      "\t\tRESULT EPOCH 29:\n",
      "\t\t\tTrain Loss: 0.003532442101277411 - Train Accuracy: 0.9377232142857143\n",
      "\t\t\tVal Loss: 0.014935120125301182 - Val Accuracy: 0.752\n",
      "\n",
      "\tSTARTING EPOCH 30 - LR=[2]...\n",
      "\t\tTrain step - Step 1020, Loss 0.0024212582502514124\n",
      "\t\tRESULT EPOCH 30:\n",
      "\t\t\tTrain Loss: 0.003496572598149734 - Train Accuracy: 0.9399553571428572\n",
      "\t\t\tVal Loss: 0.011742066242732108 - Val Accuracy: 0.804\n",
      "\n",
      "\tSTARTING EPOCH 31 - LR=[2]...\n",
      "\t\tTrain step - Step 1050, Loss 0.004013784229755402\n",
      "\t\tTrain step - Step 1080, Loss 0.004417843651026487\n",
      "\t\tRESULT EPOCH 31:\n",
      "\t\t\tTrain Loss: 0.0031734247891498464 - Train Accuracy: 0.9426339285714286\n",
      "\t\t\tVal Loss: 0.011987581849098206 - Val Accuracy: 0.804\n",
      "\n",
      "\tSTARTING EPOCH 32 - LR=[2]...\n",
      "\t\tTrain step - Step 1110, Loss 0.0023725968785583973\n",
      "\t\tRESULT EPOCH 32:\n",
      "\t\t\tTrain Loss: 0.0030816992744803428 - Train Accuracy: 0.9466517857142858\n",
      "\t\t\tVal Loss: 0.01592013140907511 - Val Accuracy: 0.756\n",
      "\n",
      "\tSTARTING EPOCH 33 - LR=[2]...\n",
      "\t\tTrain step - Step 1140, Loss 0.0037673627957701683\n",
      "\t\tRESULT EPOCH 33:\n",
      "\t\t\tTrain Loss: 0.002876534000305193 - Train Accuracy: 0.9488839285714286\n",
      "\t\t\tVal Loss: 0.012836672365665436 - Val Accuracy: 0.806\n",
      "\n",
      "\tSTARTING EPOCH 34 - LR=[2]...\n",
      "\t\tTrain step - Step 1170, Loss 0.003534490941092372\n",
      "\t\tRESULT EPOCH 34:\n",
      "\t\t\tTrain Loss: 0.003357278123231871 - Train Accuracy: 0.9419642857142857\n",
      "\t\t\tVal Loss: 0.014716608915477991 - Val Accuracy: 0.754\n",
      "\n",
      "\tSTARTING EPOCH 35 - LR=[2]...\n",
      "\t\tTrain step - Step 1200, Loss 0.003990757279098034\n",
      "\t\tRESULT EPOCH 35:\n",
      "\t\t\tTrain Loss: 0.00325435561660145 - Train Accuracy: 0.9453125\n",
      "\t\t\tVal Loss: 0.016484692227095366 - Val Accuracy: 0.738\n",
      "\n",
      "\tSTARTING EPOCH 36 - LR=[2]...\n",
      "\t\tTrain step - Step 1230, Loss 0.003071094397455454\n",
      "\t\tRESULT EPOCH 36:\n",
      "\t\t\tTrain Loss: 0.0029345152001561863 - Train Accuracy: 0.9511160714285715\n",
      "\t\t\tVal Loss: 0.010036886669695377 - Val Accuracy: 0.832\n",
      "\n",
      "\tSTARTING EPOCH 37 - LR=[2]...\n",
      "\t\tTrain step - Step 1260, Loss 0.00210920930840075\n",
      "\t\tTrain step - Step 1290, Loss 0.003050156170502305\n",
      "\t\tRESULT EPOCH 37:\n",
      "\t\t\tTrain Loss: 0.0030690966972282954 - Train Accuracy: 0.9441964285714286\n",
      "\t\t\tVal Loss: 0.018776580458506942 - Val Accuracy: 0.708\n",
      "\n",
      "\tSTARTING EPOCH 38 - LR=[2]...\n",
      "\t\tTrain step - Step 1320, Loss 0.0038213469088077545\n",
      "\t\tRESULT EPOCH 38:\n",
      "\t\t\tTrain Loss: 0.0027751431900209615 - Train Accuracy: 0.9522321428571429\n",
      "\t\t\tVal Loss: 0.009605816681869328 - Val Accuracy: 0.838\n",
      "\n",
      "\tSTARTING EPOCH 39 - LR=[2]...\n",
      "\t\tTrain step - Step 1350, Loss 0.0047301435843110085\n",
      "\t\tRESULT EPOCH 39:\n",
      "\t\t\tTrain Loss: 0.0036253378493711352 - Train Accuracy: 0.9390625\n",
      "\t\t\tVal Loss: 0.016912913764826953 - Val Accuracy: 0.744\n",
      "\n",
      "\tSTARTING EPOCH 40 - LR=[2]...\n",
      "\t\tTrain step - Step 1380, Loss 0.0031668776646256447\n",
      "\t\tRESULT EPOCH 40:\n",
      "\t\t\tTrain Loss: 0.0027329730934330396 - Train Accuracy: 0.9573660714285714\n",
      "\t\t\tVal Loss: 0.010786800179630518 - Val Accuracy: 0.822\n",
      "\n",
      "\tSTARTING EPOCH 41 - LR=[2]...\n",
      "\t\tTrain step - Step 1410, Loss 0.0016124466201290488\n",
      "\t\tRESULT EPOCH 41:\n",
      "\t\t\tTrain Loss: 0.0024775207342047777 - Train Accuracy: 0.9578125\n",
      "\t\t\tVal Loss: 0.011916008312255144 - Val Accuracy: 0.816\n",
      "\n",
      "\tSTARTING EPOCH 42 - LR=[2]...\n",
      "\t\tTrain step - Step 1440, Loss 0.0018979376181960106\n",
      "\t\tRESULT EPOCH 42:\n",
      "\t\t\tTrain Loss: 0.00253404237529529 - Train Accuracy: 0.9580357142857143\n",
      "\t\t\tVal Loss: 0.01226200838573277 - Val Accuracy: 0.79\n",
      "\n",
      "\tSTARTING EPOCH 43 - LR=[2]...\n",
      "\t\tTrain step - Step 1470, Loss 0.0019087661057710648\n",
      "\t\tTrain step - Step 1500, Loss 0.004412923473864794\n",
      "\t\tRESULT EPOCH 43:\n",
      "\t\t\tTrain Loss: 0.002910887839139572 - Train Accuracy: 0.9491071428571428\n",
      "\t\t\tVal Loss: 0.014408477582037449 - Val Accuracy: 0.792\n",
      "\n",
      "\tSTARTING EPOCH 44 - LR=[2]...\n",
      "\t\tTrain step - Step 1530, Loss 0.002355497097596526\n",
      "\t\tRESULT EPOCH 44:\n",
      "\t\t\tTrain Loss: 0.002643506691258933 - Train Accuracy: 0.9515625\n",
      "\t\t\tVal Loss: 0.015811047749593854 - Val Accuracy: 0.772\n",
      "\n",
      "\tSTARTING EPOCH 45 - LR=[2]...\n",
      "\t\tTrain step - Step 1560, Loss 0.0031502710189670324\n",
      "\t\tRESULT EPOCH 45:\n",
      "\t\t\tTrain Loss: 0.0024089504316050026 - Train Accuracy: 0.9602678571428571\n",
      "\t\t\tVal Loss: 0.015453946776688099 - Val Accuracy: 0.776\n",
      "\n",
      "\tSTARTING EPOCH 46 - LR=[2]...\n",
      "\t\tTrain step - Step 1590, Loss 0.003464994952082634\n",
      "\t\tRESULT EPOCH 46:\n",
      "\t\t\tTrain Loss: 0.002608648714210306 - Train Accuracy: 0.9524553571428571\n",
      "\t\t\tVal Loss: 0.011353417474310845 - Val Accuracy: 0.82\n",
      "\n",
      "\tSTARTING EPOCH 47 - LR=[2]...\n",
      "\t\tTrain step - Step 1620, Loss 0.0019589303992688656\n",
      "\t\tRESULT EPOCH 47:\n",
      "\t\t\tTrain Loss: 0.002280327142216265 - Train Accuracy: 0.9636160714285714\n",
      "\t\t\tVal Loss: 0.009400564711540937 - Val Accuracy: 0.826\n",
      "\n",
      "\tSTARTING EPOCH 48 - LR=[2]...\n",
      "\t\tTrain step - Step 1650, Loss 0.00283030210994184\n",
      "\t\tRESULT EPOCH 48:\n",
      "\t\t\tTrain Loss: 0.0023339854470188063 - Train Accuracy: 0.9604910714285714\n",
      "\t\t\tVal Loss: 0.012457042234018445 - Val Accuracy: 0.808\n",
      "\n",
      "\tSTARTING EPOCH 49 - LR=[2]...\n",
      "\t\tTrain step - Step 1680, Loss 0.0020856535993516445\n",
      "\t\tTrain step - Step 1710, Loss 0.0014232968678697944\n",
      "\t\tRESULT EPOCH 49:\n",
      "\t\t\tTrain Loss: 0.001897428188073848 - Train Accuracy: 0.9671875\n",
      "\t\t\tVal Loss: 0.014182952232658863 - Val Accuracy: 0.798\n",
      "\n",
      "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1740, Loss 0.0008865100098773837\n",
      "\t\tRESULT EPOCH 50:\n",
      "\t\t\tTrain Loss: 0.001386861376730459 - Train Accuracy: 0.9799107142857143\n",
      "\t\t\tVal Loss: 0.009084395482204854 - Val Accuracy: 0.854\n",
      "\n",
      "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1770, Loss 0.0005322630750015378\n",
      "\t\tRESULT EPOCH 51:\n",
      "\t\t\tTrain Loss: 0.0008219405276966947 - Train Accuracy: 0.9881696428571428\n",
      "\t\t\tVal Loss: 0.008009516721358523 - Val Accuracy: 0.86\n",
      "\n",
      "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1800, Loss 0.0005943787982687354\n",
      "\t\tRESULT EPOCH 52:\n",
      "\t\t\tTrain Loss: 0.0006318263127468527 - Train Accuracy: 0.9948660714285714\n",
      "\t\t\tVal Loss: 0.00858534243889153 - Val Accuracy: 0.87\n",
      "\n",
      "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1830, Loss 0.0004444807709660381\n",
      "\t\tRESULT EPOCH 53:\n",
      "\t\t\tTrain Loss: 0.0005983564395657075 - Train Accuracy: 0.9959821428571428\n",
      "\t\t\tVal Loss: 0.008206800150219351 - Val Accuracy: 0.876\n",
      "\n",
      "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1860, Loss 0.00033260061172768474\n",
      "\t\tRESULT EPOCH 54:\n",
      "\t\t\tTrain Loss: 0.0005116079775949142 - Train Accuracy: 0.9955357142857143\n",
      "\t\t\tVal Loss: 0.008365770161617547 - Val Accuracy: 0.876\n",
      "\n",
      "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1890, Loss 0.0004496837791521102\n",
      "\t\tTrain step - Step 1920, Loss 0.0004979503573849797\n",
      "\t\tRESULT EPOCH 55:\n",
      "\t\t\tTrain Loss: 0.00045508116433796075 - Train Accuracy: 0.9970982142857143\n",
      "\t\t\tVal Loss: 0.00779301775037311 - Val Accuracy: 0.874\n",
      "\n",
      "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1950, Loss 0.0007445734809152782\n",
      "\t\tRESULT EPOCH 56:\n",
      "\t\t\tTrain Loss: 0.0004665138794475102 - Train Accuracy: 0.9955357142857143\n",
      "\t\t\tVal Loss: 0.0077956984168849885 - Val Accuracy: 0.878\n",
      "\n",
      "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1980, Loss 0.0007350867963396013\n",
      "\t\tRESULT EPOCH 57:\n",
      "\t\t\tTrain Loss: 0.0004850265087692865 - Train Accuracy: 0.9941964285714285\n",
      "\t\t\tVal Loss: 0.007185569673310965 - Val Accuracy: 0.874\n",
      "\n",
      "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2010, Loss 0.000298469967674464\n",
      "\t\tRESULT EPOCH 58:\n",
      "\t\t\tTrain Loss: 0.00040898113677810343 - Train Accuracy: 0.9973214285714286\n",
      "\t\t\tVal Loss: 0.008747960964683443 - Val Accuracy: 0.856\n",
      "\n",
      "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2040, Loss 0.00036265183007344604\n",
      "\t\tRESULT EPOCH 59:\n",
      "\t\t\tTrain Loss: 0.0004322701200310673 - Train Accuracy: 0.9957589285714286\n",
      "\t\t\tVal Loss: 0.007646673184353858 - Val Accuracy: 0.874\n",
      "\n",
      "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2070, Loss 0.00028460953035391867\n",
      "\t\tRESULT EPOCH 60:\n",
      "\t\t\tTrain Loss: 0.00039569239306729286 - Train Accuracy: 0.9970982142857143\n",
      "\t\t\tVal Loss: 0.008015556551981717 - Val Accuracy: 0.882\n",
      "\n",
      "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2100, Loss 0.00038768150261603296\n",
      "\t\tTrain step - Step 2130, Loss 0.00024620298063382506\n",
      "\t\tRESULT EPOCH 61:\n",
      "\t\t\tTrain Loss: 0.00033291322636484565 - Train Accuracy: 0.9982142857142857\n",
      "\t\t\tVal Loss: 0.00838710879907012 - Val Accuracy: 0.878\n",
      "\n",
      "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2160, Loss 0.0004796908760908991\n",
      "\t\tRESULT EPOCH 62:\n",
      "\t\t\tTrain Loss: 0.0003769377620691167 - Train Accuracy: 0.9970982142857143\n",
      "\t\t\tVal Loss: 0.009900616481900215 - Val Accuracy: 0.856\n",
      "\n",
      "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2190, Loss 0.00018953897233586758\n",
      "\t\tRESULT EPOCH 63:\n",
      "\t\t\tTrain Loss: 0.0003245357020724831 - Train Accuracy: 0.9984375\n",
      "\t\t\tVal Loss: 0.009121091366978362 - Val Accuracy: 0.866\n",
      "\n",
      "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2220, Loss 0.00027147564105689526\n",
      "\t\tRESULT EPOCH 64:\n",
      "\t\t\tTrain Loss: 0.0003026208420383877 - Train Accuracy: 0.9991071428571429\n",
      "\t\t\tVal Loss: 0.00873265482368879 - Val Accuracy: 0.882\n",
      "\n",
      "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2250, Loss 0.00031276338268071413\n",
      "\t\tRESULT EPOCH 65:\n",
      "\t\t\tTrain Loss: 0.0002902788259754223 - Train Accuracy: 0.9991071428571429\n",
      "\t\t\tVal Loss: 0.009038993914145976 - Val Accuracy: 0.866\n",
      "\n",
      "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2280, Loss 0.0001905585959320888\n",
      "\t\tRESULT EPOCH 66:\n",
      "\t\t\tTrain Loss: 0.0003199343270223056 - Train Accuracy: 0.9982142857142857\n",
      "\t\t\tVal Loss: 0.008205898338928819 - Val Accuracy: 0.874\n",
      "\n",
      "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2310, Loss 0.00028714374639093876\n",
      "\t\tTrain step - Step 2340, Loss 0.00018806256412062794\n",
      "\t\tRESULT EPOCH 67:\n",
      "\t\t\tTrain Loss: 0.000268721826224854 - Train Accuracy: 0.9988839285714286\n",
      "\t\t\tVal Loss: 0.008768393367063254 - Val Accuracy: 0.88\n",
      "\n",
      "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2370, Loss 0.0005305998492985964\n",
      "\t\tRESULT EPOCH 68:\n",
      "\t\t\tTrain Loss: 0.0002945952071708494 - Train Accuracy: 0.9984375\n",
      "\t\t\tVal Loss: 0.009449457109440118 - Val Accuracy: 0.864\n",
      "\n",
      "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2400, Loss 0.0001881038333522156\n",
      "\t\tRESULT EPOCH 69:\n",
      "\t\t\tTrain Loss: 0.000285943821238886 - Train Accuracy: 0.9982142857142857\n",
      "\t\t\tVal Loss: 0.008201077609555796 - Val Accuracy: 0.876\n",
      "\n",
      "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2430, Loss 0.00020197356934659183\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/40 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tRESULT EPOCH 70:\n",
      "\t\t\tTrain Loss: 0.00027230709300576044 - Train Accuracy: 0.9984375\n",
      "\t\t\tVal Loss: 0.009330690634669736 - Val Accuracy: 0.87\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 28.52it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "\tResults STAGE 5:\n",
      "\t\tTrain Mean Accuracy: 0.9188488520408163\n",
      "\t\tVal Mean Accuracy: 0.7877142857142856\n",
      "\t\tTest Accuracy: 0.1746\n",
      "\n",
      "STARTING FINE TUNING STAGE 6...\n",
      "\tSTARTING EPOCH 1 - LR=[2]...\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tTrain step - Step 30, Loss 0.025996891781687737\n",
      "\t\tRESULT EPOCH 1:\n",
      "\t\t\tTrain Loss: 0.045676527810948234 - Train Accuracy: 0.25825892857142857\n",
      "\t\t\tVal Loss: 0.025815668515861034 - Val Accuracy: 0.412\n",
      "\n",
      "\tSTARTING EPOCH 2 - LR=[2]...\n",
      "\t\tTrain step - Step 60, Loss 0.017783066257834435\n",
      "\t\tRESULT EPOCH 2:\n",
      "\t\t\tTrain Loss: 0.020889225229620934 - Train Accuracy: 0.5511160714285714\n",
      "\t\t\tVal Loss: 0.01924539916217327 - Val Accuracy: 0.606\n",
      "\n",
      "\tSTARTING EPOCH 3 - LR=[2]...\n",
      "\t\tTrain step - Step 90, Loss 0.012577082961797714\n",
      "\t\tRESULT EPOCH 3:\n",
      "\t\t\tTrain Loss: 0.01561132488506181 - Train Accuracy: 0.6848214285714286\n",
      "\t\t\tVal Loss: 0.016609614482149482 - Val Accuracy: 0.652\n",
      "\n",
      "\tSTARTING EPOCH 4 - LR=[2]...\n",
      "\t\tTrain step - Step 120, Loss 0.01410472858697176\n",
      "\t\tRESULT EPOCH 4:\n",
      "\t\t\tTrain Loss: 0.012981769149856909 - Train Accuracy: 0.7542410714285714\n",
      "\t\t\tVal Loss: 0.01418772665783763 - Val Accuracy: 0.73\n",
      "\n",
      "\tSTARTING EPOCH 5 - LR=[2]...\n",
      "\t\tTrain step - Step 150, Loss 0.011292432434856892\n",
      "\t\tRESULT EPOCH 5:\n",
      "\t\t\tTrain Loss: 0.011030613843883787 - Train Accuracy: 0.7910714285714285\n",
      "\t\t\tVal Loss: 0.014691587770357728 - Val Accuracy: 0.718\n",
      "\n",
      "\tSTARTING EPOCH 6 - LR=[2]...\n",
      "\t\tTrain step - Step 180, Loss 0.008882207795977592\n",
      "\t\tRESULT EPOCH 6:\n",
      "\t\t\tTrain Loss: 0.010102952870407274 - Train Accuracy: 0.8107142857142857\n",
      "\t\t\tVal Loss: 0.013932042056694627 - Val Accuracy: 0.706\n",
      "\n",
      "\tSTARTING EPOCH 7 - LR=[2]...\n",
      "\t\tTrain step - Step 210, Loss 0.00877290964126587\n",
      "\t\tTrain step - Step 240, Loss 0.009238031692802906\n",
      "\t\tRESULT EPOCH 7:\n",
      "\t\t\tTrain Loss: 0.00867132129413741 - Train Accuracy: 0.8410714285714286\n",
      "\t\t\tVal Loss: 0.011889783898368478 - Val Accuracy: 0.786\n",
      "\n",
      "\tSTARTING EPOCH 8 - LR=[2]...\n",
      "\t\tTrain step - Step 270, Loss 0.008319479413330555\n",
      "\t\tRESULT EPOCH 8:\n",
      "\t\t\tTrain Loss: 0.00805471135037286 - Train Accuracy: 0.8508928571428571\n",
      "\t\t\tVal Loss: 0.012949661584571004 - Val Accuracy: 0.746\n",
      "\n",
      "\tSTARTING EPOCH 9 - LR=[2]...\n",
      "\t\tTrain step - Step 300, Loss 0.007052145432680845\n",
      "\t\tRESULT EPOCH 9:\n",
      "\t\t\tTrain Loss: 0.007460988273045846 - Train Accuracy: 0.8638392857142857\n",
      "\t\t\tVal Loss: 0.013415248598903418 - Val Accuracy: 0.76\n",
      "\n",
      "\tSTARTING EPOCH 10 - LR=[2]...\n",
      "\t\tTrain step - Step 330, Loss 0.007489826530218124\n",
      "\t\tRESULT EPOCH 10:\n",
      "\t\t\tTrain Loss: 0.007393854337611369 - Train Accuracy: 0.8604910714285714\n",
      "\t\t\tVal Loss: 0.010895441053435206 - Val Accuracy: 0.82\n",
      "\n",
      "\tSTARTING EPOCH 11 - LR=[2]...\n",
      "\t\tTrain step - Step 360, Loss 0.005010833498090506\n",
      "\t\tRESULT EPOCH 11:\n",
      "\t\t\tTrain Loss: 0.006698372720607689 - Train Accuracy: 0.8772321428571429\n",
      "\t\t\tVal Loss: 0.013269447023048997 - Val Accuracy: 0.77\n",
      "\n",
      "\tSTARTING EPOCH 12 - LR=[2]...\n",
      "\t\tTrain step - Step 390, Loss 0.0059456657618284225\n",
      "\t\tRESULT EPOCH 12:\n",
      "\t\t\tTrain Loss: 0.006500860968870776 - Train Accuracy: 0.8810267857142857\n",
      "\t\t\tVal Loss: 0.01198095188010484 - Val Accuracy: 0.794\n",
      "\n",
      "\tSTARTING EPOCH 13 - LR=[2]...\n",
      "\t\tTrain step - Step 420, Loss 0.0064064497128129005\n",
      "\t\tTrain step - Step 450, Loss 0.007469159085303545\n",
      "\t\tRESULT EPOCH 13:\n",
      "\t\t\tTrain Loss: 0.006100994987147195 - Train Accuracy: 0.8933035714285714\n",
      "\t\t\tVal Loss: 0.012600592104718089 - Val Accuracy: 0.756\n",
      "\n",
      "\tSTARTING EPOCH 14 - LR=[2]...\n",
      "\t\tTrain step - Step 480, Loss 0.00475451210513711\n",
      "\t\tRESULT EPOCH 14:\n",
      "\t\t\tTrain Loss: 0.005748441283191953 - Train Accuracy: 0.8928571428571429\n",
      "\t\t\tVal Loss: 0.012509135820437223 - Val Accuracy: 0.764\n",
      "\n",
      "\tSTARTING EPOCH 15 - LR=[2]...\n",
      "\t\tTrain step - Step 510, Loss 0.005095642525702715\n",
      "\t\tRESULT EPOCH 15:\n",
      "\t\t\tTrain Loss: 0.00570742499881557 - Train Accuracy: 0.8973214285714286\n",
      "\t\t\tVal Loss: 0.028943945188075304 - Val Accuracy: 0.586\n",
      "\n",
      "\tSTARTING EPOCH 16 - LR=[2]...\n",
      "\t\tTrain step - Step 540, Loss 0.0060146343894302845\n",
      "\t\tRESULT EPOCH 16:\n",
      "\t\t\tTrain Loss: 0.005211123538070492 - Train Accuracy: 0.9040178571428571\n",
      "\t\t\tVal Loss: 0.010212578577920794 - Val Accuracy: 0.806\n",
      "\n",
      "\tSTARTING EPOCH 17 - LR=[2]...\n",
      "\t\tTrain step - Step 570, Loss 0.004819263704121113\n",
      "\t\tRESULT EPOCH 17:\n",
      "\t\t\tTrain Loss: 0.004814623449263828 - Train Accuracy: 0.9151785714285714\n",
      "\t\t\tVal Loss: 0.017333558527752757 - Val Accuracy: 0.75\n",
      "\n",
      "\tSTARTING EPOCH 18 - LR=[2]...\n",
      "\t\tTrain step - Step 600, Loss 0.0048727551475167274\n",
      "\t\tRESULT EPOCH 18:\n",
      "\t\t\tTrain Loss: 0.004364749030875308 - Train Accuracy: 0.9232142857142858\n",
      "\t\t\tVal Loss: 0.011744585586711764 - Val Accuracy: 0.798\n",
      "\n",
      "\tSTARTING EPOCH 19 - LR=[2]...\n",
      "\t\tTrain step - Step 630, Loss 0.005368558224290609\n",
      "\t\tTrain step - Step 660, Loss 0.004524793475866318\n",
      "\t\tRESULT EPOCH 19:\n",
      "\t\t\tTrain Loss: 0.004459316063938397 - Train Accuracy: 0.9200892857142857\n",
      "\t\t\tVal Loss: 0.015004326356574893 - Val Accuracy: 0.76\n",
      "\n",
      "\tSTARTING EPOCH 20 - LR=[2]...\n",
      "\t\tTrain step - Step 690, Loss 0.006868497468531132\n",
      "\t\tRESULT EPOCH 20:\n",
      "\t\t\tTrain Loss: 0.004288070043548942 - Train Accuracy: 0.9205357142857142\n",
      "\t\t\tVal Loss: 0.010758032090961933 - Val Accuracy: 0.826\n",
      "\n",
      "\tSTARTING EPOCH 21 - LR=[2]...\n",
      "\t\tTrain step - Step 720, Loss 0.004427048843353987\n",
      "\t\tRESULT EPOCH 21:\n",
      "\t\t\tTrain Loss: 0.004029178306726473 - Train Accuracy: 0.9308035714285714\n",
      "\t\t\tVal Loss: 0.013333925628103316 - Val Accuracy: 0.764\n",
      "\n",
      "\tSTARTING EPOCH 22 - LR=[2]...\n",
      "\t\tTrain step - Step 750, Loss 0.003984624519944191\n",
      "\t\tRESULT EPOCH 22:\n",
      "\t\t\tTrain Loss: 0.004052097643060344 - Train Accuracy: 0.9294642857142857\n",
      "\t\t\tVal Loss: 0.013147271005436778 - Val Accuracy: 0.78\n",
      "\n",
      "\tSTARTING EPOCH 23 - LR=[2]...\n",
      "\t\tTrain step - Step 780, Loss 0.003462218213826418\n",
      "\t\tRESULT EPOCH 23:\n",
      "\t\t\tTrain Loss: 0.003917810547032527 - Train Accuracy: 0.9341517857142857\n",
      "\t\t\tVal Loss: 0.012595221865922213 - Val Accuracy: 0.794\n",
      "\n",
      "\tSTARTING EPOCH 24 - LR=[2]...\n",
      "\t\tTrain step - Step 810, Loss 0.0021294315811246634\n",
      "\t\tRESULT EPOCH 24:\n",
      "\t\t\tTrain Loss: 0.0035525278920041665 - Train Accuracy: 0.940625\n",
      "\t\t\tVal Loss: 0.010398288839496672 - Val Accuracy: 0.816\n",
      "\n",
      "\tSTARTING EPOCH 25 - LR=[2]...\n",
      "\t\tTrain step - Step 840, Loss 0.0036040153354406357\n",
      "\t\tTrain step - Step 870, Loss 0.005277763586491346\n",
      "\t\tRESULT EPOCH 25:\n",
      "\t\t\tTrain Loss: 0.0038783351691173656 - Train Accuracy: 0.9283482142857142\n",
      "\t\t\tVal Loss: 0.011738398810848594 - Val Accuracy: 0.788\n",
      "\n",
      "\tSTARTING EPOCH 26 - LR=[2]...\n",
      "\t\tTrain step - Step 900, Loss 0.004127379972487688\n",
      "\t\tRESULT EPOCH 26:\n",
      "\t\t\tTrain Loss: 0.004385480690481407 - Train Accuracy: 0.9236607142857143\n",
      "\t\t\tVal Loss: 0.014756673481315374 - Val Accuracy: 0.752\n",
      "\n",
      "\tSTARTING EPOCH 27 - LR=[2]...\n",
      "\t\tTrain step - Step 930, Loss 0.003322501666843891\n",
      "\t\tRESULT EPOCH 27:\n",
      "\t\t\tTrain Loss: 0.003394051757641137 - Train Accuracy: 0.9426339285714286\n",
      "\t\t\tVal Loss: 0.012675132369622588 - Val Accuracy: 0.78\n",
      "\n",
      "\tSTARTING EPOCH 28 - LR=[2]...\n",
      "\t\tTrain step - Step 960, Loss 0.002714741276577115\n",
      "\t\tRESULT EPOCH 28:\n",
      "\t\t\tTrain Loss: 0.0033442396404487745 - Train Accuracy: 0.9410714285714286\n",
      "\t\t\tVal Loss: 0.009474181337282062 - Val Accuracy: 0.834\n",
      "\n",
      "\tSTARTING EPOCH 29 - LR=[2]...\n",
      "\t\tTrain step - Step 990, Loss 0.0030685984529554844\n",
      "\t\tRESULT EPOCH 29:\n",
      "\t\t\tTrain Loss: 0.003268189076334238 - Train Accuracy: 0.9415178571428572\n",
      "\t\t\tVal Loss: 0.011702380958013237 - Val Accuracy: 0.806\n",
      "\n",
      "\tSTARTING EPOCH 30 - LR=[2]...\n",
      "\t\tTrain step - Step 1020, Loss 0.0018553715199232101\n",
      "\t\tRESULT EPOCH 30:\n",
      "\t\t\tTrain Loss: 0.003711203173069017 - Train Accuracy: 0.9359375\n",
      "\t\t\tVal Loss: 0.010136023978702724 - Val Accuracy: 0.83\n",
      "\n",
      "\tSTARTING EPOCH 31 - LR=[2]...\n",
      "\t\tTrain step - Step 1050, Loss 0.0037396319676190615\n",
      "\t\tTrain step - Step 1080, Loss 0.0033124082256108522\n",
      "\t\tRESULT EPOCH 31:\n",
      "\t\t\tTrain Loss: 0.0035291081560509547 - Train Accuracy: 0.9412946428571428\n",
      "\t\t\tVal Loss: 0.018437884049490094 - Val Accuracy: 0.712\n",
      "\n",
      "\tSTARTING EPOCH 32 - LR=[2]...\n",
      "\t\tTrain step - Step 1110, Loss 0.004657777491956949\n",
      "\t\tRESULT EPOCH 32:\n",
      "\t\t\tTrain Loss: 0.0033633339152272256 - Train Accuracy: 0.9419642857142857\n",
      "\t\t\tVal Loss: 0.009845322114415467 - Val Accuracy: 0.832\n",
      "\n",
      "\tSTARTING EPOCH 33 - LR=[2]...\n",
      "\t\tTrain step - Step 1140, Loss 0.002608641516417265\n",
      "\t\tRESULT EPOCH 33:\n",
      "\t\t\tTrain Loss: 0.0029735017667657563 - Train Accuracy: 0.9517857142857142\n",
      "\t\t\tVal Loss: 0.010071313241496682 - Val Accuracy: 0.82\n",
      "\n",
      "\tSTARTING EPOCH 34 - LR=[2]...\n",
      "\t\tTrain step - Step 1170, Loss 0.0027845739386975765\n",
      "\t\tRESULT EPOCH 34:\n",
      "\t\t\tTrain Loss: 0.002860618745242911 - Train Accuracy: 0.9488839285714286\n",
      "\t\t\tVal Loss: 0.011324088904075325 - Val Accuracy: 0.814\n",
      "\n",
      "\tSTARTING EPOCH 35 - LR=[2]...\n",
      "\t\tTrain step - Step 1200, Loss 0.0017636915436014533\n",
      "\t\tRESULT EPOCH 35:\n",
      "\t\t\tTrain Loss: 0.0028185786878956215 - Train Accuracy: 0.9515625\n",
      "\t\t\tVal Loss: 0.013721178867854178 - Val Accuracy: 0.81\n",
      "\n",
      "\tSTARTING EPOCH 36 - LR=[2]...\n",
      "\t\tTrain step - Step 1230, Loss 0.0027801841497421265\n",
      "\t\tRESULT EPOCH 36:\n",
      "\t\t\tTrain Loss: 0.0025490624231419394 - Train Accuracy: 0.95625\n",
      "\t\t\tVal Loss: 0.013194936094805598 - Val Accuracy: 0.788\n",
      "\n",
      "\tSTARTING EPOCH 37 - LR=[2]...\n",
      "\t\tTrain step - Step 1260, Loss 0.0022402869071811438\n",
      "\t\tTrain step - Step 1290, Loss 0.0031536074820905924\n",
      "\t\tRESULT EPOCH 37:\n",
      "\t\t\tTrain Loss: 0.0024712837168148587 - Train Accuracy: 0.9560267857142857\n",
      "\t\t\tVal Loss: 0.011281108891125768 - Val Accuracy: 0.838\n",
      "\n",
      "\tSTARTING EPOCH 38 - LR=[2]...\n",
      "\t\tTrain step - Step 1320, Loss 0.005532880779355764\n",
      "\t\tRESULT EPOCH 38:\n",
      "\t\t\tTrain Loss: 0.0031516451787735734 - Train Accuracy: 0.9453125\n",
      "\t\t\tVal Loss: 0.009747568401508033 - Val Accuracy: 0.838\n",
      "\n",
      "\tSTARTING EPOCH 39 - LR=[2]...\n",
      "\t\tTrain step - Step 1350, Loss 0.005526862107217312\n",
      "\t\tRESULT EPOCH 39:\n",
      "\t\t\tTrain Loss: 0.002752552949823439 - Train Accuracy: 0.9524553571428571\n",
      "\t\t\tVal Loss: 0.010183983598835766 - Val Accuracy: 0.836\n",
      "\n",
      "\tSTARTING EPOCH 40 - LR=[2]...\n",
      "\t\tTrain step - Step 1380, Loss 0.0025666439905762672\n",
      "\t\tRESULT EPOCH 40:\n",
      "\t\t\tTrain Loss: 0.002919638013866331 - Train Accuracy: 0.9511160714285715\n",
      "\t\t\tVal Loss: 0.010661421809345484 - Val Accuracy: 0.814\n",
      "\n",
      "\tSTARTING EPOCH 41 - LR=[2]...\n",
      "\t\tTrain step - Step 1410, Loss 0.0028240871615707874\n",
      "\t\tRESULT EPOCH 41:\n",
      "\t\t\tTrain Loss: 0.0022669986356049776 - Train Accuracy: 0.9629464285714285\n",
      "\t\t\tVal Loss: 0.011958956369198859 - Val Accuracy: 0.834\n",
      "\n",
      "\tSTARTING EPOCH 42 - LR=[2]...\n",
      "\t\tTrain step - Step 1440, Loss 0.003955721855163574\n",
      "\t\tRESULT EPOCH 42:\n",
      "\t\t\tTrain Loss: 0.0023657431559903283 - Train Accuracy: 0.9591517857142857\n",
      "\t\t\tVal Loss: 0.015060418285429478 - Val Accuracy: 0.786\n",
      "\n",
      "\tSTARTING EPOCH 43 - LR=[2]...\n",
      "\t\tTrain step - Step 1470, Loss 0.0016857758164405823\n",
      "\t\tTrain step - Step 1500, Loss 0.0010781672317534685\n",
      "\t\tRESULT EPOCH 43:\n",
      "\t\t\tTrain Loss: 0.0021977155868496212 - Train Accuracy: 0.9638392857142857\n",
      "\t\t\tVal Loss: 0.009710510144941509 - Val Accuracy: 0.84\n",
      "\n",
      "\tSTARTING EPOCH 44 - LR=[2]...\n",
      "\t\tTrain step - Step 1530, Loss 0.0019364007748663425\n",
      "\t\tRESULT EPOCH 44:\n",
      "\t\t\tTrain Loss: 0.002136771271138319 - Train Accuracy: 0.9640625\n",
      "\t\t\tVal Loss: 0.009341856930404902 - Val Accuracy: 0.848\n",
      "\n",
      "\tSTARTING EPOCH 45 - LR=[2]...\n",
      "\t\tTrain step - Step 1560, Loss 0.0010403257329016924\n",
      "\t\tRESULT EPOCH 45:\n",
      "\t\t\tTrain Loss: 0.0021680042879389863 - Train Accuracy: 0.9631696428571429\n",
      "\t\t\tVal Loss: 0.01208639144897461 - Val Accuracy: 0.82\n",
      "\n",
      "\tSTARTING EPOCH 46 - LR=[2]...\n",
      "\t\tTrain step - Step 1590, Loss 0.0016087141120806336\n",
      "\t\tRESULT EPOCH 46:\n",
      "\t\t\tTrain Loss: 0.0021185205184987613 - Train Accuracy: 0.9629464285714285\n",
      "\t\t\tVal Loss: 0.013966191560029984 - Val Accuracy: 0.806\n",
      "\n",
      "\tSTARTING EPOCH 47 - LR=[2]...\n",
      "\t\tTrain step - Step 1620, Loss 0.0017192121595144272\n",
      "\t\tRESULT EPOCH 47:\n",
      "\t\t\tTrain Loss: 0.0023229507762672647 - Train Accuracy: 0.9633928571428572\n",
      "\t\t\tVal Loss: 0.01021455111913383 - Val Accuracy: 0.846\n",
      "\n",
      "\tSTARTING EPOCH 48 - LR=[2]...\n",
      "\t\tTrain step - Step 1650, Loss 0.0016118050552904606\n",
      "\t\tRESULT EPOCH 48:\n",
      "\t\t\tTrain Loss: 0.0025382537960207886 - Train Accuracy: 0.9571428571428572\n",
      "\t\t\tVal Loss: 0.021929578622803092 - Val Accuracy: 0.71\n",
      "\n",
      "\tSTARTING EPOCH 49 - LR=[2]...\n",
      "\t\tTrain step - Step 1680, Loss 0.002114728791639209\n",
      "\t\tTrain step - Step 1710, Loss 0.0018424579175189137\n",
      "\t\tRESULT EPOCH 49:\n",
      "\t\t\tTrain Loss: 0.002258630539290607 - Train Accuracy: 0.9616071428571429\n",
      "\t\t\tVal Loss: 0.009654481313191354 - Val Accuracy: 0.844\n",
      "\n",
      "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1740, Loss 0.0005653436528518796\n",
      "\t\tRESULT EPOCH 50:\n",
      "\t\t\tTrain Loss: 0.0012039728155027012 - Train Accuracy: 0.984375\n",
      "\t\t\tVal Loss: 0.008461789577268064 - Val Accuracy: 0.856\n",
      "\n",
      "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1770, Loss 0.0005705918883904815\n",
      "\t\tRESULT EPOCH 51:\n",
      "\t\t\tTrain Loss: 0.0007808427733834832 - Train Accuracy: 0.990625\n",
      "\t\t\tVal Loss: 0.007015379494987428 - Val Accuracy: 0.868\n",
      "\n",
      "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1800, Loss 0.00024980612215586007\n",
      "\t\tRESULT EPOCH 52:\n",
      "\t\t\tTrain Loss: 0.0005865455663297325 - Train Accuracy: 0.9955357142857143\n",
      "\t\t\tVal Loss: 0.007012164685875177 - Val Accuracy: 0.874\n",
      "\n",
      "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1830, Loss 0.00036886127782054245\n",
      "\t\tRESULT EPOCH 53:\n",
      "\t\t\tTrain Loss: 0.0005553923647052475 - Train Accuracy: 0.9953125\n",
      "\t\t\tVal Loss: 0.008150315727107227 - Val Accuracy: 0.882\n",
      "\n",
      "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1860, Loss 0.00040080584585666656\n",
      "\t\tRESULT EPOCH 54:\n",
      "\t\t\tTrain Loss: 0.00048120824503712357 - Train Accuracy: 0.9959821428571428\n",
      "\t\t\tVal Loss: 0.007625422324053943 - Val Accuracy: 0.878\n",
      "\n",
      "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1890, Loss 0.0003999328473582864\n",
      "\t\tTrain step - Step 1920, Loss 0.0012336948420852423\n",
      "\t\tRESULT EPOCH 55:\n",
      "\t\t\tTrain Loss: 0.0005931990815692448 - Train Accuracy: 0.9939732142857143\n",
      "\t\t\tVal Loss: 0.007077841088175774 - Val Accuracy: 0.89\n",
      "\n",
      "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1950, Loss 0.00039730838034301996\n",
      "\t\tRESULT EPOCH 56:\n",
      "\t\t\tTrain Loss: 0.00047419525341995593 - Train Accuracy: 0.9962053571428572\n",
      "\t\t\tVal Loss: 0.007854089373722672 - Val Accuracy: 0.872\n",
      "\n",
      "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1980, Loss 0.0005329348496161401\n",
      "\t\tRESULT EPOCH 57:\n",
      "\t\t\tTrain Loss: 0.0004627009475370869 - Train Accuracy: 0.9966517857142857\n",
      "\t\t\tVal Loss: 0.007903555524535477 - Val Accuracy: 0.868\n",
      "\n",
      "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2010, Loss 0.0010305442847311497\n",
      "\t\tRESULT EPOCH 58:\n",
      "\t\t\tTrain Loss: 0.0004350900304936139 - Train Accuracy: 0.9970982142857143\n",
      "\t\t\tVal Loss: 0.00722525967285037 - Val Accuracy: 0.872\n",
      "\n",
      "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2040, Loss 0.0006485589547082782\n",
      "\t\tRESULT EPOCH 59:\n",
      "\t\t\tTrain Loss: 0.00036707045551988163 - Train Accuracy: 0.9973214285714286\n",
      "\t\t\tVal Loss: 0.007233084412291646 - Val Accuracy: 0.88\n",
      "\n",
      "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2070, Loss 0.00021189029212109745\n",
      "\t\tRESULT EPOCH 60:\n",
      "\t\t\tTrain Loss: 0.00036890386088219074 - Train Accuracy: 0.9975446428571428\n",
      "\t\t\tVal Loss: 0.0073465086170472205 - Val Accuracy: 0.876\n",
      "\n",
      "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2100, Loss 0.00034513144055381417\n",
      "\t\tTrain step - Step 2130, Loss 0.00044662877917289734\n",
      "\t\tRESULT EPOCH 61:\n",
      "\t\t\tTrain Loss: 0.0003418984299059957 - Train Accuracy: 0.9975446428571428\n",
      "\t\t\tVal Loss: 0.007523380510974675 - Val Accuracy: 0.888\n",
      "\n",
      "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2160, Loss 0.00025480176554992795\n",
      "\t\tRESULT EPOCH 62:\n",
      "\t\t\tTrain Loss: 0.0003439191537576595 - Train Accuracy: 0.9975446428571428\n",
      "\t\t\tVal Loss: 0.007672613835893571 - Val Accuracy: 0.886\n",
      "\n",
      "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2190, Loss 0.00039021208067424595\n",
      "\t\tRESULT EPOCH 63:\n",
      "\t\t\tTrain Loss: 0.00037345202872529626 - Train Accuracy: 0.996875\n",
      "\t\t\tVal Loss: 0.00790195947047323 - Val Accuracy: 0.886\n",
      "\n",
      "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2220, Loss 0.000245381350396201\n",
      "\t\tRESULT EPOCH 64:\n",
      "\t\t\tTrain Loss: 0.0003051350558442729 - Train Accuracy: 0.9993303571428571\n",
      "\t\t\tVal Loss: 0.007272188435308635 - Val Accuracy: 0.886\n",
      "\n",
      "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2250, Loss 0.0002175924164475873\n",
      "\t\tRESULT EPOCH 65:\n",
      "\t\t\tTrain Loss: 0.00029463136701711587 - Train Accuracy: 0.9993303571428571\n",
      "\t\t\tVal Loss: 0.007891449728049338 - Val Accuracy: 0.874\n",
      "\n",
      "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2280, Loss 0.0003317936207167804\n",
      "\t\tRESULT EPOCH 66:\n",
      "\t\t\tTrain Loss: 0.0002786846195314346 - Train Accuracy: 0.9986607142857142\n",
      "\t\t\tVal Loss: 0.007777937455102801 - Val Accuracy: 0.88\n",
      "\n",
      "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2310, Loss 0.000517605512868613\n",
      "\t\tTrain step - Step 2340, Loss 0.00048399134539067745\n",
      "\t\tRESULT EPOCH 67:\n",
      "\t\t\tTrain Loss: 0.00032642990866276833 - Train Accuracy: 0.9970982142857143\n",
      "\t\t\tVal Loss: 0.007577255484648049 - Val Accuracy: 0.884\n",
      "\n",
      "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2370, Loss 0.00029398113838396966\n",
      "\t\tRESULT EPOCH 68:\n",
      "\t\t\tTrain Loss: 0.0002863792985278581 - Train Accuracy: 0.9984375\n",
      "\t\t\tVal Loss: 0.006880730157718062 - Val Accuracy: 0.896\n",
      "\n",
      "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2400, Loss 0.0003009118663612753\n",
      "\t\tRESULT EPOCH 69:\n",
      "\t\t\tTrain Loss: 0.0002730967614167769 - Train Accuracy: 0.9993303571428571\n",
      "\t\t\tVal Loss: 0.007555688265711069 - Val Accuracy: 0.892\n",
      "\n",
      "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2430, Loss 0.00034553237492218614\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/47 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tRESULT EPOCH 70:\n",
      "\t\t\tTrain Loss: 0.00024190417046026725 - Train Accuracy: 0.9991071428571429\n",
      "\t\t\tVal Loss: 0.006778823095373809 - Val Accuracy: 0.898\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:01<00:00, 29.39it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "\tResults STAGE 6:\n",
      "\t\tTrain Mean Accuracy: 0.9245471938775511\n",
      "\t\tVal Mean Accuracy: 0.8058857142857144\n",
      "\t\tTest Accuracy: 0.14766666666666667\n",
      "\n",
      "STARTING FINE TUNING STAGE 7...\n",
      "\tSTARTING EPOCH 1 - LR=[2]...\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tTrain step - Step 30, Loss 0.025854382663965225\n",
      "\t\tRESULT EPOCH 1:\n",
      "\t\t\tTrain Loss: 0.04442492138062205 - Train Accuracy: 0.26986607142857144\n",
      "\t\t\tVal Loss: 0.024339372757822275 - Val Accuracy: 0.422\n",
      "\n",
      "\tSTARTING EPOCH 2 - LR=[2]...\n",
      "\t\tTrain step - Step 60, Loss 0.01946958340704441\n",
      "\t\tRESULT EPOCH 2:\n",
      "\t\t\tTrain Loss: 0.019091787987521716 - Train Accuracy: 0.5801339285714285\n",
      "\t\t\tVal Loss: 0.01832027453929186 - Val Accuracy: 0.606\n",
      "\n",
      "\tSTARTING EPOCH 3 - LR=[2]...\n",
      "\t\tTrain step - Step 90, Loss 0.012491022236645222\n",
      "\t\tRESULT EPOCH 3:\n",
      "\t\t\tTrain Loss: 0.014712701870926789 - Train Accuracy: 0.6886160714285714\n",
      "\t\t\tVal Loss: 0.0161012161988765 - Val Accuracy: 0.646\n",
      "\n",
      "\tSTARTING EPOCH 4 - LR=[2]...\n",
      "\t\tTrain step - Step 120, Loss 0.011574873700737953\n",
      "\t\tRESULT EPOCH 4:\n",
      "\t\t\tTrain Loss: 0.012447957481656755 - Train Accuracy: 0.7464285714285714\n",
      "\t\t\tVal Loss: 0.013643586076796055 - Val Accuracy: 0.716\n",
      "\n",
      "\tSTARTING EPOCH 5 - LR=[2]...\n",
      "\t\tTrain step - Step 150, Loss 0.011805289424955845\n",
      "\t\tRESULT EPOCH 5:\n",
      "\t\t\tTrain Loss: 0.01095596043659108 - Train Accuracy: 0.7872767857142857\n",
      "\t\t\tVal Loss: 0.013368648244068027 - Val Accuracy: 0.714\n",
      "\n",
      "\tSTARTING EPOCH 6 - LR=[2]...\n",
      "\t\tTrain step - Step 180, Loss 0.008593186736106873\n",
      "\t\tRESULT EPOCH 6:\n",
      "\t\t\tTrain Loss: 0.009798061847686768 - Train Accuracy: 0.8060267857142858\n",
      "\t\t\tVal Loss: 0.013845861423760653 - Val Accuracy: 0.704\n",
      "\n",
      "\tSTARTING EPOCH 7 - LR=[2]...\n",
      "\t\tTrain step - Step 210, Loss 0.008052095770835876\n",
      "\t\tTrain step - Step 240, Loss 0.007391063496470451\n",
      "\t\tRESULT EPOCH 7:\n",
      "\t\t\tTrain Loss: 0.008809048349836044 - Train Accuracy: 0.8267857142857142\n",
      "\t\t\tVal Loss: 0.014596881112083793 - Val Accuracy: 0.684\n",
      "\n",
      "\tSTARTING EPOCH 8 - LR=[2]...\n",
      "\t\tTrain step - Step 270, Loss 0.00762843107804656\n",
      "\t\tRESULT EPOCH 8:\n",
      "\t\t\tTrain Loss: 0.008106907057975019 - Train Accuracy: 0.846875\n",
      "\t\t\tVal Loss: 0.014917051303200424 - Val Accuracy: 0.722\n",
      "\n",
      "\tSTARTING EPOCH 9 - LR=[2]...\n",
      "\t\tTrain step - Step 300, Loss 0.007639648858457804\n",
      "\t\tRESULT EPOCH 9:\n",
      "\t\t\tTrain Loss: 0.007454001278217349 - Train Accuracy: 0.8573660714285715\n",
      "\t\t\tVal Loss: 0.013889897149056196 - Val Accuracy: 0.73\n",
      "\n",
      "\tSTARTING EPOCH 10 - LR=[2]...\n",
      "\t\tTrain step - Step 330, Loss 0.007710025180131197\n",
      "\t\tRESULT EPOCH 10:\n",
      "\t\t\tTrain Loss: 0.007008353740509067 - Train Accuracy: 0.8647321428571428\n",
      "\t\t\tVal Loss: 0.014973555458709598 - Val Accuracy: 0.706\n",
      "\n",
      "\tSTARTING EPOCH 11 - LR=[2]...\n",
      "\t\tTrain step - Step 360, Loss 0.003971519879996777\n",
      "\t\tRESULT EPOCH 11:\n",
      "\t\t\tTrain Loss: 0.006496245560369322 - Train Accuracy: 0.8819196428571429\n",
      "\t\t\tVal Loss: 0.013538926606997848 - Val Accuracy: 0.742\n",
      "\n",
      "\tSTARTING EPOCH 12 - LR=[2]...\n",
      "\t\tTrain step - Step 390, Loss 0.006247116718441248\n",
      "\t\tRESULT EPOCH 12:\n",
      "\t\t\tTrain Loss: 0.006331219564058951 - Train Accuracy: 0.8845982142857143\n",
      "\t\t\tVal Loss: 0.010196165647357702 - Val Accuracy: 0.832\n",
      "\n",
      "\tSTARTING EPOCH 13 - LR=[2]...\n",
      "\t\tTrain step - Step 420, Loss 0.005229460075497627\n",
      "\t\tTrain step - Step 450, Loss 0.00705147348344326\n",
      "\t\tRESULT EPOCH 13:\n",
      "\t\t\tTrain Loss: 0.006086454926324742 - Train Accuracy: 0.8868303571428572\n",
      "\t\t\tVal Loss: 0.012097840779460967 - Val Accuracy: 0.79\n",
      "\n",
      "\tSTARTING EPOCH 14 - LR=[2]...\n",
      "\t\tTrain step - Step 480, Loss 0.007171192206442356\n",
      "\t\tRESULT EPOCH 14:\n",
      "\t\t\tTrain Loss: 0.0058522990372564115 - Train Accuracy: 0.8921875\n",
      "\t\t\tVal Loss: 0.014693347038701177 - Val Accuracy: 0.724\n",
      "\n",
      "\tSTARTING EPOCH 15 - LR=[2]...\n",
      "\t\tTrain step - Step 510, Loss 0.00795016996562481\n",
      "\t\tRESULT EPOCH 15:\n",
      "\t\t\tTrain Loss: 0.0056698206745620285 - Train Accuracy: 0.8955357142857143\n",
      "\t\t\tVal Loss: 0.012060121982358396 - Val Accuracy: 0.76\n",
      "\n",
      "\tSTARTING EPOCH 16 - LR=[2]...\n",
      "\t\tTrain step - Step 540, Loss 0.005005748942494392\n",
      "\t\tRESULT EPOCH 16:\n",
      "\t\t\tTrain Loss: 0.004852108876886112 - Train Accuracy: 0.9149553571428571\n",
      "\t\t\tVal Loss: 0.013625368475914001 - Val Accuracy: 0.744\n",
      "\n",
      "\tSTARTING EPOCH 17 - LR=[2]...\n",
      "\t\tTrain step - Step 570, Loss 0.003458275692537427\n",
      "\t\tRESULT EPOCH 17:\n",
      "\t\t\tTrain Loss: 0.004663666324423892 - Train Accuracy: 0.9131696428571429\n",
      "\t\t\tVal Loss: 0.009849016671068966 - Val Accuracy: 0.818\n",
      "\n",
      "\tSTARTING EPOCH 18 - LR=[2]...\n",
      "\t\tTrain step - Step 600, Loss 0.005083075724542141\n",
      "\t\tRESULT EPOCH 18:\n",
      "\t\t\tTrain Loss: 0.00494624191362943 - Train Accuracy: 0.9049107142857142\n",
      "\t\t\tVal Loss: 0.017383934697136283 - Val Accuracy: 0.726\n",
      "\n",
      "\tSTARTING EPOCH 19 - LR=[2]...\n",
      "\t\tTrain step - Step 630, Loss 0.006460847798734903\n",
      "\t\tTrain step - Step 660, Loss 0.004498173017054796\n",
      "\t\tRESULT EPOCH 19:\n",
      "\t\t\tTrain Loss: 0.005767164379358291 - Train Accuracy: 0.8917410714285714\n",
      "\t\t\tVal Loss: 0.024138871347531676 - Val Accuracy: 0.648\n",
      "\n",
      "\tSTARTING EPOCH 20 - LR=[2]...\n",
      "\t\tTrain step - Step 690, Loss 0.004867124371230602\n",
      "\t\tRESULT EPOCH 20:\n",
      "\t\t\tTrain Loss: 0.005125464558867472 - Train Accuracy: 0.9040178571428571\n",
      "\t\t\tVal Loss: 0.010339335189200938 - Val Accuracy: 0.8\n",
      "\n",
      "\tSTARTING EPOCH 21 - LR=[2]...\n",
      "\t\tTrain step - Step 720, Loss 0.00576166994869709\n",
      "\t\tRESULT EPOCH 21:\n",
      "\t\t\tTrain Loss: 0.003991810904283609 - Train Accuracy: 0.9328125\n",
      "\t\t\tVal Loss: 0.011078595707658678 - Val Accuracy: 0.806\n",
      "\n",
      "\tSTARTING EPOCH 22 - LR=[2]...\n",
      "\t\tTrain step - Step 750, Loss 0.004109838977456093\n",
      "\t\tRESULT EPOCH 22:\n",
      "\t\t\tTrain Loss: 0.003746314612882478 - Train Accuracy: 0.9283482142857142\n",
      "\t\t\tVal Loss: 0.012772529618814588 - Val Accuracy: 0.786\n",
      "\n",
      "\tSTARTING EPOCH 23 - LR=[2]...\n",
      "\t\tTrain step - Step 780, Loss 0.004293832927942276\n",
      "\t\tRESULT EPOCH 23:\n",
      "\t\t\tTrain Loss: 0.0038318786370967117 - Train Accuracy: 0.9292410714285714\n",
      "\t\t\tVal Loss: 0.012304981588386 - Val Accuracy: 0.792\n",
      "\n",
      "\tSTARTING EPOCH 24 - LR=[2]...\n",
      "\t\tTrain step - Step 810, Loss 0.004981780890375376\n",
      "\t\tRESULT EPOCH 24:\n",
      "\t\t\tTrain Loss: 0.003528183785134128 - Train Accuracy: 0.934375\n",
      "\t\t\tVal Loss: 0.013102657278068364 - Val Accuracy: 0.792\n",
      "\n",
      "\tSTARTING EPOCH 25 - LR=[2]...\n",
      "\t\tTrain step - Step 840, Loss 0.00389161822386086\n",
      "\t\tTrain step - Step 870, Loss 0.003134162863716483\n",
      "\t\tRESULT EPOCH 25:\n",
      "\t\t\tTrain Loss: 0.003335729075063552 - Train Accuracy: 0.9395089285714285\n",
      "\t\t\tVal Loss: 0.00868561607785523 - Val Accuracy: 0.844\n",
      "\n",
      "\tSTARTING EPOCH 26 - LR=[2]...\n",
      "\t\tTrain step - Step 900, Loss 0.002741748234257102\n",
      "\t\tRESULT EPOCH 26:\n",
      "\t\t\tTrain Loss: 0.0034558514864849194 - Train Accuracy: 0.940625\n",
      "\t\t\tVal Loss: 0.01065083930734545 - Val Accuracy: 0.818\n",
      "\n",
      "\tSTARTING EPOCH 27 - LR=[2]...\n",
      "\t\tTrain step - Step 930, Loss 0.002906045177951455\n",
      "\t\tRESULT EPOCH 27:\n",
      "\t\t\tTrain Loss: 0.0034267953297655498 - Train Accuracy: 0.9401785714285714\n",
      "\t\t\tVal Loss: 0.010662092478014529 - Val Accuracy: 0.838\n",
      "\n",
      "\tSTARTING EPOCH 28 - LR=[2]...\n",
      "\t\tTrain step - Step 960, Loss 0.003533033886924386\n",
      "\t\tRESULT EPOCH 28:\n",
      "\t\t\tTrain Loss: 0.0035890523876462663 - Train Accuracy: 0.9381696428571429\n",
      "\t\t\tVal Loss: 0.009487465373240411 - Val Accuracy: 0.82\n",
      "\n",
      "\tSTARTING EPOCH 29 - LR=[2]...\n",
      "\t\tTrain step - Step 990, Loss 0.0032192873768508434\n",
      "\t\tRESULT EPOCH 29:\n",
      "\t\t\tTrain Loss: 0.003592131646083934 - Train Accuracy: 0.9359375\n",
      "\t\t\tVal Loss: 0.011304428218863904 - Val Accuracy: 0.804\n",
      "\n",
      "\tSTARTING EPOCH 30 - LR=[2]...\n",
      "\t\tTrain step - Step 1020, Loss 0.004460461437702179\n",
      "\t\tRESULT EPOCH 30:\n",
      "\t\t\tTrain Loss: 0.0033449647715315224 - Train Accuracy: 0.9419642857142857\n",
      "\t\t\tVal Loss: 0.009108152822591364 - Val Accuracy: 0.846\n",
      "\n",
      "\tSTARTING EPOCH 31 - LR=[2]...\n",
      "\t\tTrain step - Step 1050, Loss 0.0019401335157454014\n",
      "\t\tTrain step - Step 1080, Loss 0.002485306467860937\n",
      "\t\tRESULT EPOCH 31:\n",
      "\t\t\tTrain Loss: 0.0032427409663796426 - Train Accuracy: 0.9412946428571428\n",
      "\t\t\tVal Loss: 0.011369763407856226 - Val Accuracy: 0.808\n",
      "\n",
      "\tSTARTING EPOCH 32 - LR=[2]...\n",
      "\t\tTrain step - Step 1110, Loss 0.0035675696562975645\n",
      "\t\tRESULT EPOCH 32:\n",
      "\t\t\tTrain Loss: 0.003120051008383078 - Train Accuracy: 0.9488839285714286\n",
      "\t\t\tVal Loss: 0.009270780137740076 - Val Accuracy: 0.836\n",
      "\n",
      "\tSTARTING EPOCH 33 - LR=[2]...\n",
      "\t\tTrain step - Step 1140, Loss 0.0026082112453877926\n",
      "\t\tRESULT EPOCH 33:\n",
      "\t\t\tTrain Loss: 0.002879063808359206 - Train Accuracy: 0.9488839285714286\n",
      "\t\t\tVal Loss: 0.00943683972582221 - Val Accuracy: 0.842\n",
      "\n",
      "\tSTARTING EPOCH 34 - LR=[2]...\n",
      "\t\tTrain step - Step 1170, Loss 0.002365896012634039\n",
      "\t\tRESULT EPOCH 34:\n",
      "\t\t\tTrain Loss: 0.002736087499319443 - Train Accuracy: 0.9546875\n",
      "\t\t\tVal Loss: 0.012064359383657575 - Val Accuracy: 0.824\n",
      "\n",
      "\tSTARTING EPOCH 35 - LR=[2]...\n",
      "\t\tTrain step - Step 1200, Loss 0.0022630849853157997\n",
      "\t\tRESULT EPOCH 35:\n",
      "\t\t\tTrain Loss: 0.0031722126262528558 - Train Accuracy: 0.9439732142857142\n",
      "\t\t\tVal Loss: 0.01416074763983488 - Val Accuracy: 0.79\n",
      "\n",
      "\tSTARTING EPOCH 36 - LR=[2]...\n",
      "\t\tTrain step - Step 1230, Loss 0.003708441276103258\n",
      "\t\tRESULT EPOCH 36:\n",
      "\t\t\tTrain Loss: 0.0026380887787256922 - Train Accuracy: 0.9549107142857143\n",
      "\t\t\tVal Loss: 0.008683927357196808 - Val Accuracy: 0.844\n",
      "\n",
      "\tSTARTING EPOCH 37 - LR=[2]...\n",
      "\t\tTrain step - Step 1260, Loss 0.0008521407144144177\n",
      "\t\tTrain step - Step 1290, Loss 0.004015597980469465\n",
      "\t\tRESULT EPOCH 37:\n",
      "\t\t\tTrain Loss: 0.002702861774845847 - Train Accuracy: 0.9540178571428571\n",
      "\t\t\tVal Loss: 0.013401924865320325 - Val Accuracy: 0.762\n",
      "\n",
      "\tSTARTING EPOCH 38 - LR=[2]...\n",
      "\t\tTrain step - Step 1320, Loss 0.0019247240852564573\n",
      "\t\tRESULT EPOCH 38:\n",
      "\t\t\tTrain Loss: 0.0032038980795602713 - Train Accuracy: 0.9435267857142857\n",
      "\t\t\tVal Loss: 0.014546314254403114 - Val Accuracy: 0.78\n",
      "\n",
      "\tSTARTING EPOCH 39 - LR=[2]...\n",
      "\t\tTrain step - Step 1350, Loss 0.002149060135707259\n",
      "\t\tRESULT EPOCH 39:\n",
      "\t\t\tTrain Loss: 0.0024558659842503923 - Train Accuracy: 0.9564732142857143\n",
      "\t\t\tVal Loss: 0.011707974597811699 - Val Accuracy: 0.818\n",
      "\n",
      "\tSTARTING EPOCH 40 - LR=[2]...\n",
      "\t\tTrain step - Step 1380, Loss 0.00288332998752594\n",
      "\t\tRESULT EPOCH 40:\n",
      "\t\t\tTrain Loss: 0.0023111546844510095 - Train Accuracy: 0.9618303571428571\n",
      "\t\t\tVal Loss: 0.01194397360086441 - Val Accuracy: 0.812\n",
      "\n",
      "\tSTARTING EPOCH 41 - LR=[2]...\n",
      "\t\tTrain step - Step 1410, Loss 0.002043235581368208\n",
      "\t\tRESULT EPOCH 41:\n",
      "\t\t\tTrain Loss: 0.002745158241928688 - Train Accuracy: 0.9493303571428572\n",
      "\t\t\tVal Loss: 0.013228845898993313 - Val Accuracy: 0.8\n",
      "\n",
      "\tSTARTING EPOCH 42 - LR=[2]...\n",
      "\t\tTrain step - Step 1440, Loss 0.0017998787807300687\n",
      "\t\tRESULT EPOCH 42:\n",
      "\t\t\tTrain Loss: 0.0031623725380216326 - Train Accuracy: 0.9428571428571428\n",
      "\t\t\tVal Loss: 0.009603104670532048 - Val Accuracy: 0.844\n",
      "\n",
      "\tSTARTING EPOCH 43 - LR=[2]...\n",
      "\t\tTrain step - Step 1470, Loss 0.0019343688618391752\n",
      "\t\tTrain step - Step 1500, Loss 0.002254665829241276\n",
      "\t\tRESULT EPOCH 43:\n",
      "\t\t\tTrain Loss: 0.002534723188728094 - Train Accuracy: 0.9571428571428572\n",
      "\t\t\tVal Loss: 0.00962571008130908 - Val Accuracy: 0.836\n",
      "\n",
      "\tSTARTING EPOCH 44 - LR=[2]...\n",
      "\t\tTrain step - Step 1530, Loss 0.0012573378626257181\n",
      "\t\tRESULT EPOCH 44:\n",
      "\t\t\tTrain Loss: 0.0024798654951155184 - Train Accuracy: 0.95625\n",
      "\t\t\tVal Loss: 0.010035232873633504 - Val Accuracy: 0.828\n",
      "\n",
      "\tSTARTING EPOCH 45 - LR=[2]...\n",
      "\t\tTrain step - Step 1560, Loss 0.0018910883227363229\n",
      "\t\tRESULT EPOCH 45:\n",
      "\t\t\tTrain Loss: 0.0023389071725042803 - Train Accuracy: 0.9580357142857143\n",
      "\t\t\tVal Loss: 0.008344874833710492 - Val Accuracy: 0.848\n",
      "\n",
      "\tSTARTING EPOCH 46 - LR=[2]...\n",
      "\t\tTrain step - Step 1590, Loss 0.002261499408632517\n",
      "\t\tRESULT EPOCH 46:\n",
      "\t\t\tTrain Loss: 0.0024877352373940606 - Train Accuracy: 0.9604910714285714\n",
      "\t\t\tVal Loss: 0.016583751770667732 - Val Accuracy: 0.754\n",
      "\n",
      "\tSTARTING EPOCH 47 - LR=[2]...\n",
      "\t\tTrain step - Step 1620, Loss 0.00352657912299037\n",
      "\t\tRESULT EPOCH 47:\n",
      "\t\t\tTrain Loss: 0.00303756495871182 - Train Accuracy: 0.9497767857142857\n",
      "\t\t\tVal Loss: 0.010872293263673782 - Val Accuracy: 0.816\n",
      "\n",
      "\tSTARTING EPOCH 48 - LR=[2]...\n",
      "\t\tTrain step - Step 1650, Loss 0.0022062002681195736\n",
      "\t\tRESULT EPOCH 48:\n",
      "\t\t\tTrain Loss: 0.002004515579236405 - Train Accuracy: 0.965625\n",
      "\t\t\tVal Loss: 0.008875571307726204 - Val Accuracy: 0.858\n",
      "\n",
      "\tSTARTING EPOCH 49 - LR=[2]...\n",
      "\t\tTrain step - Step 1680, Loss 0.002126984531059861\n",
      "\t\tTrain step - Step 1710, Loss 0.0020467224530875683\n",
      "\t\tRESULT EPOCH 49:\n",
      "\t\t\tTrain Loss: 0.002202475845946797 - Train Accuracy: 0.9609375\n",
      "\t\t\tVal Loss: 0.01481590059120208 - Val Accuracy: 0.786\n",
      "\n",
      "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1740, Loss 0.0009737318614497781\n",
      "\t\tRESULT EPOCH 50:\n",
      "\t\t\tTrain Loss: 0.0014263039862271397 - Train Accuracy: 0.9814732142857143\n",
      "\t\t\tVal Loss: 0.007332049775868654 - Val Accuracy: 0.86\n",
      "\n",
      "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1770, Loss 0.0006996466545388103\n",
      "\t\tRESULT EPOCH 51:\n",
      "\t\t\tTrain Loss: 0.0007281322406405317 - Train Accuracy: 0.990625\n",
      "\t\t\tVal Loss: 0.006259764253627509 - Val Accuracy: 0.888\n",
      "\n",
      "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1800, Loss 0.00045689180842600763\n",
      "\t\tRESULT EPOCH 52:\n",
      "\t\t\tTrain Loss: 0.0005778362517178591 - Train Accuracy: 0.9966517857142857\n",
      "\t\t\tVal Loss: 0.006482963799498975 - Val Accuracy: 0.898\n",
      "\n",
      "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1830, Loss 0.0004598899686243385\n",
      "\t\tRESULT EPOCH 53:\n",
      "\t\t\tTrain Loss: 0.0005256669579206833 - Train Accuracy: 0.9946428571428572\n",
      "\t\t\tVal Loss: 0.007166967960074544 - Val Accuracy: 0.88\n",
      "\n",
      "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1860, Loss 0.00041132679325528443\n",
      "\t\tRESULT EPOCH 54:\n",
      "\t\t\tTrain Loss: 0.0005013215829551752 - Train Accuracy: 0.9957589285714286\n",
      "\t\t\tVal Loss: 0.007444536779075861 - Val Accuracy: 0.878\n",
      "\n",
      "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1890, Loss 0.0003236096235923469\n",
      "\t\tTrain step - Step 1920, Loss 0.0007273478549905121\n",
      "\t\tRESULT EPOCH 55:\n",
      "\t\t\tTrain Loss: 0.00045785616010627045 - Train Accuracy: 0.9966517857142857\n",
      "\t\t\tVal Loss: 0.006379356840625405 - Val Accuracy: 0.892\n",
      "\n",
      "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1950, Loss 0.00030801151297055185\n",
      "\t\tRESULT EPOCH 56:\n",
      "\t\t\tTrain Loss: 0.0003850837778632662 - Train Accuracy: 0.9986607142857142\n",
      "\t\t\tVal Loss: 0.006451643886975944 - Val Accuracy: 0.892\n",
      "\n",
      "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1980, Loss 0.0007237419486045837\n",
      "\t\tRESULT EPOCH 57:\n",
      "\t\t\tTrain Loss: 0.00041481159943422037 - Train Accuracy: 0.9966517857142857\n",
      "\t\t\tVal Loss: 0.006792128551751375 - Val Accuracy: 0.89\n",
      "\n",
      "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2010, Loss 0.0003616436733864248\n",
      "\t\tRESULT EPOCH 58:\n",
      "\t\t\tTrain Loss: 0.0003608175050300945 - Train Accuracy: 0.9993303571428571\n",
      "\t\t\tVal Loss: 0.006001703324727714 - Val Accuracy: 0.908\n",
      "\n",
      "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2040, Loss 0.0005844488623552024\n",
      "\t\tRESULT EPOCH 59:\n",
      "\t\t\tTrain Loss: 0.00036165997361032557 - Train Accuracy: 0.9973214285714286\n",
      "\t\t\tVal Loss: 0.006384383770637214 - Val Accuracy: 0.9\n",
      "\n",
      "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2070, Loss 0.0006142061902210116\n",
      "\t\tRESULT EPOCH 60:\n",
      "\t\t\tTrain Loss: 0.0003354493778065911 - Train Accuracy: 0.9984375\n",
      "\t\t\tVal Loss: 0.0069188004126772285 - Val Accuracy: 0.892\n",
      "\n",
      "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2100, Loss 0.0005359507049433887\n",
      "\t\tTrain step - Step 2130, Loss 0.0001878582261269912\n",
      "\t\tRESULT EPOCH 61:\n",
      "\t\t\tTrain Loss: 0.00037796072927968844 - Train Accuracy: 0.9977678571428571\n",
      "\t\t\tVal Loss: 0.006235676351934671 - Val Accuracy: 0.906\n",
      "\n",
      "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2160, Loss 0.00014433215255849063\n",
      "\t\tRESULT EPOCH 62:\n",
      "\t\t\tTrain Loss: 0.00032051325667582987 - Train Accuracy: 0.9986607142857142\n",
      "\t\t\tVal Loss: 0.0076634923461824656 - Val Accuracy: 0.886\n",
      "\n",
      "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2190, Loss 0.0003103747731074691\n",
      "\t\tRESULT EPOCH 63:\n",
      "\t\t\tTrain Loss: 0.00034236976935062555 - Train Accuracy: 0.9979910714285715\n",
      "\t\t\tVal Loss: 0.00683041731826961 - Val Accuracy: 0.902\n",
      "\n",
      "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2220, Loss 0.00012486561900004745\n",
      "\t\tRESULT EPOCH 64:\n",
      "\t\t\tTrain Loss: 0.00027212944613503557 - Train Accuracy: 0.9993303571428571\n",
      "\t\t\tVal Loss: 0.0062392373802140355 - Val Accuracy: 0.914\n",
      "\n",
      "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2250, Loss 0.0002800894726533443\n",
      "\t\tRESULT EPOCH 65:\n",
      "\t\t\tTrain Loss: 0.00027287728818399564 - Train Accuracy: 0.9993303571428571\n",
      "\t\t\tVal Loss: 0.006264943745918572 - Val Accuracy: 0.898\n",
      "\n",
      "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2280, Loss 0.0001884692464955151\n",
      "\t\tRESULT EPOCH 66:\n",
      "\t\t\tTrain Loss: 0.0002584537025541067 - Train Accuracy: 0.9991071428571429\n",
      "\t\t\tVal Loss: 0.005639784736558795 - Val Accuracy: 0.904\n",
      "\n",
      "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2310, Loss 0.00023763049102853984\n",
      "\t\tTrain step - Step 2340, Loss 0.00042239396134391427\n",
      "\t\tRESULT EPOCH 67:\n",
      "\t\t\tTrain Loss: 0.00025574041771635946 - Train Accuracy: 0.9995535714285714\n",
      "\t\t\tVal Loss: 0.006204980192705989 - Val Accuracy: 0.904\n",
      "\n",
      "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2370, Loss 0.0001881017378764227\n",
      "\t\tRESULT EPOCH 68:\n",
      "\t\t\tTrain Loss: 0.0002866643518375765 - Train Accuracy: 0.9986607142857142\n",
      "\t\t\tVal Loss: 0.00594764668494463 - Val Accuracy: 0.922\n",
      "\n",
      "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2400, Loss 0.00018347750301472843\n",
      "\t\tRESULT EPOCH 69:\n",
      "\t\t\tTrain Loss: 0.00025303227386237786 - Train Accuracy: 0.9993303571428571\n",
      "\t\t\tVal Loss: 0.006288637523539364 - Val Accuracy: 0.902\n",
      "\n",
      "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2430, Loss 0.000130079424707219\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/55 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tRESULT EPOCH 70:\n",
      "\t\t\tTrain Loss: 0.00023118995429415788 - Train Accuracy: 0.9995535714285714\n",
      "\t\t\tVal Loss: 0.007170927943661809 - Val Accuracy: 0.884\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:01<00:00, 29.92it/s]\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "\tResults STAGE 7:\n",
      "\t\tTrain Mean Accuracy: 0.9235650510204081\n",
      "\t\tVal Mean Accuracy: 0.8095142857142857\n",
      "\t\tTest Accuracy: 0.12785714285714286\n",
      "\n",
      "STARTING FINE TUNING STAGE 8...\n",
      "\tSTARTING EPOCH 1 - LR=[2]...\n",
      "\t\tTrain step - Step 30, Loss 0.02642090804874897\n",
      "\t\tRESULT EPOCH 1:\n",
      "\t\t\tTrain Loss: 0.04558394040380206 - Train Accuracy: 0.24464285714285713\n",
      "\t\t\tVal Loss: 0.024390308186411858 - Val Accuracy: 0.49\n",
      "\n",
      "\tSTARTING EPOCH 2 - LR=[2]...\n",
      "\t\tTrain step - Step 60, Loss 0.017869025468826294\n",
      "\t\tRESULT EPOCH 2:\n",
      "\t\t\tTrain Loss: 0.01887460619743381 - Train Accuracy: 0.6368303571428572\n",
      "\t\t\tVal Loss: 0.01723899389617145 - Val Accuracy: 0.64\n",
      "\n",
      "\tSTARTING EPOCH 3 - LR=[2]...\n",
      "\t\tTrain step - Step 90, Loss 0.012351155281066895\n",
      "\t\tRESULT EPOCH 3:\n",
      "\t\t\tTrain Loss: 0.013702635546880108 - Train Accuracy: 0.7495535714285714\n",
      "\t\t\tVal Loss: 0.013939922209829092 - Val Accuracy: 0.728\n",
      "\n",
      "\tSTARTING EPOCH 4 - LR=[2]...\n",
      "\t\tTrain step - Step 120, Loss 0.01130362693220377\n",
      "\t\tRESULT EPOCH 4:\n",
      "\t\t\tTrain Loss: 0.011427403028522218 - Train Accuracy: 0.7953125\n",
      "\t\t\tVal Loss: 0.013929479056969285 - Val Accuracy: 0.732\n",
      "\n",
      "\tSTARTING EPOCH 5 - LR=[2]...\n",
      "\t\tTrain step - Step 150, Loss 0.01161937229335308\n",
      "\t\tRESULT EPOCH 5:\n",
      "\t\t\tTrain Loss: 0.00973216804808804 - Train Accuracy: 0.8241071428571428\n",
      "\t\t\tVal Loss: 0.012307625729590654 - Val Accuracy: 0.76\n",
      "\n",
      "\tSTARTING EPOCH 6 - LR=[2]...\n",
      "\t\tTrain step - Step 180, Loss 0.007365166209638119\n",
      "\t\tRESULT EPOCH 6:\n",
      "\t\t\tTrain Loss: 0.009443712420761585 - Train Accuracy: 0.8316964285714286\n",
      "\t\t\tVal Loss: 0.01089883828535676 - Val Accuracy: 0.796\n",
      "\n",
      "\tSTARTING EPOCH 7 - LR=[2]...\n",
      "\t\tTrain step - Step 210, Loss 0.008211921900510788\n",
      "\t\tTrain step - Step 240, Loss 0.01010278519243002\n",
      "\t\tRESULT EPOCH 7:\n",
      "\t\t\tTrain Loss: 0.008346495378230298 - Train Accuracy: 0.8493303571428571\n",
      "\t\t\tVal Loss: 0.011157987057231367 - Val Accuracy: 0.798\n",
      "\n",
      "\tSTARTING EPOCH 8 - LR=[2]...\n",
      "\t\tTrain step - Step 270, Loss 0.004859465174376965\n",
      "\t\tRESULT EPOCH 8:\n",
      "\t\t\tTrain Loss: 0.007513890322297811 - Train Accuracy: 0.8705357142857143\n",
      "\t\t\tVal Loss: 0.014168874127790332 - Val Accuracy: 0.726\n",
      "\n",
      "\tSTARTING EPOCH 9 - LR=[2]...\n",
      "\t\tTrain step - Step 300, Loss 0.008847869001328945\n",
      "\t\tRESULT EPOCH 9:\n",
      "\t\t\tTrain Loss: 0.006763133672731263 - Train Accuracy: 0.8796875\n",
      "\t\t\tVal Loss: 0.011095815687440336 - Val Accuracy: 0.804\n",
      "\n",
      "\tSTARTING EPOCH 10 - LR=[2]...\n",
      "\t\tTrain step - Step 330, Loss 0.005118642933666706\n",
      "\t\tRESULT EPOCH 10:\n",
      "\t\t\tTrain Loss: 0.006651900269623314 - Train Accuracy: 0.8814732142857142\n",
      "\t\t\tVal Loss: 0.015128055587410927 - Val Accuracy: 0.744\n",
      "\n",
      "\tSTARTING EPOCH 11 - LR=[2]...\n",
      "\t\tTrain step - Step 360, Loss 0.005762230139225721\n",
      "\t\tRESULT EPOCH 11:\n",
      "\t\t\tTrain Loss: 0.006396713879491602 - Train Accuracy: 0.8821428571428571\n",
      "\t\t\tVal Loss: 0.0125483627198264 - Val Accuracy: 0.768\n",
      "\n",
      "\tSTARTING EPOCH 12 - LR=[2]...\n",
      "\t\tTrain step - Step 390, Loss 0.005837473552674055\n",
      "\t\tRESULT EPOCH 12:\n",
      "\t\t\tTrain Loss: 0.006261106627061963 - Train Accuracy: 0.8863839285714286\n",
      "\t\t\tVal Loss: 0.01436568470671773 - Val Accuracy: 0.746\n",
      "\n",
      "\tSTARTING EPOCH 13 - LR=[2]...\n",
      "\t\tTrain step - Step 420, Loss 0.004761017393320799\n",
      "\t\tTrain step - Step 450, Loss 0.004427354317158461\n",
      "\t\tRESULT EPOCH 13:\n",
      "\t\t\tTrain Loss: 0.005497200088575483 - Train Accuracy: 0.9055803571428571\n",
      "\t\t\tVal Loss: 0.012346443487331271 - Val Accuracy: 0.796\n",
      "\n",
      "\tSTARTING EPOCH 14 - LR=[2]...\n",
      "\t\tTrain step - Step 480, Loss 0.005947910249233246\n",
      "\t\tRESULT EPOCH 14:\n",
      "\t\t\tTrain Loss: 0.005161617410236172 - Train Accuracy: 0.9087053571428572\n",
      "\t\t\tVal Loss: 0.016966168768703938 - Val Accuracy: 0.722\n",
      "\n",
      "\tSTARTING EPOCH 15 - LR=[2]...\n",
      "\t\tTrain step - Step 510, Loss 0.0065619503147900105\n",
      "\t\tRESULT EPOCH 15:\n",
      "\t\t\tTrain Loss: 0.004955915567864265 - Train Accuracy: 0.9120535714285715\n",
      "\t\t\tVal Loss: 0.013555935467593372 - Val Accuracy: 0.76\n",
      "\n",
      "\tSTARTING EPOCH 16 - LR=[2]...\n",
      "\t\tTrain step - Step 540, Loss 0.0029356719460338354\n",
      "\t\tRESULT EPOCH 16:\n",
      "\t\t\tTrain Loss: 0.005013671484110611 - Train Accuracy: 0.9102678571428572\n",
      "\t\t\tVal Loss: 0.01339673064649105 - Val Accuracy: 0.758\n",
      "\n",
      "\tSTARTING EPOCH 17 - LR=[2]...\n",
      "\t\tTrain step - Step 570, Loss 0.004853797145187855\n",
      "\t\tRESULT EPOCH 17:\n",
      "\t\t\tTrain Loss: 0.005254064014713679 - Train Accuracy: 0.9069196428571429\n",
      "\t\t\tVal Loss: 0.013611300149932504 - Val Accuracy: 0.74\n",
      "\n",
      "\tSTARTING EPOCH 18 - LR=[2]...\n",
      "\t\tTrain step - Step 600, Loss 0.00438813678920269\n",
      "\t\tRESULT EPOCH 18:\n",
      "\t\t\tTrain Loss: 0.004493878981364625 - Train Accuracy: 0.9238839285714285\n",
      "\t\t\tVal Loss: 0.013294664677232504 - Val Accuracy: 0.78\n",
      "\n",
      "\tSTARTING EPOCH 19 - LR=[2]...\n",
      "\t\tTrain step - Step 630, Loss 0.004054855089634657\n",
      "\t\tTrain step - Step 660, Loss 0.005966097116470337\n",
      "\t\tRESULT EPOCH 19:\n",
      "\t\t\tTrain Loss: 0.004714720117460404 - Train Accuracy: 0.9171875\n",
      "\t\t\tVal Loss: 0.01916946133133024 - Val Accuracy: 0.72\n",
      "\n",
      "\tSTARTING EPOCH 20 - LR=[2]...\n",
      "\t\tTrain step - Step 690, Loss 0.006009114906191826\n",
      "\t\tRESULT EPOCH 20:\n",
      "\t\t\tTrain Loss: 0.004973830495561872 - Train Accuracy: 0.9120535714285715\n",
      "\t\t\tVal Loss: 0.009950659237802029 - Val Accuracy: 0.804\n",
      "\n",
      "\tSTARTING EPOCH 21 - LR=[2]...\n",
      "\t\tTrain step - Step 720, Loss 0.003499950049445033\n",
      "\t\tRESULT EPOCH 21:\n",
      "\t\t\tTrain Loss: 0.004531436094215938 - Train Accuracy: 0.915625\n",
      "\t\t\tVal Loss: 0.015643870923668146 - Val Accuracy: 0.748\n",
      "\n",
      "\tSTARTING EPOCH 22 - LR=[2]...\n",
      "\t\tTrain step - Step 750, Loss 0.004112508147954941\n",
      "\t\tRESULT EPOCH 22:\n",
      "\t\t\tTrain Loss: 0.0038170711203877414 - Train Accuracy: 0.9314732142857143\n",
      "\t\t\tVal Loss: 0.011003668420016766 - Val Accuracy: 0.786\n",
      "\n",
      "\tSTARTING EPOCH 23 - LR=[2]...\n",
      "\t\tTrain step - Step 780, Loss 0.005479936022311449\n",
      "\t\tRESULT EPOCH 23:\n",
      "\t\t\tTrain Loss: 0.0045067971771849055 - Train Accuracy: 0.9205357142857142\n",
      "\t\t\tVal Loss: 0.012406674679368734 - Val Accuracy: 0.772\n",
      "\n",
      "\tSTARTING EPOCH 24 - LR=[2]...\n",
      "\t\tTrain step - Step 810, Loss 0.002424193313345313\n",
      "\t\tRESULT EPOCH 24:\n",
      "\t\t\tTrain Loss: 0.004103164318283754 - Train Accuracy: 0.9272321428571428\n",
      "\t\t\tVal Loss: 0.011192717822268605 - Val Accuracy: 0.788\n",
      "\n",
      "\tSTARTING EPOCH 25 - LR=[2]...\n",
      "\t\tTrain step - Step 840, Loss 0.004439931828528643\n",
      "\t\tTrain step - Step 870, Loss 0.0024244121741503477\n",
      "\t\tRESULT EPOCH 25:\n",
      "\t\t\tTrain Loss: 0.003497250477916428 - Train Accuracy: 0.9397321428571429\n",
      "\t\t\tVal Loss: 0.012188946013338864 - Val Accuracy: 0.796\n",
      "\n",
      "\tSTARTING EPOCH 26 - LR=[2]...\n",
      "\t\tTrain step - Step 900, Loss 0.0062675923109054565\n",
      "\t\tRESULT EPOCH 26:\n",
      "\t\t\tTrain Loss: 0.0034257161830152784 - Train Accuracy: 0.9441964285714286\n",
      "\t\t\tVal Loss: 0.014099830528721213 - Val Accuracy: 0.78\n",
      "\n",
      "\tSTARTING EPOCH 27 - LR=[2]...\n",
      "\t\tTrain step - Step 930, Loss 0.003021079348400235\n",
      "\t\tRESULT EPOCH 27:\n",
      "\t\t\tTrain Loss: 0.003688421260033335 - Train Accuracy: 0.9375\n",
      "\t\t\tVal Loss: 0.011629468179307878 - Val Accuracy: 0.8\n",
      "\n",
      "\tSTARTING EPOCH 28 - LR=[2]...\n",
      "\t\tTrain step - Step 960, Loss 0.0031960895285010338\n",
      "\t\tRESULT EPOCH 28:\n",
      "\t\t\tTrain Loss: 0.0034319296346179075 - Train Accuracy: 0.9395089285714285\n",
      "\t\t\tVal Loss: 0.010651957709342241 - Val Accuracy: 0.806\n",
      "\n",
      "\tSTARTING EPOCH 29 - LR=[2]...\n",
      "\t\tTrain step - Step 990, Loss 0.0032172095961868763\n",
      "\t\tRESULT EPOCH 29:\n",
      "\t\t\tTrain Loss: 0.0031717511525909815 - Train Accuracy: 0.9455357142857143\n",
      "\t\t\tVal Loss: 0.012140862294472754 - Val Accuracy: 0.794\n",
      "\n",
      "\tSTARTING EPOCH 30 - LR=[2]...\n",
      "\t\tTrain step - Step 1020, Loss 0.0033380286768078804\n",
      "\t\tRESULT EPOCH 30:\n",
      "\t\t\tTrain Loss: 0.0034605499556554214 - Train Accuracy: 0.9408482142857143\n",
      "\t\t\tVal Loss: 0.016186769120395184 - Val Accuracy: 0.768\n",
      "\n",
      "\tSTARTING EPOCH 31 - LR=[2]...\n",
      "\t\tTrain step - Step 1050, Loss 0.002397810108959675\n",
      "\t\tTrain step - Step 1080, Loss 0.003349532140418887\n",
      "\t\tRESULT EPOCH 31:\n",
      "\t\t\tTrain Loss: 0.0033299499257866826 - Train Accuracy: 0.94375\n",
      "\t\t\tVal Loss: 0.011919419630430639 - Val Accuracy: 0.792\n",
      "\n",
      "\tSTARTING EPOCH 32 - LR=[2]...\n",
      "\t\tTrain step - Step 1110, Loss 0.003604621859267354\n",
      "\t\tRESULT EPOCH 32:\n",
      "\t\t\tTrain Loss: 0.0030066080424668534 - Train Accuracy: 0.9479910714285714\n",
      "\t\t\tVal Loss: 0.010087405564263463 - Val Accuracy: 0.832\n",
      "\n",
      "\tSTARTING EPOCH 33 - LR=[2]...\n",
      "\t\tTrain step - Step 1140, Loss 0.003569565014913678\n",
      "\t\tRESULT EPOCH 33:\n",
      "\t\t\tTrain Loss: 0.0032502775812255484 - Train Accuracy: 0.9477678571428572\n",
      "\t\t\tVal Loss: 0.014271597377955914 - Val Accuracy: 0.776\n",
      "\n",
      "\tSTARTING EPOCH 34 - LR=[2]...\n",
      "\t\tTrain step - Step 1170, Loss 0.0026124969590455294\n",
      "\t\tRESULT EPOCH 34:\n",
      "\t\t\tTrain Loss: 0.0031510081774156007 - Train Accuracy: 0.9453125\n",
      "\t\t\tVal Loss: 0.009489865275099874 - Val Accuracy: 0.85\n",
      "\n",
      "\tSTARTING EPOCH 35 - LR=[2]...\n",
      "\t\tTrain step - Step 1200, Loss 0.0032817476894706488\n",
      "\t\tRESULT EPOCH 35:\n",
      "\t\t\tTrain Loss: 0.002836555941030383 - Train Accuracy: 0.9520089285714286\n",
      "\t\t\tVal Loss: 0.010409696958959103 - Val Accuracy: 0.814\n",
      "\n",
      "\tSTARTING EPOCH 36 - LR=[2]...\n",
      "\t\tTrain step - Step 1230, Loss 0.0022852926049381495\n",
      "\t\tRESULT EPOCH 36:\n",
      "\t\t\tTrain Loss: 0.0024174385072131244 - Train Accuracy: 0.9604910714285714\n",
      "\t\t\tVal Loss: 0.015382703626528382 - Val Accuracy: 0.77\n",
      "\n",
      "\tSTARTING EPOCH 37 - LR=[2]...\n",
      "\t\tTrain step - Step 1260, Loss 0.0020113587379455566\n",
      "\t\tTrain step - Step 1290, Loss 0.0020456474740058184\n",
      "\t\tRESULT EPOCH 37:\n",
      "\t\t\tTrain Loss: 0.0022149238635652832 - Train Accuracy: 0.9627232142857143\n",
      "\t\t\tVal Loss: 0.009697358007542789 - Val Accuracy: 0.834\n",
      "\n",
      "\tSTARTING EPOCH 38 - LR=[2]...\n",
      "\t\tTrain step - Step 1320, Loss 0.003257456934079528\n",
      "\t\tRESULT EPOCH 38:\n",
      "\t\t\tTrain Loss: 0.0021994567243382333 - Train Accuracy: 0.9645089285714286\n",
      "\t\t\tVal Loss: 0.010106861009262502 - Val Accuracy: 0.824\n",
      "\n",
      "\tSTARTING EPOCH 39 - LR=[2]...\n",
      "\t\tTrain step - Step 1350, Loss 0.001077307271771133\n",
      "\t\tRESULT EPOCH 39:\n",
      "\t\t\tTrain Loss: 0.00228610127565584 - Train Accuracy: 0.9631696428571429\n",
      "\t\t\tVal Loss: 0.009799403487704694 - Val Accuracy: 0.844\n",
      "\n",
      "\tSTARTING EPOCH 40 - LR=[2]...\n",
      "\t\tTrain step - Step 1380, Loss 0.002292884746566415\n",
      "\t\tRESULT EPOCH 40:\n",
      "\t\t\tTrain Loss: 0.002524582012223878 - Train Accuracy: 0.9616071428571429\n",
      "\t\t\tVal Loss: 0.01578203763347119 - Val Accuracy: 0.782\n",
      "\n",
      "\tSTARTING EPOCH 41 - LR=[2]...\n",
      "\t\tTrain step - Step 1410, Loss 0.0018777592340484262\n",
      "\t\tRESULT EPOCH 41:\n",
      "\t\t\tTrain Loss: 0.002593062532001308 - Train Accuracy: 0.9526785714285714\n",
      "\t\t\tVal Loss: 0.010891891201026738 - Val Accuracy: 0.824\n",
      "\n",
      "\tSTARTING EPOCH 42 - LR=[2]...\n",
      "\t\tTrain step - Step 1440, Loss 0.0017133131623268127\n",
      "\t\tRESULT EPOCH 42:\n",
      "\t\t\tTrain Loss: 0.002564432332292199 - Train Accuracy: 0.9580357142857143\n",
      "\t\t\tVal Loss: 0.01834909268654883 - Val Accuracy: 0.746\n",
      "\n",
      "\tSTARTING EPOCH 43 - LR=[2]...\n",
      "\t\tTrain step - Step 1470, Loss 0.0015734783373773098\n",
      "\t\tTrain step - Step 1500, Loss 0.0036319398786872625\n",
      "\t\tRESULT EPOCH 43:\n",
      "\t\t\tTrain Loss: 0.0026554929824279885 - Train Accuracy: 0.9544642857142858\n",
      "\t\t\tVal Loss: 0.013989271246828139 - Val Accuracy: 0.812\n",
      "\n",
      "\tSTARTING EPOCH 44 - LR=[2]...\n",
      "\t\tTrain step - Step 1530, Loss 0.002622737316414714\n",
      "\t\tRESULT EPOCH 44:\n",
      "\t\t\tTrain Loss: 0.0025310716691559977 - Train Accuracy: 0.9560267857142857\n",
      "\t\t\tVal Loss: 0.01442978112027049 - Val Accuracy: 0.79\n",
      "\n",
      "\tSTARTING EPOCH 45 - LR=[2]...\n",
      "\t\tTrain step - Step 1560, Loss 0.002241851296275854\n",
      "\t\tRESULT EPOCH 45:\n",
      "\t\t\tTrain Loss: 0.0021494797098317317 - Train Accuracy: 0.9629464285714285\n",
      "\t\t\tVal Loss: 0.01466689957305789 - Val Accuracy: 0.784\n",
      "\n",
      "\tSTARTING EPOCH 46 - LR=[2]...\n",
      "\t\tTrain step - Step 1590, Loss 0.0016736671095713973\n",
      "\t\tRESULT EPOCH 46:\n",
      "\t\t\tTrain Loss: 0.0022634436575961966 - Train Accuracy: 0.9622767857142858\n",
      "\t\t\tVal Loss: 0.009532901458442211 - Val Accuracy: 0.822\n",
      "\n",
      "\tSTARTING EPOCH 47 - LR=[2]...\n",
      "\t\tTrain step - Step 1620, Loss 0.0015207272954285145\n",
      "\t\tRESULT EPOCH 47:\n",
      "\t\t\tTrain Loss: 0.002023049134628049 - Train Accuracy: 0.9678571428571429\n",
      "\t\t\tVal Loss: 0.011694423505105078 - Val Accuracy: 0.842\n",
      "\n",
      "\tSTARTING EPOCH 48 - LR=[2]...\n",
      "\t\tTrain step - Step 1650, Loss 0.0021129557862877846\n",
      "\t\tRESULT EPOCH 48:\n",
      "\t\t\tTrain Loss: 0.0025607718653710824 - Train Accuracy: 0.9558035714285714\n",
      "\t\t\tVal Loss: 0.011392237152904272 - Val Accuracy: 0.824\n",
      "\n",
      "\tSTARTING EPOCH 49 - LR=[2]...\n",
      "\t\tTrain step - Step 1680, Loss 0.0023361342027783394\n",
      "\t\tTrain step - Step 1710, Loss 0.0018173358403146267\n",
      "\t\tRESULT EPOCH 49:\n",
      "\t\t\tTrain Loss: 0.0020222187940297383 - Train Accuracy: 0.9660714285714286\n",
      "\t\t\tVal Loss: 0.012299202149733901 - Val Accuracy: 0.816\n",
      "\n",
      "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1740, Loss 0.0010565511183813214\n",
      "\t\tRESULT EPOCH 50:\n",
      "\t\t\tTrain Loss: 0.0011741459685643868 - Train Accuracy: 0.984375\n",
      "\t\t\tVal Loss: 0.006167871993966401 - Val Accuracy: 0.898\n",
      "\n",
      "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1770, Loss 0.0003906609781552106\n",
      "\t\tRESULT EPOCH 51:\n",
      "\t\t\tTrain Loss: 0.0007388119777065835 - Train Accuracy: 0.99375\n",
      "\t\t\tVal Loss: 0.006339863524772227 - Val Accuracy: 0.906\n",
      "\n",
      "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1800, Loss 0.000686247949488461\n",
      "\t\tRESULT EPOCH 52:\n",
      "\t\t\tTrain Loss: 0.0006168370592474406 - Train Accuracy: 0.9946428571428572\n",
      "\t\t\tVal Loss: 0.0058561142068356276 - Val Accuracy: 0.906\n",
      "\n",
      "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1830, Loss 0.0005759813357144594\n",
      "\t\tRESULT EPOCH 53:\n",
      "\t\t\tTrain Loss: 0.000494033335624928 - Train Accuracy: 0.9970982142857143\n",
      "\t\t\tVal Loss: 0.00660385558148846 - Val Accuracy: 0.902\n",
      "\n",
      "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1860, Loss 0.0003689849399961531\n",
      "\t\tRESULT EPOCH 54:\n",
      "\t\t\tTrain Loss: 0.00047049036823279625 - Train Accuracy: 0.9959821428571428\n",
      "\t\t\tVal Loss: 0.006259602669160813 - Val Accuracy: 0.888\n",
      "\n",
      "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1890, Loss 0.0006113286362960935\n",
      "\t\tTrain step - Step 1920, Loss 0.0004759064468089491\n",
      "\t\tRESULT EPOCH 55:\n",
      "\t\t\tTrain Loss: 0.00044221597075063204 - Train Accuracy: 0.9973214285714286\n",
      "\t\t\tVal Loss: 0.006139224220532924 - Val Accuracy: 0.888\n",
      "\n",
      "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1950, Loss 0.0002008878072956577\n",
      "\t\tRESULT EPOCH 56:\n",
      "\t\t\tTrain Loss: 0.0004403294201308329 - Train Accuracy: 0.9964285714285714\n",
      "\t\t\tVal Loss: 0.006245115480851382 - Val Accuracy: 0.894\n",
      "\n",
      "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1980, Loss 0.0003239777288399637\n",
      "\t\tRESULT EPOCH 57:\n",
      "\t\t\tTrain Loss: 0.0004885278068416353 - Train Accuracy: 0.9953125\n",
      "\t\t\tVal Loss: 0.005987236800137907 - Val Accuracy: 0.902\n",
      "\n",
      "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2010, Loss 0.00022808309586253017\n",
      "\t\tRESULT EPOCH 58:\n",
      "\t\t\tTrain Loss: 0.00038066193103856804 - Train Accuracy: 0.9977678571428571\n",
      "\t\t\tVal Loss: 0.006517216039355844 - Val Accuracy: 0.894\n",
      "\n",
      "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2040, Loss 0.0003647490811999887\n",
      "\t\tRESULT EPOCH 59:\n",
      "\t\t\tTrain Loss: 0.0003559794306056574 - Train Accuracy: 0.9977678571428571\n",
      "\t\t\tVal Loss: 0.006614120095036924 - Val Accuracy: 0.904\n",
      "\n",
      "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2070, Loss 0.00020992360077798367\n",
      "\t\tRESULT EPOCH 60:\n",
      "\t\t\tTrain Loss: 0.00033617145880790694 - Train Accuracy: 0.9982142857142857\n",
      "\t\t\tVal Loss: 0.0059843582566827536 - Val Accuracy: 0.904\n",
      "\n",
      "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2100, Loss 0.0003279490629211068\n",
      "\t\tTrain step - Step 2130, Loss 0.0002374301984673366\n",
      "\t\tRESULT EPOCH 61:\n",
      "\t\t\tTrain Loss: 0.0003378120342469109 - Train Accuracy: 0.9982142857142857\n",
      "\t\t\tVal Loss: 0.006069393071811646 - Val Accuracy: 0.9\n",
      "\n",
      "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2160, Loss 0.00030153722036629915\n",
      "\t\tRESULT EPOCH 62:\n",
      "\t\t\tTrain Loss: 0.0003106464644328558 - Train Accuracy: 0.9988839285714286\n",
      "\t\t\tVal Loss: 0.006604528171010315 - Val Accuracy: 0.896\n",
      "\n",
      "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2190, Loss 0.00019645388238132\n",
      "\t\tRESULT EPOCH 63:\n",
      "\t\t\tTrain Loss: 0.0003839591651090554 - Train Accuracy: 0.9973214285714286\n",
      "\t\t\tVal Loss: 0.005399125337135047 - Val Accuracy: 0.918\n",
      "\n",
      "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2220, Loss 0.00020104236318729818\n",
      "\t\tRESULT EPOCH 64:\n",
      "\t\t\tTrain Loss: 0.00032187042566615026 - Train Accuracy: 0.9986607142857142\n",
      "\t\t\tVal Loss: 0.006159123731777072 - Val Accuracy: 0.904\n",
      "\n",
      "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2250, Loss 0.00035959493834525347\n",
      "\t\tRESULT EPOCH 65:\n",
      "\t\t\tTrain Loss: 0.0002788571141926306 - Train Accuracy: 0.9993303571428571\n",
      "\t\t\tVal Loss: 0.006251743296161294 - Val Accuracy: 0.892\n",
      "\n",
      "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2280, Loss 0.00031003940966911614\n",
      "\t\tRESULT EPOCH 66:\n",
      "\t\t\tTrain Loss: 0.00031269088171289434 - Train Accuracy: 0.9979910714285715\n",
      "\t\t\tVal Loss: 0.006071707583032548 - Val Accuracy: 0.898\n",
      "\n",
      "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2310, Loss 0.0009786688024178147\n",
      "\t\tTrain step - Step 2340, Loss 0.0007700000423938036\n",
      "\t\tRESULT EPOCH 67:\n",
      "\t\t\tTrain Loss: 0.0003266386521447982 - Train Accuracy: 0.9982142857142857\n",
      "\t\t\tVal Loss: 0.0060700265457853675 - Val Accuracy: 0.894\n",
      "\n",
      "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2370, Loss 0.00023154509835876524\n",
      "\t\tRESULT EPOCH 68:\n",
      "\t\t\tTrain Loss: 0.0002825154976952555 - Train Accuracy: 0.9984375\n",
      "\t\t\tVal Loss: 0.006459718104451895 - Val Accuracy: 0.894\n",
      "\n",
      "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2400, Loss 0.00021263599046505988\n",
      "\t\tRESULT EPOCH 69:\n",
      "\t\t\tTrain Loss: 0.00026930040496933675 - Train Accuracy: 0.9986607142857142\n",
      "\t\t\tVal Loss: 0.0060318707837723196 - Val Accuracy: 0.898\n",
      "\n",
      "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2430, Loss 0.00019205956778023392\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/63 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tRESULT EPOCH 70:\n",
      "\t\t\tTrain Loss: 0.00026598125321990147 - Train Accuracy: 0.9993303571428571\n",
      "\t\t\tVal Loss: 0.00600059813586995 - Val Accuracy: 0.898\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:02<00:00, 30.96it/s]\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "\tResults STAGE 8:\n",
      "\t\tTrain Mean Accuracy: 0.9298533163265307\n",
      "\t\tVal Mean Accuracy: 0.8129428571428572\n",
      "\t\tTest Accuracy: 0.111625\n",
      "\n",
      "STARTING FINE TUNING STAGE 9...\n",
      "\tSTARTING EPOCH 1 - LR=[2]...\n",
      "\t\tTrain step - Step 30, Loss 0.025606904178857803\n",
      "\t\tRESULT EPOCH 1:\n",
      "\t\t\tTrain Loss: 0.04367678271872657 - Train Accuracy: 0.33035714285714285\n",
      "\t\t\tVal Loss: 0.024348901584744453 - Val Accuracy: 0.45\n",
      "\n",
      "\tSTARTING EPOCH 2 - LR=[2]...\n",
      "\t\tTrain step - Step 60, Loss 0.014049653895199299\n",
      "\t\tRESULT EPOCH 2:\n",
      "\t\t\tTrain Loss: 0.016674259730747768 - Train Accuracy: 0.659375\n",
      "\t\t\tVal Loss: 0.014152058865875006 - Val Accuracy: 0.716\n",
      "\n",
      "\tSTARTING EPOCH 3 - LR=[2]...\n",
      "\t\tTrain step - Step 90, Loss 0.012568124569952488\n",
      "\t\tRESULT EPOCH 3:\n",
      "\t\t\tTrain Loss: 0.011943606526723929 - Train Accuracy: 0.7636160714285715\n",
      "\t\t\tVal Loss: 0.012530814157798886 - Val Accuracy: 0.768\n",
      "\n",
      "\tSTARTING EPOCH 4 - LR=[2]...\n",
      "\t\tTrain step - Step 120, Loss 0.009879707358777523\n",
      "\t\tRESULT EPOCH 4:\n",
      "\t\t\tTrain Loss: 0.009753074496984482 - Train Accuracy: 0.8138392857142858\n",
      "\t\t\tVal Loss: 0.013739864574745297 - Val Accuracy: 0.744\n",
      "\n",
      "\tSTARTING EPOCH 5 - LR=[2]...\n",
      "\t\tTrain step - Step 150, Loss 0.007305050268769264\n",
      "\t\tRESULT EPOCH 5:\n",
      "\t\t\tTrain Loss: 0.009001860089067901 - Train Accuracy: 0.83125\n",
      "\t\t\tVal Loss: 0.01177806151099503 - Val Accuracy: 0.766\n",
      "\n",
      "\tSTARTING EPOCH 6 - LR=[2]...\n",
      "\t\tTrain step - Step 180, Loss 0.007454793434590101\n",
      "\t\tRESULT EPOCH 6:\n",
      "\t\t\tTrain Loss: 0.0077869856730103494 - Train Accuracy: 0.8595982142857143\n",
      "\t\t\tVal Loss: 0.012992917443625629 - Val Accuracy: 0.742\n",
      "\n",
      "\tSTARTING EPOCH 7 - LR=[2]...\n",
      "\t\tTrain step - Step 210, Loss 0.005075329449027777\n",
      "\t\tTrain step - Step 240, Loss 0.006020566914230585\n",
      "\t\tRESULT EPOCH 7:\n",
      "\t\t\tTrain Loss: 0.007045580792639936 - Train Accuracy: 0.8714285714285714\n",
      "\t\t\tVal Loss: 0.013555586570873857 - Val Accuracy: 0.758\n",
      "\n",
      "\tSTARTING EPOCH 8 - LR=[2]...\n",
      "\t\tTrain step - Step 270, Loss 0.008568878285586834\n",
      "\t\tRESULT EPOCH 8:\n",
      "\t\t\tTrain Loss: 0.006294227976884161 - Train Accuracy: 0.8870535714285714\n",
      "\t\t\tVal Loss: 0.013088376261293888 - Val Accuracy: 0.77\n",
      "\n",
      "\tSTARTING EPOCH 9 - LR=[2]...\n",
      "\t\tTrain step - Step 300, Loss 0.005906452424824238\n",
      "\t\tRESULT EPOCH 9:\n",
      "\t\t\tTrain Loss: 0.006003104389778205 - Train Accuracy: 0.8944196428571428\n",
      "\t\t\tVal Loss: 0.00920118176145479 - Val Accuracy: 0.83\n",
      "\n",
      "\tSTARTING EPOCH 10 - LR=[2]...\n",
      "\t\tTrain step - Step 330, Loss 0.005334113258868456\n",
      "\t\tRESULT EPOCH 10:\n",
      "\t\t\tTrain Loss: 0.005823997268453241 - Train Accuracy: 0.8924107142857143\n",
      "\t\t\tVal Loss: 0.009216129896230996 - Val Accuracy: 0.826\n",
      "\n",
      "\tSTARTING EPOCH 11 - LR=[2]...\n",
      "\t\tTrain step - Step 360, Loss 0.0036928390618413687\n",
      "\t\tRESULT EPOCH 11:\n",
      "\t\t\tTrain Loss: 0.005610543722286821 - Train Accuracy: 0.9022321428571428\n",
      "\t\t\tVal Loss: 0.013244478264823556 - Val Accuracy: 0.764\n",
      "\n",
      "\tSTARTING EPOCH 12 - LR=[2]...\n",
      "\t\tTrain step - Step 390, Loss 0.004796728026121855\n",
      "\t\tRESULT EPOCH 12:\n",
      "\t\t\tTrain Loss: 0.0051743165656392065 - Train Accuracy: 0.9091517857142857\n",
      "\t\t\tVal Loss: 0.008877288666553795 - Val Accuracy: 0.832\n",
      "\n",
      "\tSTARTING EPOCH 13 - LR=[2]...\n",
      "\t\tTrain step - Step 420, Loss 0.005276782438158989\n",
      "\t\tTrain step - Step 450, Loss 0.004552037455141544\n",
      "\t\tRESULT EPOCH 13:\n",
      "\t\t\tTrain Loss: 0.004965702810191683 - Train Accuracy: 0.9149553571428571\n",
      "\t\t\tVal Loss: 0.012102348497137427 - Val Accuracy: 0.8\n",
      "\n",
      "\tSTARTING EPOCH 14 - LR=[2]...\n",
      "\t\tTrain step - Step 480, Loss 0.004955487325787544\n",
      "\t\tRESULT EPOCH 14:\n",
      "\t\t\tTrain Loss: 0.00476281374825963 - Train Accuracy: 0.9183035714285714\n",
      "\t\t\tVal Loss: 0.009816201170906425 - Val Accuracy: 0.824\n",
      "\n",
      "\tSTARTING EPOCH 15 - LR=[2]...\n",
      "\t\tTrain step - Step 510, Loss 0.003217147896066308\n",
      "\t\tRESULT EPOCH 15:\n",
      "\t\t\tTrain Loss: 0.004231545182743243 - Train Accuracy: 0.9254464285714286\n",
      "\t\t\tVal Loss: 0.012396139791235328 - Val Accuracy: 0.794\n",
      "\n",
      "\tSTARTING EPOCH 16 - LR=[2]...\n",
      "\t\tTrain step - Step 540, Loss 0.002310799667611718\n",
      "\t\tRESULT EPOCH 16:\n",
      "\t\t\tTrain Loss: 0.003687443018757871 - Train Accuracy: 0.9363839285714286\n",
      "\t\t\tVal Loss: 0.00985823292285204 - Val Accuracy: 0.85\n",
      "\n",
      "\tSTARTING EPOCH 17 - LR=[2]...\n",
      "\t\tTrain step - Step 570, Loss 0.004757081624120474\n",
      "\t\tRESULT EPOCH 17:\n",
      "\t\t\tTrain Loss: 0.0036824331053399613 - Train Accuracy: 0.9370535714285714\n",
      "\t\t\tVal Loss: 0.011168565950356424 - Val Accuracy: 0.794\n",
      "\n",
      "\tSTARTING EPOCH 18 - LR=[2]...\n",
      "\t\tTrain step - Step 600, Loss 0.004139256197959185\n",
      "\t\tRESULT EPOCH 18:\n",
      "\t\t\tTrain Loss: 0.003990260395221412 - Train Accuracy: 0.9303571428571429\n",
      "\t\t\tVal Loss: 0.014764860272407532 - Val Accuracy: 0.774\n",
      "\n",
      "\tSTARTING EPOCH 19 - LR=[2]...\n",
      "\t\tTrain step - Step 630, Loss 0.0028489374089986086\n",
      "\t\tTrain step - Step 660, Loss 0.004338711500167847\n",
      "\t\tRESULT EPOCH 19:\n",
      "\t\t\tTrain Loss: 0.004290148412941822 - Train Accuracy: 0.9272321428571428\n",
      "\t\t\tVal Loss: 0.009221898159012198 - Val Accuracy: 0.808\n",
      "\n",
      "\tSTARTING EPOCH 20 - LR=[2]...\n",
      "\t\tTrain step - Step 690, Loss 0.002733142813667655\n",
      "\t\tRESULT EPOCH 20:\n",
      "\t\t\tTrain Loss: 0.003870985996244209 - Train Accuracy: 0.9323660714285714\n",
      "\t\t\tVal Loss: 0.010431071044877172 - Val Accuracy: 0.82\n",
      "\n",
      "\tSTARTING EPOCH 21 - LR=[2]...\n",
      "\t\tTrain step - Step 720, Loss 0.0059244511649012566\n",
      "\t\tRESULT EPOCH 21:\n",
      "\t\t\tTrain Loss: 0.0036016754107549786 - Train Accuracy: 0.9368303571428571\n",
      "\t\t\tVal Loss: 0.0146068693138659 - Val Accuracy: 0.77\n",
      "\n",
      "\tSTARTING EPOCH 22 - LR=[2]...\n",
      "\t\tTrain step - Step 750, Loss 0.004171081818640232\n",
      "\t\tRESULT EPOCH 22:\n",
      "\t\t\tTrain Loss: 0.0032110445534012147 - Train Accuracy: 0.9448660714285714\n",
      "\t\t\tVal Loss: 0.00870795943774283 - Val Accuracy: 0.844\n",
      "\n",
      "\tSTARTING EPOCH 23 - LR=[2]...\n",
      "\t\tTrain step - Step 780, Loss 0.002766111632809043\n",
      "\t\tRESULT EPOCH 23:\n",
      "\t\t\tTrain Loss: 0.0031338986142405443 - Train Accuracy: 0.9482142857142857\n",
      "\t\t\tVal Loss: 0.013537062332034111 - Val Accuracy: 0.804\n",
      "\n",
      "\tSTARTING EPOCH 24 - LR=[2]...\n",
      "\t\tTrain step - Step 810, Loss 0.0030395882204174995\n",
      "\t\tRESULT EPOCH 24:\n",
      "\t\t\tTrain Loss: 0.0033617147843220405 - Train Accuracy: 0.9412946428571428\n",
      "\t\t\tVal Loss: 0.008221381693147123 - Val Accuracy: 0.874\n",
      "\n",
      "\tSTARTING EPOCH 25 - LR=[2]...\n",
      "\t\tTrain step - Step 840, Loss 0.002251364290714264\n",
      "\t\tTrain step - Step 870, Loss 0.004342598374933004\n",
      "\t\tRESULT EPOCH 25:\n",
      "\t\t\tTrain Loss: 0.0031513195717707276 - Train Accuracy: 0.9428571428571428\n",
      "\t\t\tVal Loss: 0.011274083517491817 - Val Accuracy: 0.808\n",
      "\n",
      "\tSTARTING EPOCH 26 - LR=[2]...\n",
      "\t\tTrain step - Step 900, Loss 0.0030999728478491306\n",
      "\t\tRESULT EPOCH 26:\n",
      "\t\t\tTrain Loss: 0.0029950432678950683 - Train Accuracy: 0.9486607142857143\n",
      "\t\t\tVal Loss: 0.010205885511822999 - Val Accuracy: 0.832\n",
      "\n",
      "\tSTARTING EPOCH 27 - LR=[2]...\n",
      "\t\tTrain step - Step 930, Loss 0.0027678622864186764\n",
      "\t\tRESULT EPOCH 27:\n",
      "\t\t\tTrain Loss: 0.0028296293025570256 - Train Accuracy: 0.9535714285714286\n",
      "\t\t\tVal Loss: 0.01791439251974225 - Val Accuracy: 0.73\n",
      "\n",
      "\tSTARTING EPOCH 28 - LR=[2]...\n",
      "\t\tTrain step - Step 960, Loss 0.003361594630405307\n",
      "\t\tRESULT EPOCH 28:\n",
      "\t\t\tTrain Loss: 0.0028661446679117426 - Train Accuracy: 0.9542410714285714\n",
      "\t\t\tVal Loss: 0.007550917332991958 - Val Accuracy: 0.868\n",
      "\n",
      "\tSTARTING EPOCH 29 - LR=[2]...\n",
      "\t\tTrain step - Step 990, Loss 0.0035224836319684982\n",
      "\t\tRESULT EPOCH 29:\n",
      "\t\t\tTrain Loss: 0.002675723730187331 - Train Accuracy: 0.9553571428571429\n",
      "\t\t\tVal Loss: 0.008242869633249938 - Val Accuracy: 0.854\n",
      "\n",
      "\tSTARTING EPOCH 30 - LR=[2]...\n",
      "\t\tTrain step - Step 1020, Loss 0.0013335432158783078\n",
      "\t\tRESULT EPOCH 30:\n",
      "\t\t\tTrain Loss: 0.002578803782151746 - Train Accuracy: 0.9600446428571429\n",
      "\t\t\tVal Loss: 0.012041752226650715 - Val Accuracy: 0.804\n",
      "\n",
      "\tSTARTING EPOCH 31 - LR=[2]...\n",
      "\t\tTrain step - Step 1050, Loss 0.00203054235316813\n",
      "\t\tTrain step - Step 1080, Loss 0.0021142633631825447\n",
      "\t\tRESULT EPOCH 31:\n",
      "\t\t\tTrain Loss: 0.002279421321249434 - Train Accuracy: 0.9667410714285715\n",
      "\t\t\tVal Loss: 0.017783686402253807 - Val Accuracy: 0.752\n",
      "\n",
      "\tSTARTING EPOCH 32 - LR=[2]...\n",
      "\t\tTrain step - Step 1110, Loss 0.0014395167818292975\n",
      "\t\tRESULT EPOCH 32:\n",
      "\t\t\tTrain Loss: 0.0024220092321879097 - Train Accuracy: 0.9582589285714286\n",
      "\t\t\tVal Loss: 0.008770771382842213 - Val Accuracy: 0.85\n",
      "\n",
      "\tSTARTING EPOCH 33 - LR=[2]...\n",
      "\t\tTrain step - Step 1140, Loss 0.0023382939398288727\n",
      "\t\tRESULT EPOCH 33:\n",
      "\t\t\tTrain Loss: 0.002447561841524605 - Train Accuracy: 0.9584821428571428\n",
      "\t\t\tVal Loss: 0.014064533170312643 - Val Accuracy: 0.8\n",
      "\n",
      "\tSTARTING EPOCH 34 - LR=[2]...\n",
      "\t\tTrain step - Step 1170, Loss 0.0040272981859743595\n",
      "\t\tRESULT EPOCH 34:\n",
      "\t\t\tTrain Loss: 0.002637106373107859 - Train Accuracy: 0.9558035714285714\n",
      "\t\t\tVal Loss: 0.010126466862857342 - Val Accuracy: 0.828\n",
      "\n",
      "\tSTARTING EPOCH 35 - LR=[2]...\n",
      "\t\tTrain step - Step 1200, Loss 0.0017742335330694914\n",
      "\t\tRESULT EPOCH 35:\n",
      "\t\t\tTrain Loss: 0.0024883163860067725 - Train Accuracy: 0.9553571428571429\n",
      "\t\t\tVal Loss: 0.012142838328145444 - Val Accuracy: 0.804\n",
      "\n",
      "\tSTARTING EPOCH 36 - LR=[2]...\n",
      "\t\tTrain step - Step 1230, Loss 0.0026370971463620663\n",
      "\t\tRESULT EPOCH 36:\n",
      "\t\t\tTrain Loss: 0.002922834306290107 - Train Accuracy: 0.9482142857142857\n",
      "\t\t\tVal Loss: 0.010763639700599015 - Val Accuracy: 0.822\n",
      "\n",
      "\tSTARTING EPOCH 37 - LR=[2]...\n",
      "\t\tTrain step - Step 1260, Loss 0.0035333011765033007\n",
      "\t\tTrain step - Step 1290, Loss 0.002019645879045129\n",
      "\t\tRESULT EPOCH 37:\n",
      "\t\t\tTrain Loss: 0.002720085850783757 - Train Accuracy: 0.9540178571428571\n",
      "\t\t\tVal Loss: 0.01731450203806162 - Val Accuracy: 0.76\n",
      "\n",
      "\tSTARTING EPOCH 38 - LR=[2]...\n",
      "\t\tTrain step - Step 1320, Loss 0.0030281376093626022\n",
      "\t\tRESULT EPOCH 38:\n",
      "\t\t\tTrain Loss: 0.0026892764094684804 - Train Accuracy: 0.9522321428571429\n",
      "\t\t\tVal Loss: 0.013672185712493956 - Val Accuracy: 0.784\n",
      "\n",
      "\tSTARTING EPOCH 39 - LR=[2]...\n",
      "\t\tTrain step - Step 1350, Loss 0.0016143245156854391\n",
      "\t\tRESULT EPOCH 39:\n",
      "\t\t\tTrain Loss: 0.0020075773022004534 - Train Accuracy: 0.9662946428571428\n",
      "\t\t\tVal Loss: 0.009704558760859072 - Val Accuracy: 0.838\n",
      "\n",
      "\tSTARTING EPOCH 40 - LR=[2]...\n",
      "\t\tTrain step - Step 1380, Loss 0.0011982235591858625\n",
      "\t\tRESULT EPOCH 40:\n",
      "\t\t\tTrain Loss: 0.0020298916696836907 - Train Accuracy: 0.9658482142857143\n",
      "\t\t\tVal Loss: 0.0101514239795506 - Val Accuracy: 0.862\n",
      "\n",
      "\tSTARTING EPOCH 41 - LR=[2]...\n",
      "\t\tTrain step - Step 1410, Loss 0.001797139411792159\n",
      "\t\tRESULT EPOCH 41:\n",
      "\t\t\tTrain Loss: 0.0019166289712302387 - Train Accuracy: 0.9712053571428572\n",
      "\t\t\tVal Loss: 0.009124987409450114 - Val Accuracy: 0.842\n",
      "\n",
      "\tSTARTING EPOCH 42 - LR=[2]...\n",
      "\t\tTrain step - Step 1440, Loss 0.001658196677453816\n",
      "\t\tRESULT EPOCH 42:\n",
      "\t\t\tTrain Loss: 0.0016922692202829888 - Train Accuracy: 0.9756696428571429\n",
      "\t\t\tVal Loss: 0.016716805403120816 - Val Accuracy: 0.766\n",
      "\n",
      "\tSTARTING EPOCH 43 - LR=[2]...\n",
      "\t\tTrain step - Step 1470, Loss 0.001490660710260272\n",
      "\t\tTrain step - Step 1500, Loss 0.0015608306275680661\n",
      "\t\tRESULT EPOCH 43:\n",
      "\t\t\tTrain Loss: 0.002117598083402429 - Train Accuracy: 0.965625\n",
      "\t\t\tVal Loss: 0.00986575533170253 - Val Accuracy: 0.846\n",
      "\n",
      "\tSTARTING EPOCH 44 - LR=[2]...\n",
      "\t\tTrain step - Step 1530, Loss 0.002592842560261488\n",
      "\t\tRESULT EPOCH 44:\n",
      "\t\t\tTrain Loss: 0.0022284654368247303 - Train Accuracy: 0.9649553571428572\n",
      "\t\t\tVal Loss: 0.013135699089616537 - Val Accuracy: 0.808\n",
      "\n",
      "\tSTARTING EPOCH 45 - LR=[2]...\n",
      "\t\tTrain step - Step 1560, Loss 0.003927519079297781\n",
      "\t\tRESULT EPOCH 45:\n",
      "\t\t\tTrain Loss: 0.0021353204784515713 - Train Accuracy: 0.9649553571428572\n",
      "\t\t\tVal Loss: 0.008613095618784428 - Val Accuracy: 0.844\n",
      "\n",
      "\tSTARTING EPOCH 46 - LR=[2]...\n",
      "\t\tTrain step - Step 1590, Loss 0.0027513836976140738\n",
      "\t\tRESULT EPOCH 46:\n",
      "\t\t\tTrain Loss: 0.0016257184973385718 - Train Accuracy: 0.9758928571428571\n",
      "\t\t\tVal Loss: 0.012450063251890242 - Val Accuracy: 0.812\n",
      "\n",
      "\tSTARTING EPOCH 47 - LR=[2]...\n",
      "\t\tTrain step - Step 1620, Loss 0.0024173459969460964\n",
      "\t\tRESULT EPOCH 47:\n",
      "\t\t\tTrain Loss: 0.0017269449691022082 - Train Accuracy: 0.9741071428571428\n",
      "\t\t\tVal Loss: 0.011954093468375504 - Val Accuracy: 0.812\n",
      "\n",
      "\tSTARTING EPOCH 48 - LR=[2]...\n",
      "\t\tTrain step - Step 1650, Loss 0.0013322249287739396\n",
      "\t\tRESULT EPOCH 48:\n",
      "\t\t\tTrain Loss: 0.0021342122794262 - Train Accuracy: 0.9625\n",
      "\t\t\tVal Loss: 0.01256914483383298 - Val Accuracy: 0.8\n",
      "\n",
      "\tSTARTING EPOCH 49 - LR=[2]...\n",
      "\t\tTrain step - Step 1680, Loss 0.0010894477600231767\n",
      "\t\tTrain step - Step 1710, Loss 0.003494739066809416\n",
      "\t\tRESULT EPOCH 49:\n",
      "\t\t\tTrain Loss: 0.002269675419665873 - Train Accuracy: 0.9631696428571429\n",
      "\t\t\tVal Loss: 0.016661596891935915 - Val Accuracy: 0.77\n",
      "\n",
      "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1740, Loss 0.000999744632281363\n",
      "\t\tRESULT EPOCH 50:\n",
      "\t\t\tTrain Loss: 0.0014244797972163983 - Train Accuracy: 0.9819196428571428\n",
      "\t\t\tVal Loss: 0.005868801032193005 - Val Accuracy: 0.9\n",
      "\n",
      "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1770, Loss 0.0015782926930114627\n",
      "\t\tRESULT EPOCH 51:\n",
      "\t\t\tTrain Loss: 0.0007617314894949751 - Train Accuracy: 0.990625\n",
      "\t\t\tVal Loss: 0.005862781486939639 - Val Accuracy: 0.912\n",
      "\n",
      "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1800, Loss 0.00033295995672233403\n",
      "\t\tRESULT EPOCH 52:\n",
      "\t\t\tTrain Loss: 0.0005093440783509452 - Train Accuracy: 0.9953125\n",
      "\t\t\tVal Loss: 0.005341384676285088 - Val Accuracy: 0.918\n",
      "\n",
      "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1830, Loss 0.0003028708742931485\n",
      "\t\tRESULT EPOCH 53:\n",
      "\t\t\tTrain Loss: 0.0005293067153875849 - Train Accuracy: 0.9950892857142857\n",
      "\t\t\tVal Loss: 0.00560776999918744 - Val Accuracy: 0.922\n",
      "\n",
      "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1860, Loss 0.0004846047959290445\n",
      "\t\tRESULT EPOCH 54:\n",
      "\t\t\tTrain Loss: 0.0004527188072513257 - Train Accuracy: 0.9964285714285714\n",
      "\t\t\tVal Loss: 0.00548153615090996 - Val Accuracy: 0.922\n",
      "\n",
      "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1890, Loss 0.0003851190849673003\n",
      "\t\tTrain step - Step 1920, Loss 0.00032757731969468296\n",
      "\t\tRESULT EPOCH 55:\n",
      "\t\t\tTrain Loss: 0.0003866337422680642 - Train Accuracy: 0.9977678571428571\n",
      "\t\t\tVal Loss: 0.005603924102615565 - Val Accuracy: 0.914\n",
      "\n",
      "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1950, Loss 0.00023061303363647312\n",
      "\t\tRESULT EPOCH 56:\n",
      "\t\t\tTrain Loss: 0.00033245287444775125 - Train Accuracy: 0.9982142857142857\n",
      "\t\t\tVal Loss: 0.0055413139052689075 - Val Accuracy: 0.922\n",
      "\n",
      "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1980, Loss 0.00031498423777520657\n",
      "\t\tRESULT EPOCH 57:\n",
      "\t\t\tTrain Loss: 0.0003714424017484167 - Train Accuracy: 0.9970982142857143\n",
      "\t\t\tVal Loss: 0.00538866117130965 - Val Accuracy: 0.918\n",
      "\n",
      "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2010, Loss 0.00025898570311255753\n",
      "\t\tRESULT EPOCH 58:\n",
      "\t\t\tTrain Loss: 0.0003291064736133974 - Train Accuracy: 0.9986607142857142\n",
      "\t\t\tVal Loss: 0.005225994158536196 - Val Accuracy: 0.918\n",
      "\n",
      "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2040, Loss 0.00028133264277130365\n",
      "\t\tRESULT EPOCH 59:\n",
      "\t\t\tTrain Loss: 0.0003465691124022539 - Train Accuracy: 0.9970982142857143\n",
      "\t\t\tVal Loss: 0.004898241371847689 - Val Accuracy: 0.92\n",
      "\n",
      "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2070, Loss 0.00021007366012781858\n",
      "\t\tRESULT EPOCH 60:\n",
      "\t\t\tTrain Loss: 0.0002675731554128496 - Train Accuracy: 0.9993303571428571\n",
      "\t\t\tVal Loss: 0.0054494928335770965 - Val Accuracy: 0.906\n",
      "\n",
      "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2100, Loss 0.00039067145553417504\n",
      "\t\tTrain step - Step 2130, Loss 0.00015381892444565892\n",
      "\t\tRESULT EPOCH 61:\n",
      "\t\t\tTrain Loss: 0.00027957256118367826 - Train Accuracy: 0.9988839285714286\n",
      "\t\t\tVal Loss: 0.0055988122476264834 - Val Accuracy: 0.914\n",
      "\n",
      "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2160, Loss 0.0004113077884539962\n",
      "\t\tRESULT EPOCH 62:\n",
      "\t\t\tTrain Loss: 0.0003024623367569542 - Train Accuracy: 0.9984375\n",
      "\t\t\tVal Loss: 0.0057324632070958614 - Val Accuracy: 0.92\n",
      "\n",
      "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2190, Loss 0.0004047780530527234\n",
      "\t\tRESULT EPOCH 63:\n",
      "\t\t\tTrain Loss: 0.0002609650421488498 - Train Accuracy: 0.9995535714285714\n",
      "\t\t\tVal Loss: 0.005820627906359732 - Val Accuracy: 0.914\n",
      "\n",
      "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2220, Loss 0.00016525336832273751\n",
      "\t\tRESULT EPOCH 64:\n",
      "\t\t\tTrain Loss: 0.00024331489569574062 - Train Accuracy: 0.9993303571428571\n",
      "\t\t\tVal Loss: 0.004548964323475957 - Val Accuracy: 0.93\n",
      "\n",
      "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2250, Loss 0.0001792719413060695\n",
      "\t\tRESULT EPOCH 65:\n",
      "\t\t\tTrain Loss: 0.0002365280603823651 - Train Accuracy: 0.9988839285714286\n",
      "\t\t\tVal Loss: 0.005731021519750357 - Val Accuracy: 0.912\n",
      "\n",
      "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2280, Loss 0.00023093674099072814\n",
      "\t\tRESULT EPOCH 66:\n",
      "\t\t\tTrain Loss: 0.0002384299728354173 - Train Accuracy: 0.9993303571428571\n",
      "\t\t\tVal Loss: 0.005774367251433432 - Val Accuracy: 0.92\n",
      "\n",
      "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2310, Loss 0.00023225373297464103\n",
      "\t\tTrain step - Step 2340, Loss 0.00044706519111059606\n",
      "\t\tRESULT EPOCH 67:\n",
      "\t\t\tTrain Loss: 0.0002570317731754455 - Train Accuracy: 0.9988839285714286\n",
      "\t\t\tVal Loss: 0.006396826647687703 - Val Accuracy: 0.918\n",
      "\n",
      "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2370, Loss 0.0002573227393440902\n",
      "\t\tRESULT EPOCH 68:\n",
      "\t\t\tTrain Loss: 0.0002272597131585436 - Train Accuracy: 0.9995535714285714\n",
      "\t\t\tVal Loss: 0.0057796406908892095 - Val Accuracy: 0.912\n",
      "\n",
      "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2400, Loss 0.00041201856220141053\n",
      "\t\tRESULT EPOCH 69:\n",
      "\t\t\tTrain Loss: 0.0002646290726261213 - Train Accuracy: 0.9977678571428571\n",
      "\t\t\tVal Loss: 0.005286388855893165 - Val Accuracy: 0.914\n",
      "\n",
      "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2430, Loss 0.0002443311386741698\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/71 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tRESULT EPOCH 70:\n",
      "\t\t\tTrain Loss: 0.00022547760329741452 - Train Accuracy: 0.9995535714285714\n",
      "\t\t\tVal Loss: 0.0056691456702537835 - Val Accuracy: 0.91\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:02<00:00, 30.93it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "\tResults STAGE 9:\n",
      "\t\tTrain Mean Accuracy: 0.9394260204081635\n",
      "\t\tVal Mean Accuracy: 0.8321999999999999\n",
      "\t\tTest Accuracy: 0.10166666666666667\n",
      "\n",
      "STARTING FINE TUNING STAGE 10...\n",
      "\tSTARTING EPOCH 1 - LR=[2]...\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tTrain step - Step 30, Loss 0.02250906266272068\n",
      "\t\tRESULT EPOCH 1:\n",
      "\t\t\tTrain Loss: 0.04503700951380389 - Train Accuracy: 0.2676339285714286\n",
      "\t\t\tVal Loss: 0.02617840562015772 - Val Accuracy: 0.428\n",
      "\n",
      "\tSTARTING EPOCH 2 - LR=[2]...\n",
      "\t\tTrain step - Step 60, Loss 0.017871322110295296\n",
      "\t\tRESULT EPOCH 2:\n",
      "\t\t\tTrain Loss: 0.017915354961795468 - Train Accuracy: 0.6058035714285714\n",
      "\t\t\tVal Loss: 0.015315814409404993 - Val Accuracy: 0.68\n",
      "\n",
      "\tSTARTING EPOCH 3 - LR=[2]...\n",
      "\t\tTrain step - Step 90, Loss 0.014208857901394367\n",
      "\t\tRESULT EPOCH 3:\n",
      "\t\t\tTrain Loss: 0.013585427563105311 - Train Accuracy: 0.7055803571428572\n",
      "\t\t\tVal Loss: 0.014087773393839598 - Val Accuracy: 0.716\n",
      "\n",
      "\tSTARTING EPOCH 4 - LR=[2]...\n",
      "\t\tTrain step - Step 120, Loss 0.011421659030020237\n",
      "\t\tRESULT EPOCH 4:\n",
      "\t\t\tTrain Loss: 0.011185307348413127 - Train Accuracy: 0.7752232142857143\n",
      "\t\t\tVal Loss: 0.013490736484527588 - Val Accuracy: 0.724\n",
      "\n",
      "\tSTARTING EPOCH 5 - LR=[2]...\n",
      "\t\tTrain step - Step 150, Loss 0.00874096155166626\n",
      "\t\tRESULT EPOCH 5:\n",
      "\t\t\tTrain Loss: 0.010368267340319497 - Train Accuracy: 0.7816964285714286\n",
      "\t\t\tVal Loss: 0.015550140291452408 - Val Accuracy: 0.646\n",
      "\n",
      "\tSTARTING EPOCH 6 - LR=[2]...\n",
      "\t\tTrain step - Step 180, Loss 0.007714740000665188\n",
      "\t\tRESULT EPOCH 6:\n",
      "\t\t\tTrain Loss: 0.008918832588408674 - Train Accuracy: 0.8299107142857143\n",
      "\t\t\tVal Loss: 0.012544890400022268 - Val Accuracy: 0.75\n",
      "\n",
      "\tSTARTING EPOCH 7 - LR=[2]...\n",
      "\t\tTrain step - Step 210, Loss 0.009014394134283066\n",
      "\t\tTrain step - Step 240, Loss 0.008241859264671803\n",
      "\t\tRESULT EPOCH 7:\n",
      "\t\t\tTrain Loss: 0.008092301259083407 - Train Accuracy: 0.8479910714285714\n",
      "\t\t\tVal Loss: 0.016031578183174133 - Val Accuracy: 0.662\n",
      "\n",
      "\tSTARTING EPOCH 8 - LR=[2]...\n",
      "\t\tTrain step - Step 270, Loss 0.00533893471583724\n",
      "\t\tRESULT EPOCH 8:\n",
      "\t\t\tTrain Loss: 0.007180220074951648 - Train Accuracy: 0.8674107142857143\n",
      "\t\t\tVal Loss: 0.013213835307396948 - Val Accuracy: 0.742\n",
      "\n",
      "\tSTARTING EPOCH 9 - LR=[2]...\n",
      "\t\tTrain step - Step 300, Loss 0.008545379154384136\n",
      "\t\tRESULT EPOCH 9:\n",
      "\t\t\tTrain Loss: 0.006964930279978684 - Train Accuracy: 0.8707589285714286\n",
      "\t\t\tVal Loss: 0.010508904466405511 - Val Accuracy: 0.794\n",
      "\n",
      "\tSTARTING EPOCH 10 - LR=[2]...\n",
      "\t\tTrain step - Step 330, Loss 0.00700708432123065\n",
      "\t\tRESULT EPOCH 10:\n",
      "\t\t\tTrain Loss: 0.00719170356169343 - Train Accuracy: 0.8660714285714286\n",
      "\t\t\tVal Loss: 0.01102639571763575 - Val Accuracy: 0.782\n",
      "\n",
      "\tSTARTING EPOCH 11 - LR=[2]...\n",
      "\t\tTrain step - Step 360, Loss 0.0048230718821287155\n",
      "\t\tRESULT EPOCH 11:\n",
      "\t\t\tTrain Loss: 0.006104572410030025 - Train Accuracy: 0.8888392857142857\n",
      "\t\t\tVal Loss: 0.010735061136074364 - Val Accuracy: 0.804\n",
      "\n",
      "\tSTARTING EPOCH 12 - LR=[2]...\n",
      "\t\tTrain step - Step 390, Loss 0.0035954106133431196\n",
      "\t\tRESULT EPOCH 12:\n",
      "\t\t\tTrain Loss: 0.005680251181391733 - Train Accuracy: 0.9004464285714285\n",
      "\t\t\tVal Loss: 0.013111824519000947 - Val Accuracy: 0.736\n",
      "\n",
      "\tSTARTING EPOCH 13 - LR=[2]...\n",
      "\t\tTrain step - Step 420, Loss 0.005030387546867132\n",
      "\t\tTrain step - Step 450, Loss 0.005944753065705299\n",
      "\t\tRESULT EPOCH 13:\n",
      "\t\t\tTrain Loss: 0.005169472364442689 - Train Accuracy: 0.9113839285714286\n",
      "\t\t\tVal Loss: 0.010458306060172617 - Val Accuracy: 0.794\n",
      "\n",
      "\tSTARTING EPOCH 14 - LR=[2]...\n",
      "\t\tTrain step - Step 480, Loss 0.002890456933528185\n",
      "\t\tRESULT EPOCH 14:\n",
      "\t\t\tTrain Loss: 0.005532748797642333 - Train Accuracy: 0.9017857142857143\n",
      "\t\t\tVal Loss: 0.01247117028106004 - Val Accuracy: 0.782\n",
      "\n",
      "\tSTARTING EPOCH 15 - LR=[2]...\n",
      "\t\tTrain step - Step 510, Loss 0.007224678061902523\n",
      "\t\tRESULT EPOCH 15:\n",
      "\t\t\tTrain Loss: 0.005521557919148888 - Train Accuracy: 0.8975446428571429\n",
      "\t\t\tVal Loss: 0.010816007852554321 - Val Accuracy: 0.8\n",
      "\n",
      "\tSTARTING EPOCH 16 - LR=[2]...\n",
      "\t\tTrain step - Step 540, Loss 0.006902158260345459\n",
      "\t\tRESULT EPOCH 16:\n",
      "\t\t\tTrain Loss: 0.005134412772687418 - Train Accuracy: 0.9075892857142858\n",
      "\t\t\tVal Loss: 0.014919382520020008 - Val Accuracy: 0.74\n",
      "\n",
      "\tSTARTING EPOCH 17 - LR=[2]...\n",
      "\t\tTrain step - Step 570, Loss 0.0033709630370140076\n",
      "\t\tRESULT EPOCH 17:\n",
      "\t\t\tTrain Loss: 0.004494775958093149 - Train Accuracy: 0.9196428571428571\n",
      "\t\t\tVal Loss: 0.0106356066535227 - Val Accuracy: 0.816\n",
      "\n",
      "\tSTARTING EPOCH 18 - LR=[2]...\n",
      "\t\tTrain step - Step 600, Loss 0.0030245620291680098\n",
      "\t\tRESULT EPOCH 18:\n",
      "\t\t\tTrain Loss: 0.0044733845429228885 - Train Accuracy: 0.9169642857142857\n",
      "\t\t\tVal Loss: 0.016107463045045733 - Val Accuracy: 0.722\n",
      "\n",
      "\tSTARTING EPOCH 19 - LR=[2]...\n",
      "\t\tTrain step - Step 630, Loss 0.005083505995571613\n",
      "\t\tTrain step - Step 660, Loss 0.003459483850747347\n",
      "\t\tRESULT EPOCH 19:\n",
      "\t\t\tTrain Loss: 0.0045331535328711784 - Train Accuracy: 0.9194196428571428\n",
      "\t\t\tVal Loss: 0.015575779718346894 - Val Accuracy: 0.714\n",
      "\n",
      "\tSTARTING EPOCH 20 - LR=[2]...\n",
      "\t\tTrain step - Step 690, Loss 0.0033554192632436752\n",
      "\t\tRESULT EPOCH 20:\n",
      "\t\t\tTrain Loss: 0.0040611054016543285 - Train Accuracy: 0.9247767857142857\n",
      "\t\t\tVal Loss: 0.014066262869164348 - Val Accuracy: 0.78\n",
      "\n",
      "\tSTARTING EPOCH 21 - LR=[2]...\n",
      "\t\tTrain step - Step 720, Loss 0.0038563269190490246\n",
      "\t\tRESULT EPOCH 21:\n",
      "\t\t\tTrain Loss: 0.004205053106748632 - Train Accuracy: 0.9265625\n",
      "\t\t\tVal Loss: 0.023544685216620564 - Val Accuracy: 0.67\n",
      "\n",
      "\tSTARTING EPOCH 22 - LR=[2]...\n",
      "\t\tTrain step - Step 750, Loss 0.0035178663674741983\n",
      "\t\tRESULT EPOCH 22:\n",
      "\t\t\tTrain Loss: 0.004204140463843942 - Train Accuracy: 0.9283482142857142\n",
      "\t\t\tVal Loss: 0.012132078409194946 - Val Accuracy: 0.772\n",
      "\n",
      "\tSTARTING EPOCH 23 - LR=[2]...\n",
      "\t\tTrain step - Step 780, Loss 0.003925715107470751\n",
      "\t\tRESULT EPOCH 23:\n",
      "\t\t\tTrain Loss: 0.0038356670045426914 - Train Accuracy: 0.9341517857142857\n",
      "\t\t\tVal Loss: 0.011517081875354052 - Val Accuracy: 0.786\n",
      "\n",
      "\tSTARTING EPOCH 24 - LR=[2]...\n",
      "\t\tTrain step - Step 810, Loss 0.003386638592928648\n",
      "\t\tRESULT EPOCH 24:\n",
      "\t\t\tTrain Loss: 0.0035916026581877046 - Train Accuracy: 0.9392857142857143\n",
      "\t\t\tVal Loss: 0.0145094261970371 - Val Accuracy: 0.76\n",
      "\n",
      "\tSTARTING EPOCH 25 - LR=[2]...\n",
      "\t\tTrain step - Step 840, Loss 0.003490343689918518\n",
      "\t\tTrain step - Step 870, Loss 0.0030908691696822643\n",
      "\t\tRESULT EPOCH 25:\n",
      "\t\t\tTrain Loss: 0.004113339193697487 - Train Accuracy: 0.9227678571428571\n",
      "\t\t\tVal Loss: 0.012373457895591855 - Val Accuracy: 0.774\n",
      "\n",
      "\tSTARTING EPOCH 26 - LR=[2]...\n",
      "\t\tTrain step - Step 900, Loss 0.002646450651809573\n",
      "\t\tRESULT EPOCH 26:\n",
      "\t\t\tTrain Loss: 0.0034979346474366528 - Train Accuracy: 0.9408482142857143\n",
      "\t\t\tVal Loss: 0.009409205056726933 - Val Accuracy: 0.818\n",
      "\n",
      "\tSTARTING EPOCH 27 - LR=[2]...\n",
      "\t\tTrain step - Step 930, Loss 0.003513648174703121\n",
      "\t\tRESULT EPOCH 27:\n",
      "\t\t\tTrain Loss: 0.0031061684213844793 - Train Accuracy: 0.9430803571428571\n",
      "\t\t\tVal Loss: 0.010016142739914358 - Val Accuracy: 0.82\n",
      "\n",
      "\tSTARTING EPOCH 28 - LR=[2]...\n",
      "\t\tTrain step - Step 960, Loss 0.005333262495696545\n",
      "\t\tRESULT EPOCH 28:\n",
      "\t\t\tTrain Loss: 0.0032144901143120867 - Train Accuracy: 0.94375\n",
      "\t\t\tVal Loss: 0.015084874583408237 - Val Accuracy: 0.776\n",
      "\n",
      "\tSTARTING EPOCH 29 - LR=[2]...\n",
      "\t\tTrain step - Step 990, Loss 0.0030586773063987494\n",
      "\t\tRESULT EPOCH 29:\n",
      "\t\t\tTrain Loss: 0.0037659332189442854 - Train Accuracy: 0.9337053571428572\n",
      "\t\t\tVal Loss: 0.012919739412609488 - Val Accuracy: 0.768\n",
      "\n",
      "\tSTARTING EPOCH 30 - LR=[2]...\n",
      "\t\tTrain step - Step 1020, Loss 0.003469492308795452\n",
      "\t\tRESULT EPOCH 30:\n",
      "\t\t\tTrain Loss: 0.0035154688105519328 - Train Accuracy: 0.9404017857142857\n",
      "\t\t\tVal Loss: 0.01761629246175289 - Val Accuracy: 0.746\n",
      "\n",
      "\tSTARTING EPOCH 31 - LR=[2]...\n",
      "\t\tTrain step - Step 1050, Loss 0.0024474011734128\n",
      "\t\tTrain step - Step 1080, Loss 0.00439112214371562\n",
      "\t\tRESULT EPOCH 31:\n",
      "\t\t\tTrain Loss: 0.0031429049991337317 - Train Accuracy: 0.9430803571428571\n",
      "\t\t\tVal Loss: 0.013325397158041596 - Val Accuracy: 0.776\n",
      "\n",
      "\tSTARTING EPOCH 32 - LR=[2]...\n",
      "\t\tTrain step - Step 1110, Loss 0.0035606820601969957\n",
      "\t\tRESULT EPOCH 32:\n",
      "\t\t\tTrain Loss: 0.003043717488513461 - Train Accuracy: 0.9497767857142857\n",
      "\t\t\tVal Loss: 0.01814772211946547 - Val Accuracy: 0.734\n",
      "\n",
      "\tSTARTING EPOCH 33 - LR=[2]...\n",
      "\t\tTrain step - Step 1140, Loss 0.002151843626052141\n",
      "\t\tRESULT EPOCH 33:\n",
      "\t\t\tTrain Loss: 0.0027211733528279833 - Train Accuracy: 0.9558035714285714\n",
      "\t\t\tVal Loss: 0.01214131887536496 - Val Accuracy: 0.792\n",
      "\n",
      "\tSTARTING EPOCH 34 - LR=[2]...\n",
      "\t\tTrain step - Step 1170, Loss 0.0021400616969913244\n",
      "\t\tRESULT EPOCH 34:\n",
      "\t\t\tTrain Loss: 0.0028217374214104243 - Train Accuracy: 0.9533482142857143\n",
      "\t\t\tVal Loss: 0.01518072874750942 - Val Accuracy: 0.754\n",
      "\n",
      "\tSTARTING EPOCH 35 - LR=[2]...\n",
      "\t\tTrain step - Step 1200, Loss 0.0020194901153445244\n",
      "\t\tRESULT EPOCH 35:\n",
      "\t\t\tTrain Loss: 0.003158739837817848 - Train Accuracy: 0.9464285714285714\n",
      "\t\t\tVal Loss: 0.012832352193072438 - Val Accuracy: 0.782\n",
      "\n",
      "\tSTARTING EPOCH 36 - LR=[2]...\n",
      "\t\tTrain step - Step 1230, Loss 0.0027212288696318865\n",
      "\t\tRESULT EPOCH 36:\n",
      "\t\t\tTrain Loss: 0.002793319576552936 - Train Accuracy: 0.9515625\n",
      "\t\t\tVal Loss: 0.013316122349351645 - Val Accuracy: 0.784\n",
      "\n",
      "\tSTARTING EPOCH 37 - LR=[2]...\n",
      "\t\tTrain step - Step 1260, Loss 0.003289820859208703\n",
      "\t\tTrain step - Step 1290, Loss 0.0023643027525395155\n",
      "\t\tRESULT EPOCH 37:\n",
      "\t\t\tTrain Loss: 0.002949414265874241 - Train Accuracy: 0.9482142857142857\n",
      "\t\t\tVal Loss: 0.013998222770169377 - Val Accuracy: 0.788\n",
      "\n",
      "\tSTARTING EPOCH 38 - LR=[2]...\n",
      "\t\tTrain step - Step 1320, Loss 0.0026351711712777615\n",
      "\t\tRESULT EPOCH 38:\n",
      "\t\t\tTrain Loss: 0.0025231314290847097 - Train Accuracy: 0.9571428571428572\n",
      "\t\t\tVal Loss: 0.010427653673104942 - Val Accuracy: 0.824\n",
      "\n",
      "\tSTARTING EPOCH 39 - LR=[2]...\n",
      "\t\tTrain step - Step 1350, Loss 0.0014512443449348211\n",
      "\t\tRESULT EPOCH 39:\n",
      "\t\t\tTrain Loss: 0.0027133220274533545 - Train Accuracy: 0.9517857142857142\n",
      "\t\t\tVal Loss: 0.012692437274381518 - Val Accuracy: 0.804\n",
      "\n",
      "\tSTARTING EPOCH 40 - LR=[2]...\n",
      "\t\tTrain step - Step 1380, Loss 0.0032529267482459545\n",
      "\t\tRESULT EPOCH 40:\n",
      "\t\t\tTrain Loss: 0.0033293848524668388 - Train Accuracy: 0.9408482142857143\n",
      "\t\t\tVal Loss: 0.012197679374366999 - Val Accuracy: 0.784\n",
      "\n",
      "\tSTARTING EPOCH 41 - LR=[2]...\n",
      "\t\tTrain step - Step 1410, Loss 0.0021506722550839186\n",
      "\t\tRESULT EPOCH 41:\n",
      "\t\t\tTrain Loss: 0.002743234861242984 - Train Accuracy: 0.9546875\n",
      "\t\t\tVal Loss: 0.011172455619089305 - Val Accuracy: 0.824\n",
      "\n",
      "\tSTARTING EPOCH 42 - LR=[2]...\n",
      "\t\tTrain step - Step 1440, Loss 0.0024461543653160334\n",
      "\t\tRESULT EPOCH 42:\n",
      "\t\t\tTrain Loss: 0.0026274437134686324 - Train Accuracy: 0.9549107142857143\n",
      "\t\t\tVal Loss: 0.013842095620930195 - Val Accuracy: 0.776\n",
      "\n",
      "\tSTARTING EPOCH 43 - LR=[2]...\n",
      "\t\tTrain step - Step 1470, Loss 0.0027589525561779737\n",
      "\t\tTrain step - Step 1500, Loss 0.0017607001354917884\n",
      "\t\tRESULT EPOCH 43:\n",
      "\t\t\tTrain Loss: 0.002547192553590451 - Train Accuracy: 0.9607142857142857\n",
      "\t\t\tVal Loss: 0.009292525588534772 - Val Accuracy: 0.85\n",
      "\n",
      "\tSTARTING EPOCH 44 - LR=[2]...\n",
      "\t\tTrain step - Step 1530, Loss 0.001292548724450171\n",
      "\t\tRESULT EPOCH 44:\n",
      "\t\t\tTrain Loss: 0.002124153057645474 - Train Accuracy: 0.9627232142857143\n",
      "\t\t\tVal Loss: 0.01453631347976625 - Val Accuracy: 0.78\n",
      "\n",
      "\tSTARTING EPOCH 45 - LR=[2]...\n",
      "\t\tTrain step - Step 1560, Loss 0.003000550903379917\n",
      "\t\tRESULT EPOCH 45:\n",
      "\t\t\tTrain Loss: 0.0023759392938310546 - Train Accuracy: 0.9587053571428571\n",
      "\t\t\tVal Loss: 0.01242000050842762 - Val Accuracy: 0.812\n",
      "\n",
      "\tSTARTING EPOCH 46 - LR=[2]...\n",
      "\t\tTrain step - Step 1590, Loss 0.002427295781672001\n",
      "\t\tRESULT EPOCH 46:\n",
      "\t\t\tTrain Loss: 0.0023052054557151026 - Train Accuracy: 0.9618303571428571\n",
      "\t\t\tVal Loss: 0.011966734193265438 - Val Accuracy: 0.802\n",
      "\n",
      "\tSTARTING EPOCH 47 - LR=[2]...\n",
      "\t\tTrain step - Step 1620, Loss 0.0014437963254749775\n",
      "\t\tRESULT EPOCH 47:\n",
      "\t\t\tTrain Loss: 0.002247958650280322 - Train Accuracy: 0.9595982142857142\n",
      "\t\t\tVal Loss: 0.01110799121670425 - Val Accuracy: 0.83\n",
      "\n",
      "\tSTARTING EPOCH 48 - LR=[2]...\n",
      "\t\tTrain step - Step 1650, Loss 0.004120624158531427\n",
      "\t\tRESULT EPOCH 48:\n",
      "\t\t\tTrain Loss: 0.0019228362012654542 - Train Accuracy: 0.9678571428571429\n",
      "\t\t\tVal Loss: 0.011438313871622086 - Val Accuracy: 0.818\n",
      "\n",
      "\tSTARTING EPOCH 49 - LR=[2]...\n",
      "\t\tTrain step - Step 1680, Loss 0.0016814221162348986\n",
      "\t\tTrain step - Step 1710, Loss 0.0023612051736563444\n",
      "\t\tRESULT EPOCH 49:\n",
      "\t\t\tTrain Loss: 0.0021211269261714604 - Train Accuracy: 0.9665178571428571\n",
      "\t\t\tVal Loss: 0.011477440013550222 - Val Accuracy: 0.814\n",
      "\n",
      "\tSTARTING EPOCH 50 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1740, Loss 0.0010215217480435967\n",
      "\t\tRESULT EPOCH 50:\n",
      "\t\t\tTrain Loss: 0.0011113618467269199 - Train Accuracy: 0.9841517857142857\n",
      "\t\t\tVal Loss: 0.00849308748729527 - Val Accuracy: 0.85\n",
      "\n",
      "\tSTARTING EPOCH 51 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1770, Loss 0.0012467801570892334\n",
      "\t\tRESULT EPOCH 51:\n",
      "\t\t\tTrain Loss: 0.0008152737855977778 - Train Accuracy: 0.9912946428571429\n",
      "\t\t\tVal Loss: 0.007626619888469577 - Val Accuracy: 0.862\n",
      "\n",
      "\tSTARTING EPOCH 52 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1800, Loss 0.0003789360052905977\n",
      "\t\tRESULT EPOCH 52:\n",
      "\t\t\tTrain Loss: 0.0005855709646961518 - Train Accuracy: 0.9948660714285714\n",
      "\t\t\tVal Loss: 0.007280084770172834 - Val Accuracy: 0.866\n",
      "\n",
      "\tSTARTING EPOCH 53 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1830, Loss 0.0006627639522776008\n",
      "\t\tRESULT EPOCH 53:\n",
      "\t\t\tTrain Loss: 0.0005427466688810715 - Train Accuracy: 0.9957589285714286\n",
      "\t\t\tVal Loss: 0.007216696627438068 - Val Accuracy: 0.878\n",
      "\n",
      "\tSTARTING EPOCH 54 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1860, Loss 0.0009277122444473207\n",
      "\t\tRESULT EPOCH 54:\n",
      "\t\t\tTrain Loss: 0.00045377783202898823 - Train Accuracy: 0.996875\n",
      "\t\t\tVal Loss: 0.007820374215953052 - Val Accuracy: 0.878\n",
      "\n",
      "\tSTARTING EPOCH 55 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1890, Loss 0.000708048464730382\n",
      "\t\tTrain step - Step 1920, Loss 0.00031819939613342285\n",
      "\t\tRESULT EPOCH 55:\n",
      "\t\t\tTrain Loss: 0.0004285349015844986 - Train Accuracy: 0.996875\n",
      "\t\t\tVal Loss: 0.007228966569527984 - Val Accuracy: 0.864\n",
      "\n",
      "\tSTARTING EPOCH 56 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1950, Loss 0.000491384242195636\n",
      "\t\tRESULT EPOCH 56:\n",
      "\t\t\tTrain Loss: 0.0004141681070905179 - Train Accuracy: 0.9973214285714286\n",
      "\t\t\tVal Loss: 0.007420371170155704 - Val Accuracy: 0.88\n",
      "\n",
      "\tSTARTING EPOCH 57 - LR=[0.4]...\n",
      "\t\tTrain step - Step 1980, Loss 0.00034948281245306134\n",
      "\t\tRESULT EPOCH 57:\n",
      "\t\t\tTrain Loss: 0.00036466804075254393 - Train Accuracy: 0.9984375\n",
      "\t\t\tVal Loss: 0.007618168951012194 - Val Accuracy: 0.868\n",
      "\n",
      "\tSTARTING EPOCH 58 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2010, Loss 0.001011623302474618\n",
      "\t\tRESULT EPOCH 58:\n",
      "\t\t\tTrain Loss: 0.0004282083906998326 - Train Accuracy: 0.9964285714285714\n",
      "\t\t\tVal Loss: 0.008009861805476248 - Val Accuracy: 0.87\n",
      "\n",
      "\tSTARTING EPOCH 59 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2040, Loss 0.00022921105846762657\n",
      "\t\tRESULT EPOCH 59:\n",
      "\t\t\tTrain Loss: 0.00034570827223693153 - Train Accuracy: 0.9984375\n",
      "\t\t\tVal Loss: 0.0077135489555075765 - Val Accuracy: 0.872\n",
      "\n",
      "\tSTARTING EPOCH 60 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2070, Loss 0.00017653367831371725\n",
      "\t\tRESULT EPOCH 60:\n",
      "\t\t\tTrain Loss: 0.00029203718669512977 - Train Accuracy: 0.9991071428571429\n",
      "\t\t\tVal Loss: 0.006479234201833606 - Val Accuracy: 0.888\n",
      "\n",
      "\tSTARTING EPOCH 61 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2100, Loss 0.00023453819449059665\n",
      "\t\tTrain step - Step 2130, Loss 0.0002437599905533716\n",
      "\t\tRESULT EPOCH 61:\n",
      "\t\t\tTrain Loss: 0.0003387299258195396 - Train Accuracy: 0.9977678571428571\n",
      "\t\t\tVal Loss: 0.007768732728436589 - Val Accuracy: 0.878\n",
      "\n",
      "\tSTARTING EPOCH 62 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2160, Loss 0.0001649086771067232\n",
      "\t\tRESULT EPOCH 62:\n",
      "\t\t\tTrain Loss: 0.000308440625251803 - Train Accuracy: 0.9984375\n",
      "\t\t\tVal Loss: 0.007529045804403722 - Val Accuracy: 0.868\n",
      "\n",
      "\tSTARTING EPOCH 63 - LR=[0.4]...\n",
      "\t\tTrain step - Step 2190, Loss 0.00022367405472323298\n",
      "\t\tRESULT EPOCH 63:\n",
      "\t\t\tTrain Loss: 0.0003733057774037921 - Train Accuracy: 0.9975446428571428\n",
      "\t\t\tVal Loss: 0.007361927768215537 - Val Accuracy: 0.872\n",
      "\n",
      "\tSTARTING EPOCH 64 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2220, Loss 0.0002445654245093465\n",
      "\t\tRESULT EPOCH 64:\n",
      "\t\t\tTrain Loss: 0.00030071165487502834 - Train Accuracy: 0.9988839285714286\n",
      "\t\t\tVal Loss: 0.007435762207023799 - Val Accuracy: 0.87\n",
      "\n",
      "\tSTARTING EPOCH 65 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2250, Loss 0.000260215369053185\n",
      "\t\tRESULT EPOCH 65:\n",
      "\t\t\tTrain Loss: 0.0003103345345672486 - Train Accuracy: 0.9982142857142857\n",
      "\t\t\tVal Loss: 0.00762785121332854 - Val Accuracy: 0.888\n",
      "\n",
      "\tSTARTING EPOCH 66 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2280, Loss 0.00021436095994431525\n",
      "\t\tRESULT EPOCH 66:\n",
      "\t\t\tTrain Loss: 0.00027427230088505894 - Train Accuracy: 0.9984375\n",
      "\t\t\tVal Loss: 0.008037517312914133 - Val Accuracy: 0.878\n",
      "\n",
      "\tSTARTING EPOCH 67 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2310, Loss 0.0002218735171481967\n",
      "\t\tTrain step - Step 2340, Loss 0.00027725554537028074\n",
      "\t\tRESULT EPOCH 67:\n",
      "\t\t\tTrain Loss: 0.00027973373944405465 - Train Accuracy: 0.9993303571428571\n",
      "\t\t\tVal Loss: 0.007292424445040524 - Val Accuracy: 0.878\n",
      "\n",
      "\tSTARTING EPOCH 68 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2370, Loss 0.0002910112962126732\n",
      "\t\tRESULT EPOCH 68:\n",
      "\t\t\tTrain Loss: 0.0002535898712397154 - Train Accuracy: 0.9991071428571429\n",
      "\t\t\tVal Loss: 0.0075973160564899445 - Val Accuracy: 0.874\n",
      "\n",
      "\tSTARTING EPOCH 69 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2400, Loss 0.0003518908633850515\n",
      "\t\tRESULT EPOCH 69:\n",
      "\t\t\tTrain Loss: 0.00030548656941391527 - Train Accuracy: 0.9986607142857142\n",
      "\t\t\tVal Loss: 0.007389389676973224 - Val Accuracy: 0.888\n",
      "\n",
      "\tSTARTING EPOCH 70 - LR=[0.08000000000000002]...\n",
      "\t\tTrain step - Step 2430, Loss 0.00030452964711003006\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/79 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\t\tRESULT EPOCH 70:\n",
      "\t\t\tTrain Loss: 0.0002824815231308873 - Train Accuracy: 0.9986607142857142\n",
      "\t\t\tVal Loss: 0.007365312776528299 - Val Accuracy: 0.876\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 31.46it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "\tResults STAGE 10:\n",
      "\t\tTrain Mean Accuracy: 0.9277072704081633\n",
      "\t\tVal Mean Accuracy: 0.7968\n",
      "\t\tTest Accuracy: 0.0896\n",
      "\n",
      "\n",
      "Total time: 26 min 16 sec\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ciGlvEWabcbD",
    "colab_type": "code",
    "outputId": "27f709be-3f47-48e8-9c82-5b08b4ef3c55",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "import libs.plots as plots\n",
    "\n",
    "method = \"finetuning\" if TRAINING_TYPE == 'FT' else 'joint_training'\n",
    "plots.plot_accuracy_trend(test_accuracies, method, SEED)\n",
    "plots.plot_confusion_matrix(y_true, y_preds, method, SEED)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxV9Z3/8dcn+0bYAmELEgXFbUACuNYaUautVX4WRYcq06q0Haejbe1PWn/ttJ1xRutM905nbHWk1Rr3ZbRuxajVKhBQBBcWkVV2whICgSSf3x/nJFxiAiHJvecm9/18PO7jnvO959zzTrjcT872/Zq7IyIiApAWdQAREUkeKgoiItJMRUFERJqpKIiISDMVBRERaaaiICIizeJWFMzsHjPbZGaLY9r6mdmLZrYsfO4btpuZ/cLMlpvZO2Y2Ll65RESkbfHcU7gXuLBF20xgtruPAmaH8wAXAaPCxwzgN3HMJSIibYhbUXD3V4FtLZovBWaF07OAyTHtv/fAm0AfMxscr2wiItK6jARvr9jd14fTG4DicHoosCZmubVh23paMLMZBHsT5ObmlpWUlHQoSGNjI2lp0Z9SUQ7lSOYMytEzcyxdunSLuw9o9UV3j9sDGAEsjpnf3uL16vD5aeCsmPbZwPjDvX9ZWZl3VGVlZYfX7UrKcTDlSK4M7srRUk/IAVR5G9+riS53G5sOC4XPm8L2dUDsn/zDwjYREUmgRBeFp4Dp4fR04MmY9mvCq5BOA3b4gcNMIiKSIHE7p2BmDwDnAEVmthb4J+B24CEzuxZYBVwRLv4n4LPAcqAW+FK8comISNviVhTc/ao2XprUyrIO3BCvLCIi0j7Rn0IXEZGkoaIgIiLNVBRERKSZioKIiDRTURARkWYqCiIi0kxFQUREmqkoiIhIMxUFERFppqIgIiLNVBRERKSZioKIiDRTURARkWaRFAUzu9HMFpvZu2Z2U9jWz8xeNLNl4XPfKLKJiKSyhBcFMzsJuB6YCIwBLjazkcBMYLa7jyIYjnNmorOJiKS6KPYUjgfmuHutu9cDrwCXAZcCs8JlZgGTI8gmIpLSLBjfJoEbNDueYBjO04E9BHsFVcDV7t4nXMaA6qb5FuvPAGYAFBcXl1VUVHQoR01NDQUFBR1atysph3Ikcwbl6Jk5ysvL57v7+FZfdPeEP4BrgfnAq8BvgJ8B21ssU3249ykrK/OOqqys7PC6XUk5DqYcyZXBXTla6gk5gCpv43s1khPN7n63u5e5+9lANbAU2GhmgwHC501RZBMRSWVRXX00MHweTnA+4Y/AU8D0cJHpBIeYREQkgTIi2u6jZtYf2A/c4O7bzex24CEzuxZYBVwRUTYRkZQVSVFw90+10rYVmBRBHBERCemOZhERaaaiICIizVQURESkWeoVhY/uhydG8OmPz4UnRgTzIiICRHf1UTQ+uh/mzoCGWgygdlUwD1A6LcpkIiJJIbX2FBbeCg21B7c11AbtIiKSYkWhdvWRtYuIpJjUKgp5w4+sXUQkxaRWURhzG6TnHdTk6XlBu4iIpFhRKJ0GE++CvKNwjLX7BjC/+A6dZBYRCaVWUYCgAExeSeXg2Vy1qYKfLGu9S3ERkVSUekUhlGbGFWUl/PXDrazaujvqOCIiSSFliwLAlPHDSDN4uGpt1FFERJJCVOMpfMPM3jWzxWb2gJnlmFmpmc0xs+Vm9qCZZcU7x+DeuXz62AE8PH8N9Q2N8d6ciEjSS3hRMLOhwD8C4939JCAduBK4A/ipu48kGI3t2kTkmTphOBt31vHK0s2J2JyISFKL6vBRBpBrZhlAHrAeOBd4JHx9FjA5EUEmHT+QooIsHpy3JhGbExFJahaM4ZzgjZrdCNwG7AFeAG4E3gz3EjCzEuDZcE+i5bozgBkAxcXFZRUVFR3KUFNTQ0FBAQAPLtnH8yv385NzcumTndg6GZsjSsqRfDmSIYNy9Mwc5eXl89299Usv3T2hD6Av8BIwAMgEngC+CCyPWaYEWHy49yorK/OOqqysbJ5evmmXH3XL0/6flcs7/H5dkSNKynGwZMiRDBnclaOlnpADqPI2vlejOHx0HvCRu2929/3AY8CZQJ/wcBLAMGBdogIdM6CAiSP68VDVmqaiJCKSkqIoCquB08wsz8yMYFzm94BKYEq4zHTgyUSGumJCCR9t2c3cj7YlcrMiIkkl4UXB3ecQnFBeACwKM9wF3AJ808yWA/2BuxOZ67MnD6JXdoZOOItISovk6iN3/yd3H+3uJ7n71e5e5+4r3H2iu49098vdvS6RmfKyMrhk7BD+tHg9O/bsT+SmRUSSRkrf0dzS1Akl7N3fyFMLP446iohIJFQUYpw8tDfHDy7kwXkadEdEUpOKQgwz48oJJSxet5PF63ZEHUdEJOFUFFqYPHYoWRlpPFSlE84iknpUFFronZfJRScN4vG31rF3f0PUcUREEkpFoRVTJ5Swa289zy3eEHUUEZGEUlFoxWml/RneL48KnXAWkRSjotCKtDRj6oQS3lyxjZVbNCqbiKQOFYU2TCkLRmXTCWcRSSUqCm0oLsyh/LiBPDx/rUZlE5GUoaJwCFMnlLB5Vx2VSzQqm4ikBhWFQygfPZABvbLVSZ6IpIwoxmg+zszejnnsNLObzKyfmb1oZsvC576JztZSZnoaXxg3jMolm9i4c2/UcURE4i6KrrOXuPtYdx8LlAG1wOPATGC2u48CZofzkZs6oYSGRueR+WujjiIiEndRHz6aBHzo7quAS4FZYfssYHJkqWKUFuVzaqlGZROR1BB1UbgSeCCcLnb39eH0BqA4mkifNHVCCau21vLmCo3KJiI9m0X116+ZZQEfAye6+0Yz2+7ufWJer3b3T5xXMLMZwAyA4uLisoqKig5tv6amhoKCgnYtW9fg3FRZy9gB6XxlTE6HttcVOeJJOZIvRzJkUI6emaO8vHy+u49v9UV3j+RBcLjohZj5JcDgcHowsORw71FWVuYdVVlZeUTL/7/HF/mxt/7Jt+/e1+FtdkWOeFGOgyVDjmTI4K4cLfWEHECVt/G9GuXho6s4cOgI4Clgejg9HXgy4YkOYeqEEurqG3ly4bqoo4iIxE0kRcHM8oHzgcdimm8HzjezZcB54XzSOGlob04cUkjFXN2zICI9VyRFwd13u3t/d98R07bV3Se5+yh3P8/dk+6s7pUTSnhvvUZlE5GeK+qrj7qVS8YOJTsjTV1qi0iPpaJwBHrnZvLZkwfz5Fsfs2efRmUTkZ5HReEITZ1Qwq66ep5dvP7wC4uIdDMqCkfo1NJ+jOifR4U6yRORHkhF4QiZGVdMKGHuR9tYsbkm6jgiIl1KRaEDpowbRnqa8VCVOskTkZ5FRaEDBhbmcO7ogTwyfy37NSqbiPQgKgodNHV8CVtq6njpg01RRxER6TIqCh10znEDGNgrm4d0wllEehAVhQ7KSE/j8vHBqGwbdmhUNhHpGVQUOuGK8SU0OjwyX3sLItIztLsomNlIM7vPzB41s9PjGaq7OKp/Pqcf3Z+HqtbS2KhR2USk+2uzKJhZy9Fk/hn4DnAT8Jt4hupOrpxYwupttby5YmvUUUREOu1Qewr/a2bXxMzvB0YARwGd6vjHzPqY2SNm9oGZvW9mp5tZPzN70cyWhc+fGHUtGX3mxEEU5mToDmcR6REOVRQuBArN7DkzOxu4GfgM8H+AaZ3c7s+B59x9NDAGeB+YCcx291HA7HA+6eVkpvN/ThnKc+9uYHvtvqjjiIh0SptFwd0b3P1XwFTgEoIv8v9x92+5+wcd3aCZ9QbOBu4Ot7PP3bcTDM85K1xsFjC5o9tItKkThrOvvpEn3tKobCLSvVkwXGcrL5idCnwb2Af8K7AHuA1YB/xz+EV+5Bs0GwvcBbxHsJcwH7gRWOfufcJlDKhumm+x/gxgBkBxcXFZRUVFR2J0+eDbP/jrHhocfnRGDkH8aHJ0lHIkX45kyKAcPTNHeXn5fHcf3+qLbQ3eDLwNDAGOBV6Paf808Hxb6x3uAYwH6oFTw/mfE5zE3t5iuerDvVdZWVmHB67u6sG3//DGSj/qlqd94ZrqSHN0lHIcLBlyJEMGd+VoqSfkAKq8je/VQ51TqOfAieXmg+Xu/oq7f6ZD5SmwFljr7nPC+UeAccBGMxsMED53q/4jLhk7hJzMNJ1wFpFu7VBF4W+BLwDnAtccYrkj4u4bgDVmdlzYNIngUNJTwPSwbTrwZFdtMxEKc4JR2Z56+2Nq99VHHUdEpEMy2nrB3ZcC34rTdr8O3G9mWcAK4EsEBeohM7sWWAVcEadtx82VE4bz2IJ1/GnRBqaUDYs6jojIEWuzKMSTu79NcG6hpUmJztKVJozoy9FF+Tw4b7WKgoh0S+r7qAs1jco2b2U1yzdpVDYR6X4OWxTM7PNmpuLRTpeNG0pGmvFwlU44i0j3054v+6nAMjP7sZmNjneg7m5grxwmHT+QRxesZV+9RmUTke7lsEXB3b8InAJ8CNxrZm+Y2Qwz6xX3dN3U1AklbKnZx0sfbIw6iojIEWnXYSF330lwP0EFMJig/6MFZvb1OGbrts4eNYBBhTk8qHsWRKSbac85hUvM7HHgZSATmOjuFxF0URGvS1a7taZR2V5ZupmPt++JOo6ISLu1Z0/hC8BP3f1kd7/T3TcBuHstcG1c03Vjl5c1jcq2NuooIiLt1p6i8ANgbtOMmeWa2QgAd58dl1Q9wPD+eZw5sj8PVa3RqGwi0m20pyg8DMReRtMQtslhTJ0wnLXVe/jrhxqVTUS6h/YUhQx3j+0Qbx+QFb9IPccFJxTTOzeTinmro44iItIu7SkKm83skqYZM7sU2BK/SD1H06hsL7y7kerdGpVNRJJfe4rCV4HvmtlqM1sD3AJ8Jb6xeo6pE0rY19DI4xqVTUS6gfbcvPahu58GnAAc7+5nuPvy+EfrGY4fXMiYYb15cN6apsGDRESSVrt6STWzzwEnAjlNQ026+486ulEzWwnsIjhpXe/u482sH/AgwcA+K4Er3L26o9tIJlMnDOe7jy9i4dodjC35xAijIiJJoz03r/0XQf9HXwcMuJxgNLbOKnf3sX5gnNCZwGx3HwXMDud7hM+PGUxuZjoP6oSziCS59pxTOMPdryEYM/mHwOkE4zZ3tUuBWeH0LGByHLYRiV45mXzub4JR2XbXaVQ2EUledrjj3GY2190nmtmbwGXAVuBddx/Z4Y2afQRUAw78t7vfZWbb3b1P+LoRFKFPHGsxsxnADIDi4uKyioqKDmWoqamhoKCgoz/CEVtW3cBtc/Zy7UlZfGpYZmQ52qIcyZcjGTIoR8/MUV5ePj/mKM3B3P2QD+B7QB+C7i42AOuBHx1uvcO859DweSCwEDgb2N5imerDvU9ZWZl3VGVlZYfX7YjGxkY/998r/bL/fD3SHG1RjoMlQ45kyOCuHC31hBxAlbfxvXrIw0fh4Dqz3X27uz9KcC5htLt/v0Pl6UAhWhc+bwIeByYCG81scLjdwcCmzmwj2ZgZUyeUMH9VNcs37Yo6johIqw5ZFNy9Efh1zHydu+/ozAbNLL9pLAYzywcuABYDTwHTw8WmA092ZjvJ6LJxw8hIM3WpLSJJqz0nmmeb2Res6VrUzisGXjOzhQQd7T3j7s8BtwPnm9ky4LxwvkcpKsjm/BOKeXTBOo3KJiJJqT33KXwF+CZQb2Z7CS5LdXcv7MgG3X0FwVgMLdu3ApM68p7dyRUTSnh28Qb+/P5GPnvy4KjjiIgcpD13NPdy9zR3z3L3wnC+QwVBglHZBvfWqGwikpwOu6dgZme31u7ur3Z9nJ4vPc24fHwJv3xpGes0KpuIJJn2HD76dsx0DsGVQvOBc+OSKAVcXjaMX760jIer1jC2XR2NiIgkxmG/ktz987HzZlYC/CxuiVJASb88vn1cFZd9/GWKMzbDE8NhzG1QOi3qaCKS4jryd+pa4PiuDpJSPrqfGdl3kOHh4aPaVTB3RjCtwiAiEWrPOYVfEnRHAcGJ6bHAgniG6vEW3nqgIDRpqIWFt6ooiEik2rOnUBUzXQ884O6vxylPaqhto7fUttpFRBKkPUXhEWCvuzcAmFm6meW5e218o/VgecODQ0attYuIRKhddzQDuTHzucCf4xMnRYy5DdLzDmqqbcxmft+bIwokIhJoT1HIcfeapplwOu8Qy8vhlE6DiXdB3lE4RmPecH5bN5Opzx/NSx9sjDqdiKSw9hSF3WY2rmnGzMoA3XXVWaXTYPJKXhnyEmmTV/HlabcyenAvvnbfAuas2Bp1OhFJUe0pCjcBD5vZX8zsNYJxlP8hvrFST6+cTGZ9aSLD+uZy3awqFq/rVGe0IiId0p6+j+YBo4GvAV8Fjnf3+fEOlor6F2Rz33WnUpibyTX3zGX5pprDryQi0oUOWxTM7AYg390Xu/tioMDM/r6zGw6vYnrLzJ4O50vNbI6ZLTezB80sq7Pb6I4G987lvutOJc2Mq++ew9pqXeQlIonTnsNH17v79qYZd68Gru+Cbd8IvB8zfwfwUw/Gfq4Gru2CbXRLpUX5/P7LE9ldV8/Vd89l8666qCOJSIpoT1FIjx1gx8zSgU79FW9mw4DPAb8L542gg71HwkVmAZM7s43u7oQhhfzPlyawYcderrlnLjv27I86koikAAvGcD7EAmZ3EozN/N9h01eANe7+rQ5v1OwR4N+AXsDNwN8Bb4Z7CU2d7j3r7ie1su4MYAZAcXFxWUVFRYcy1NTUUFBQ0KF1u9LhcizaXM/PFtRR2juNb4/PITujqwbAO7IciaIcyZVBOXpmjvLy8vnuPr7VF939kA+CvYmvEvwV/whBUUg73HqHeL+Lgf8Mp88BngaKgOUxy5QAiw/3XmVlZd5RlZWVHV63K7UnxzPvfOylM5/2q++e43X7GyLLkQjKkVwZ3JWjpZ6QA6jyNr5X23P1UaO7/5e7T3H3KcB7wC87VJ4CZwKXmNlKoILgsNHPgT5m1tTtxjBgXSe20aN89uTB3H7Z3/Dq0s1848G3aWg89N6diEhHteecAmZ2ipn9OPwi/xHwQUc36O7fcfdh7j4CuBJ4yd2nAZXAlHCx6cCTHd1GT3TFhBL+3+eO55lF6/nuY4ua9qhERLpUmx3imdmxwFXhYwvBTWvm7uVxynILUGFm/wK8Bdwdp+10W9d96mh27NnPL19aTu+8TL5z0WhirgEQEem0Q/WS+gHwF+Bid18OYGbf6MqNu/vLwMvh9AqCoT7lEL55/rHs3LOfu15dQe/cTG4oHxl1JBHpQQ5VFC4jOLxTaWbPERz/15+lETMz/unzJ7Jzbz13Pr+EXjkZXHP6iKhjiUgP0WZRcPcngCfMLB+4lKAPpIFm9hvgcXd/IUEZpYW0NOPHU/6GXXv38/0n36UwJ5PJpwyNOpaI9ADtufpot7v/0d0/T3BV0FsEx/8lQpnpafzqb8dx2tH9+NbDC/nze+pyW0Q6r11XHzVx92p3v8vdJ8UrkLRfTmY6v5s+gZOGFPL3f1zAGx+qy20R6ZwjKgqSfAqyM7j3SxM5ql8e182axztrtx9+JRGRNqgo9AB987P4w7Wn0jc/i+n3zGXZxl1RRxKRbkpFoYcY1DuH+687lYz0NL549xzWbFOX2yJy5FQUepCj+ufzh2snsnd/I1+8ew6bdu6NOpKIdDMqCj3M6EFBl9ubd9VxzT1z2V67L+pIItKNqCj0QOOG9+Wuq8ezYvNuvnTvPHbX1UcdSUS6CRWFHuqsUUX84qpTWLhmO1+9bz519Q1RRxKRbkBFoQe78KRB/HjKGP6ybAs3PvA29Q2NUUcSkSSX8KJgZjlmNtfMFprZu2b2w7C91MzmmNlyM3vQzDo15KcEppQN4/sXn8Bz725g5mOLaNRYDCJyCFHsKdQB57r7GGAscKGZnQbcAfzUgyE5q4FrI8jWI335rFJunDSKR+av5V+eeV9jMYhImxJeFMLR4GrC2czw4QQjsD0Sts8CJic6W09203mj+LszRnDP6x/xi9nLo44jIknqUF1nx42ZpQPzgZHAr4EPge3u3nSZzFpA3X52ITPj+xefwK699fz0z0spzM3gS2eWRh1LRJKMRXkowcz6AI8D3wPuDQ8dYWYlwLPuflIr68wAZgAUFxeXVVRUdGjbNTU1FBQUdDR6l0l0joZG59dv17FgUwPXn5zFmUMzI8nRFuVIrgzK0TNzlJeXz3f38a2+6O6RPoDvA98mGPIzI2w7HXj+cOuWlZV5R1VWVnZ43a4URY49++r9b3/7hh/9nWd84au/dn/8KG+839wfP8p9xX0JzxMrlf9dkjGDu3K01BNyAFXexvdqFFcfDQj3EDCzXOB84H2gEpgSLjYdeDLR2VJFTmY6d109nr8fMYeRq74JtaswHGpXwdwZ8NH9UUcUkYhEcfXRYIIhPt8B5gEvuvvTBAP3fNPMlgP9gbsjyJYy8rMzuGnAveSl1R38QkMtLLw1mlAiErmEn2h293eAU1ppXwFMTHSeVJa+Z02r7V67WoNxi6Qo3dGcyvKGt9r88b4B3FjxFm+u2Kp7GkRSjIpCKhtzG6TnHdTUmJbLGwXf5KUPNnHlXW8y6T9e4a5XP2RrTV0bbyIiPUkk9ylIkiidFjwvvDU4ZJQ3nLQxtzGldBqfu6SBPy1azwNzV/Ovf/qAO59fwgUnDuJvJw7n9KP7k5amA0wiPZGKQqornQal03jl5Zc555xzmptzs9L5QtkwvlA2jKUbd1Exdw2PLljLM++s56j+eUydUMKUsmEM7JUTXXYR6XI6fCSHdWxxL77/+ROY891J/GzqWAYV5vDj55Zwxr+9xNfum88rSzeroz2RHkJ7CtJuOZnpTD5lKJNPGcqHm2uomLuaRxes49nFGxjWN5crJ5Rw+fgSigu19yDSXWlPQTrkmAEF3Pq5E3jjO+fyy6tOYXi/PP79haWccftLXP/7Kio/2ESD9h5Euh3tKUinZGek8/kxQ/j8mCGs3LKbinlreGT+Gl58byNDeudwxYQSrhhfwpA+uVFHFZF2UFGQLjOiKJ+ZF43mm+cfy+z3N/LHuav5+exl/GL2Ms45biBXTRxO+XEDyEjXDqpIslJRkC6XlZHGRScP5qKTB7NmWy0PzlvDQ1VruP73VRQXZnPF+GDvoaRf3uHfTEQSSn+ySVyV9Mvj5s8cx19nnstdV5dxwuBCflW5nLPvrGT6PXN5bvF69jc0Bp3wPTGCT398LjwxQp3yiUREewqSEBnpaVxw4iAuOHEQ67bv4aFw7+Gr9y1gWvFr/KD4Z2SyN+hzqam3Vjhwg52IJISKgiTc0D65fOP8Y/n6uSN5Zelmxiy4jkz2HrxQQy2NC79LmoqCSEJFMZ5CiZlVmtl7Zvaumd0YtvczsxfNbFn43DfR2SSxMtLTmHR8MUW2sfUFdq/h6rvn8F+vfMjidTt0g5xIAkSxp1APfMvdF5hZL2C+mb0I/B0w291vN7OZwEyCMRakp8sbHhwyamFn2iA27tzL7c9+AEC//CzOOKY/nxpVxJkjixjWVyeqRbpaFOMprAfWh9O7zOx9YChwKXBOuNgs4GVUFFLDmNuCcwgNtQfa0vPoM/FOXij9NJt27uW15Vt4bdkWXlu+haffWQ9AaVE+Z47sz1kjB3D6Mf3pnZsZ0Q8g0nNYlP3lm9kI4FXgJGC1uzcN02lAddN8i3VmADMAiouLyyoqKjq07Z4w+HZPyjGw9s8cvet3ZDdsoi59ICt6XcemvPM+sZy783GN8+7WBt7d2sAH2xqoawADSnuncWJROif2T2dknzQyOtGTa9S/j2TJoBw9M0d5efl8dx/f2muRFQUzKwBeAW5z98fMbHtsETCzanc/5HmF8ePHe1VVVYe2/3KLXkGjohydy7GvvpG312wP9yQ2s3DtDhoandzMdE49uh9njSzirFFFHFfci+BvjfjkiIdkyKAcPTOHmbVZFCK5+sjMMoFHgfvd/bGweaOZDXb39WY2GNgURTbpXrIy0phY2o+Jpf345vnHsnPvft78cGtQJJZv4V+eeR+AooJszhrZn7NGDeCskUUM6q1O+0Rak/CiEB4auht4391/EvPSU8B04Pbw+clEZ5PurzAns/l+CIB12/fweng+4i/LtvDE2x8DMHJgQbAXMbKI047pT0F2+F/ho/th4a18unY1PDE8ON+hy2IlhUSxp3AmcDWwyMzeDtu+S1AMHjKza4FVwBURZJMeZmif3OZuNRobnQ827OL15Vv4y/ItVMxbzb1/XUlGmjG2pA/XDnuDC3Z/j/TGPbqJTlJWFFcfvUZwXrA1kxKZRVJLWppxwpBCThhSyPVnH83e/Q0sWF3Na8u28PryLZy89Q7Ss/YcvFJDLXXzZ1I78HL65mdFE1wkgXRHs6SsnMx0zjimiDOOKQLA/7il1eUy69Zxyj+/yIBe2Ywe1Itji3txXHEvjhvUi1HFBeRl6b+R9Bz6NIuErI2b6PZlD+XWzx7PBxt2sXTjLu6fs4q9+xuDdQxK+uZx3KCgUBw7qBejB/WitCifTHURLt2QioJIkzZuosspu53rS49ubmpodFZvq2VJWCSWbNzFkg27eClmtLnMdOPoooKgWIR7F6MH9WJon1zSOnH/hEi8qSiINGk6mbzwVrx2dbDn0MrVR+lpRmlRPqVF+Vx40qDm9rr6BlZs3s2SDUGhWLphF/NXVfPUwo+bl8nLSmdUcS9Gh3sVTYehigqyDtxHoSugJEIqCiKxSqdB6TRe6cCNQdkZ6Rw/uJDjBxce1L5r736WbaoJikX4ePH9jTxYtaZ5mX75WRxbXMDl/V/l0n0/JMN1BZREQ0VBJM565WQybnhfxg0/+Ab9LTV1LN2wq/lcxZKNuzit5idkZH7yCqitf72Z/35/HMP65lLSN4+SfrkM7ZNHblZ6An8SSQUqCiIRKSrIpmhkNmeMLGpu8z9ubnXZvmzk3r+uZF994yfeo6RfLsP65lHSN3zuFxSOIX1yycrQyW45MioKIkmkrSug0vKH88GPLmRLTR1rqmtZW72HNdtqWbNtD2u317JwzXaeXbSe+pgxJ8xgUGFO897FsH55B6b75jK4dw4Zh7pCSuc2UpKKgiF6p6wAAA57SURBVEgyaeMKKMbcRlqaMbAwh4GFOZQd9clVGxqdDTv3smbbgaKxtnoPa6prmfPRNp54ex2x4xSlpxlD+uQwrE/egb2NcC9jZO1T9F50A9ZQq3MbKUZFQSSZtPMKqNakpxlD++QytE9uq6/vq29k/Y49nygYa7bV8vKSzWzaVde87Guj/y99smoPfoOGWmrm3sJfaydRXJjDoN45FBVkk65LbHsUFQWRZNOJK6AOJSsjjaP653NU//xWX9+7v4F124OCMXR+63d359V/zIw/zG+eT08zBhRkU1yY3VwoiguDx6DCHAb1zmZgYQ69sjOOqOtyiY6KgogAQbcfxwwo4JgBBfB+6+c2PG8Y//sPZ7Fh51427NzLpp172bAjmF65dTdzPtrGjj37P7FeXlY6gwqbCkY2xb1zYuaDYjKwV3brd4Hr3EZCqSiIyCe1cW4jfey/cfKw3pxM7zZX3bOvgY1h0dgYPjbsqGuerlpVzaaddexrOPhKKjPon5/VvJcxsDCHszNf4Pya7x1034bPnYE7pB2twhAPUQ2ycw9wMbDJ3U8K2/oBDwIjgJXAFe5eHUU+kZTXiXMbuVnpjCjKZ0RR64epIBhWddvufWzcWddcQDbs2MumXcHzxzv28vaa7dxQcgcZLXqutYZa1r36DS76fRGFOZn0zs2kMDcjZjoznM6gMLdlW7Bsbmb6kR/OSpE9lqj2FO4FfgX8PqZtJjDb3W83s5nh/C0RZBMRiNu5DQAzo39BNv0LsjlhSGGby7XVc+3QrC18Ydwwdu7dz849+9m5p55VW2ub53fvazjk9jPTjcKcsFjkZlKYE1NAWik0w3c9wfBlN5KWAmNtRFIU3P1VMxvRovlS4JxwehbwMioKIimtrfs2LG84P7jkxDbX29/QyK699ezYExaNvfvD6fqY6fB5bz079+xnXfWe5tf2Nxw8dv1ro28lrZWxNja99i2+88qx9M3Pol9+Fn3zsuiXn0mfvNj5LHrnZnbdVVpx3mMxdz/8UnEQFoWnYw4fbXf3PuG0AdVN8y3WmwHMACguLi6rqKjo0PZramooKCjoWPgupBzKkcwZos4xsPbPHLfj30n3A5fLNlg2S3rfzKa88+KyTXdnXyPU7ndq90NtvXPdnvMxPvld2ehG+apn2LXP2bXP2d/YyhsSjCqWnwkFWUavTKMgyyjINHplGQVZNLfFvpaXCWktDnF11e+jvLx8vruPbzVrMhaFcL7a3fu2sToA48eP96qqqg5t/+U47BIrh3L0tAxJkSP8y/hIz210qSdGtLrHQt5RMHll8+yefQ1sq91H9e59bNu9j+qm6dr94XPL1/Z/4oR7kzSDvnlZwV5IXhZ98zO5Pf0S+rL+sDkOx8zaLArJdPXRRjMb7O7rzWwwsCnqQCKSBOJ4bqPdDnGneazcrHSGZrV9A2FL7k7tvobmInHg+UAR2R62r9xSS++BG1ofzLh2dSd+uIMlU1F4CpgO3B4+PxltHBGRUCeuxjoUMyM/O4P87AxK+uUdfoUnWj/HQt7wTuWIFUkXimb2APAGcJyZrTWzawmKwflmtgw4L5wXEUkOpdNg8kpeGfJScKgmiquOxtwW7KHEamWPpTOiuvroqjZempTQICIi3Umc9lhiqbN1EZHuJM57LCoKIiLSTEVBRESaqSiIiEgzFQUREWmmoiAiIs1UFEREpJmKgoiINFNREBGRZioKIiLSTEVBRESaqSiIiEgzFQUREWmWVEXBzC40syVmttzMZkadR0Qk1SRNUTCzdODXwEXACcBVZnZCtKlERFJL0hQFYCKw3N1XuPs+oAK4NOJMIiIpJZmG4xwKrImZXwuc2nIhM5sBzAhna8xsSQe3VwRs6eC6XUk5DqYcyZUBlKOlnpDjqLZeSKai0C7ufhdwV2ffx8yq3H18F0RSDuXosRmUI/VyJNPho3VAScz8sLBNREQSJJmKwjxglJmVmlkWcCXwVMSZRERSStIcPnL3ejP7B+B5IB24x93fjeMmO30Iqosox8GU44BkyADK0VKPzmHuHo/3FRGRbiiZDh+JiEjEVBRERKRZShQFM7vHzDaZ2eKYtn5m9qKZLQuf+yYgR4mZVZrZe2b2rpndmOgsZpZjZnPNbGGY4Ydhe6mZzQm7GHkwPNkfd2aWbmZvmdnTUeUws5VmtsjM3jazqrAtis9HHzN7xMw+MLP3zez0ROcws+PC30PTY6eZ3RRBjm+En8/FZvZA+LmN4rNxY5jhXTO7KWyL++/iSL6zLPCL8PfyjpmN68y2U6IoAPcCF7ZomwnMdvdRwOxwPt7qgW+5+wnAacANYVceicxSB5zr7mOAscCFZnYacAfwU3cfCVQD18YxQ6wbgfdj5qPKUe7uY2Ou+47i8/Fz4Dl3Hw2MIfi9JDSHuy8Jfw9jgTKgFng8kTnMbCjwj8B4dz+J4MKTK0nwZ8PMTgKuJ+htYQxwsZmNJDG/i3tp/3fWRcCo8DED+E2ntuzuKfEARgCLY+aXAIPD6cHAkggyPQmcH1UWIA9YQHDn+BYgI2w/HXg+AdsfFn64zwWeBiyiHCuBohZtCf03AXoDHxFe/BFVjhbbvgB4PdE5ONC7QT+CKySfBj6T6M8GcDlwd8z894D/m6jfRXu/s4D/Bq5qbbmOPFJlT6E1xe6+PpzeABQncuNmNgI4BZiT6CzhIZu3gU3Ai8CHwHZ3rw8XWUvwHzPefkbwn6wxnO8fUQ4HXjCz+RZ0owKJ/3yUApuB/wkPp/3OzPIjyBHrSuCBcDphOdx9HfDvwGpgPbADmE/iPxuLgU+ZWX8zywM+S3CDbVT/Jm1tt7Uugjr8u0nlotDMg/KasGtzzawAeBS4yd13JjqLuzd4cHhgGMGu8eh4bq81ZnYxsMnd5yd62604y93HEeyG32BmZ8e+mKDPRwYwDviNu58C7KbFYYlEfk7D4/WXAA+3fC3eOcJj5ZcSFMohQD6fPJQSd+7+PsEhqxeA54C3gYYWyyT0uyMR203lorDRzAYDhM+bErFRM8skKAj3u/tjUWZx9+1AJcGueB8za7qZMRFdjJwJXGJmKwl6xD2X4Jh6onM0/WWKu28iOH4+kcT/m6wF1rr7nHD+EYIiEclng6BALnD3jeF8InOcB3zk7pvdfT/wGMHnJYrPxt3uXubuZxOcx1hKdP8mbW23S7sISuWi8BQwPZyeTnB8P67MzIC7gffd/SdRZDGzAWbWJ5zOJTin8T5BcZiSiAwA7v4ddx/m7iMIDlO85O7TEp3DzPLNrFfTNMFx9MUk+PPh7huANWZ2XNg0CXgv0TliXMWBQ0ckOMdq4DQzywv/zzT9LhL62QAws4Hh83DgMuCPRPdv0tZ2nwKuCa9COg3YEXOY6cjF80RNsjwIPtzrgf0Ef5FdS3D8ejawDPgz0C8BOc4i2OV7h2BX9G2C45QJywL8DfBWmGEx8P2w/WhgLrCc4JBBdgL/fc4Bno4iR7i9heHjXeDWsD2Kz8dYoCr8t3kC6BtRjnxgK9A7pi2hOYAfAh+En9E/ANlRfEaBvxAUpIXApET9Lo7kO4vgAo1fE5wbXERw1VaHt61uLkREpFkqHz4SEZEWVBRERKSZioKIiDRTURARkWYqCiIi0kxFQZKembmZ/UfM/M1m9oMueu97zWzK4Zfs9HYuD3s+rUymXCItqShId1AHXGZmRVEHiRVzd217XAtc7+7l8coj0hVUFKQ7qCcYj/YbLV9o+Re1mdWEz+eY2Stm9qSZrTCz281smgVjSSwys2Ni3uY8M6sys6Vhn0xNnQbeaWbzwj7qvxLzvn8xs6cIbmpqmeeq8P0Xm9kdYdv3CW5cvNvM7mxlnVvCdRaa2e2tvP79MMdiM7srvMsXM/tHC8bmeMfMKsK2T9uBsRDeirlb+9sxP0vTGBr5ZvZMuN3FZja1ff8c0pMdyV86IlH6NfCOmf34CNYZAxwPbANWAL9z94kWDG70deCmcLkRBP0dHQNUhn3mX0PQXcAEM8sGXjezF8LlxwEnuftHsRszsyEEHaiVEfST84KZTXb3H5nZucDN7l7VYp2LCDp/O9Xda82sXys/x6/c/Ufh8n8ALgb+l6DDvFJ3r2vqugS4GbjB3V8PO17ca2YXEPS1P5Hg7tenwk7/BgAfu/vnwvfu3e7frPRY2lOQbsGD3mR/TzD4SnvNc/f17l5H0AVA05f6IoJC0OQhd29092UExWM0QR9I11jQxfgcgi4GRoXLz21ZEEITgJc96MitHrgfOLuV5WKdB/yPu9eGP+e2VpYpt2DEsUUEHQeeGLa/A9xvZl8k2JsCeB34iZn9I9AnzHFB+HiLYPyM0eHPsgg438zuMLNPufuOw2SVFKCiIN3JzwiOzefHtNUTfo7NLA2IHaKxLma6MWa+kYP3klv29eIEf1F/3cNRyNy91N2bisruTv0UR8DMcoD/BKa4+8nAb4Gc8OXPEexBjQPmmVmGu98OXAfkEuzdjA5/ln+L+VlGetD759Jw3UXAv4SHuSTFqShItxH+Ff0QBw/DuJLgcA0E/f9nduCtLzeztPA8w9EEI1c9D3zNgq7OMbNjw15UD2Uu8GkzKzKzdIKeRl85zDovAl+yYBAXWjl81FQAtoSHg6aEy6UBJe5eCdxCMHJbgZkd4+6L3P0OYB7BXsHzwJfD9TGzoWY2MDzcVevu9wF3EhQISXE6pyDdzX8A/xAz/1vgSTNbSDAQSkf+il9N8IVeCHzV3fea2e8IDjEtCE/sbgYmH+pN3H29mc0k6OLZgGfc/ZDdKrv7c2Y2Fqgys33An4Dvxry+3cx+S9Bb6AaCL3oIxi2+LzwPYMAvwmX/2czKCfaG3gWeDc85HA+8EZ6jrgG+CIwE7jSzRoLeOL/Wnl+W9GzqJVVERJrp8JGIiDRTURARkWYqCiIi0kxFQUREmqkoiIhIMxUFERFppqIgIiLN/j+RETi1TH9TLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "amC8Qy-yVw8W",
    "colab_type": "code",
    "outputId": "59f73d22-5229-49bf-b744-e4914b04af16",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "def save_accuracies(train_accuracies, val_accuracies, test_accuracies, output=OUTPUT_PATH):\n",
    "  with open(f\"{output}_accuracies.csv\", \"w\", encoding=\"utf8\") as f:\n",
    "    f.write(\"mean_train_acc,mean_val_acc,test_acc\\n\")\n",
    "    for train, val, test in zip(train_accuracies, val_accuracies, test_accuracies):\n",
    "      f.write(f\"{train},{val},{test}\\n\")\n",
    "    print(\"********** FILE SAVED **********\")\n",
    "\n",
    "\n",
    "save_accuracies(train_accuracies, val_accuracies, test_accuracies)"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "********** FILE SAVED **********\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}